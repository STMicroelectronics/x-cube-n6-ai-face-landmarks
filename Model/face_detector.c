/* AUTOGENERATED DO NOT MODIFY */

/**
  ******************************************************************************
  * @file    face_detector.c
  * @brief   NN Code autogenerated DO NOT MODIFY IT
  ******************************************************************************
  * @attention
  *
  * Copyright (c) 2023 STMicroelectronics.
  * All rights reserved.
  *
  * This software is licensed under terms that can be found in the LICENSE file
  * in the root directory of this software component.
  * If no LICENSE file comes with this software, it is provided AS-IS.
  *
  ******************************************************************************
  */

/*
 * GIT_SHA         "e619e8606099384540d70eeaaa8091752b1bebe9"
 * GIT_BRANCH      "STAI-2.2"
 * GIT_DESCRIPTION "atonn-v1.1.1-14-ge619e860"
 *
 * Command Line options:
 * --load-mdesc-file = "/home/rattingu/st/stedgeai/2.2/Utilities/configs/stm32n6"
 * --load-mpool-file = "/home/rattingu/Workspace/x-cube-n6-ai-face-landmarks/Model/my_mpools/face_detector"
 * --cache-maintenance = true
 * --enable-virtual-mem-pools = true
 * --native-float = true
 * --json-quant-file = "/home/rattingu/Workspace/x-cube-n6-ai-face-landmarks/Model/st_ai_output/blazeface_front_128_quant_pc_ff_od_wider_face_OE_3_3_0_Q.json"
 * --optimization = 3
 * --Os = true
 * --Omax-ca-pipe = 4
 * --Ocache-opt = true
 * --enable-epoch-controller = true
 * --output-info-file = "c_info"
 * --onnx-input = "/home/rattingu/Workspace/x-cube-n6-ai-face-landmarks/Model/st_ai_output/blazeface_front_128_quant_pc_ff_od_wider_face_OE_3_3_0.onnx"
 * --out-dir-prefix = "/home/rattingu/Workspace/x-cube-n6-ai-face-landmarks/Model/st_ai_ws/neural_art__face_detector/"
 * --network-name = "face_detector"
 * --all-buffers-info = true
 * --mvei = true
 * --Oauto-sched = true
 *
 * auto* option expanded into:
 *   alt-scheduler = false
 */

#include "ll_aton_NN_interface.h"
#include "ll_aton.h"
#include "ll_aton_lib.h"
#include "ll_aton_version.h"
#include "ll_sw.h"
#include "ecloader.h"

#if LL_ATON_VERSION_MAJOR != 1 || LL_ATON_VERSION_MINOR != 1 || LL_ATON_VERSION_MICRO != 1 || LL_ATON_VERSION_DEV != 14
#  error "Possible mismatch in ll_aton library used"
#endif

#if !defined(LL_ATON_DBG_BUFFER_INFO_EXCLUDED)
#  define LL_ATON_DBG_BUFFER_INFO_EXCLUDED 0
#endif

/* global pool 4 is ? */
/* index=4 file postfix=xSPI1 name=hyperRAM offset=0x90000000  absolute_mode size=16777208 READ_WRITE THROUGHPUT=MID LATENCY=HIGH byte width=2 freq ratio=5 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=ON read_power=380 write_power=340 use4initializers=YES score=82  */
/* global pool 5 is 150.82 KB */
/* index=5 file postfix=xSPI2 name=octoFlash offset=0x70380000  absolute_mode size=2097144 READ_ONLY THROUGHPUT=MID LATENCY=HIGH byte width=1 freq ratio=6 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=ON read_power=110 write_power=400 use4initializers=YES score=50  */
/* global pool 8 is 448.00 KB */
/* index=8 file postfix=AXISRAM3_AXISRAM4_AXISRAM5_AXISRAM6 name=npuRAM3_npuRAM4_npuRAM5_npuRAM6 offset=0x34200000  absolute_mode size=1835000 vpool READ_WRITE THROUGHPUT=HIGH LATENCY=LOW byte width=8 freq ratio=1.25 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=19.006 write_power=16.201 use4initializers=NO score=95  */
/* global pool 1 is ? */
/* index=1 file postfix=AXISRAM5 name=npuRAM5 offset=0x342e0000  absolute_mode size=458752 READ_WRITE THROUGHPUT=HIGH LATENCY=LOW byte width=8 freq ratio=1.25 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=18.531 write_power=16.201 use4initializers=NO score=94  */
/* global pool 2 is ? */
/* index=2 file postfix=AXISRAM4 name=npuRAM4 offset=0x34270000  absolute_mode size=458752 READ_WRITE THROUGHPUT=HIGH LATENCY=LOW byte width=8 freq ratio=1.25 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=18.531 write_power=16.201 use4initializers=NO score=94  */
/* global pool 3 is 448.00 KB */
/* index=3 file postfix=AXISRAM3 name=npuRAM3 offset=0x34200000  absolute_mode size=458752 READ_WRITE THROUGHPUT=HIGH LATENCY=LOW byte width=8 freq ratio=1.25 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=18.531 write_power=16.201 use4initializers=NO score=94  */
/* global pool 0 is ? */
/* index=0 file postfix=AXISRAM6 name=npuRAM6 offset=0x34350000  absolute_mode size=458744 READ_WRITE THROUGHPUT=HIGH LATENCY=LOW byte width=8 freq ratio=1.25 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=19.006 write_power=15.79 use4initializers=NO score=94  */

/* User Input allocated buffer (mempool 9) size 49152 */
static unsigned char *_mem_pool__user_io_input_0_face_detector = NULL; /* tensor name Input_0_out_0 */

LL_ATON_User_IO_Result_t LL_ATON_Set_User_Input_Buffer_face_detector(uint32_t num, void* buffer, uint32_t size)
{
  if (num == 0) {
    if (((uintptr_t)buffer % 32) != 0)
      return LL_ATON_User_IO_WRONG_ALIGN; /* enforce MCU cacheline alignment */
    if (size < 49152)
      return LL_ATON_User_IO_WRONG_SIZE; /* enforce size needed */
    _mem_pool__user_io_input_0_face_detector = buffer;
    return LL_ATON_User_IO_NOERROR;
  } else
  { 
    return LL_ATON_User_IO_WRONG_INDEX;
  }
}

void *LL_ATON_Get_User_Input_Buffer_face_detector(uint32_t num)
{
  if (num == 0) {
    return _mem_pool__user_io_input_0_face_detector;
  } else
  { 
    return NULL;
  }
}

LL_ATON_User_IO_Result_t LL_ATON_Set_User_Output_Buffer_face_detector(uint32_t num, void* buffer, uint32_t size)
{
  { 
    return LL_ATON_User_IO_WRONG_INDEX;
  }
}

void *LL_ATON_Get_User_Output_Buffer_face_detector(uint32_t num)
{
  { 
    return NULL;
  }
}

#include "face_detector_ecblobs.h"

/* scheduling epoch=0    nodes=146 ------------------------------------------------------------------- */

// Epoch Controller Blob (name='_ec_blob_face_detector_1') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_1') start function
static void _ec_blob_cache_start_func_1(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 98304))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 196608))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 98304))) /* Equivalent hex address = 0x34218000UL */, 98304);

};


/* scheduling epoch=7    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_7(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 98304))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 98304);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_22 */
  static const uint32_t Transpose_22_tensor_shape_in_7_shape_0[] = { 1, 64, 64, 24 };
  static const LL_LIB_TensorShape_TypeDef Transpose_22_tensor_shape_in_7[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 98304,
      .offset_end = 196608,
      .offset_limit = 196672,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_22_tensor_shape_in_7_shape_0,
      .batch = 24,
    }
  };

  static const uint32_t Transpose_22_tensor_axes_offsets_in_7_0[] = { 98304, 1536, 24, 1 };
  static const uint32_t* Transpose_22_tensor_axes_offsets_in_7[] = {
    Transpose_22_tensor_axes_offsets_in_7_0
  };

  static const uint32_t Transpose_22_tensor_shape_out_7_shape_0[] = { 1, 24, 64, 64 };
  static const LL_LIB_TensorShape_TypeDef Transpose_22_tensor_shape_out_7[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 98304,
      .offset_limit = 98368,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_22_tensor_shape_out_7_shape_0,
      .batch = 64,
    }
  };

  static const uint32_t Transpose_22_tensor_axes_offsets_out_7_0[] = { 98304, 4096, 64, 1 };
  static const uint32_t* Transpose_22_tensor_axes_offsets_out_7[] = {
    Transpose_22_tensor_axes_offsets_out_7_0
  };

  static const uint8_t Transpose_22_perm_to_use_array_in_7[] = { 0, 3, 2, 1 };
  static const uint8_t Transpose_22_target_pos_array_in_7[] = { 0, 3, 2, 1 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_22_tensor_shape_in_7[0], Transpose_22_tensor_axes_offsets_in_7[0], &Transpose_22_tensor_shape_out_7[0], Transpose_22_tensor_axes_offsets_out_7[0], Transpose_22_target_pos_array_in_7, Transpose_22_perm_to_use_array_in_7, 0, 9);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 98304))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 98304);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_8') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_8') start function
static void _ec_blob_cache_start_func_8(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 114688))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 114688);

};


/* scheduling epoch=10   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_10(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 229376))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 344064))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 229376))) /* Equivalent hex address = 0x34238000UL */, 114688);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_24 */
  static const uint32_t Transpose_24_tensor_shape_in_10_shape_0[] = { 1, 64, 28, 64 };
  static const LL_LIB_TensorShape_TypeDef Transpose_24_tensor_shape_in_10[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 114688,
      .offset_limit = 114752,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_24_tensor_shape_in_10_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_24_tensor_axes_offsets_in_10_0[] = { 114688, 1792, 64, 1 };
  static const uint32_t* Transpose_24_tensor_axes_offsets_in_10[] = {
    Transpose_24_tensor_axes_offsets_in_10_0
  };

  static const uint32_t Transpose_24_tensor_shape_out_10_shape_0[] = { 1, 28, 64, 64 };
  static const LL_LIB_TensorShape_TypeDef Transpose_24_tensor_shape_out_10[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 229376,
      .offset_end = 344064,
      .offset_limit = 344128,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_24_tensor_shape_out_10_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_24_tensor_axes_offsets_out_10_0[] = { 114688, 4096, 64, 1 };
  static const uint32_t* Transpose_24_tensor_axes_offsets_out_10[] = {
    Transpose_24_tensor_axes_offsets_out_10_0
  };

  static const uint8_t Transpose_24_perm_to_use_array_in_10[] = { 0, 2, 1, 3 };
  static const uint8_t Transpose_24_target_pos_array_in_10[] = { 0, 2, 1, 3 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_24_tensor_shape_in_10[0], Transpose_24_tensor_axes_offsets_in_10[0], &Transpose_24_tensor_shape_out_10[0], Transpose_24_tensor_axes_offsets_out_10[0], Transpose_24_target_pos_array_in_10, Transpose_24_perm_to_use_array_in_10, 0, 9);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 229376))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 344064))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 229376))) /* Equivalent hex address = 0x34238000UL */, 114688);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_11') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_11') start function
static void _ec_blob_cache_start_func_11(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 344064))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 372736))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 344064))) /* Equivalent hex address = 0x34254000UL */, 28672);

};


/* scheduling epoch=14   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_14(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 372736))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 401408))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 372736))) /* Equivalent hex address = 0x3425b000UL */, 28672);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_44 */
  static const uint32_t Transpose_44_tensor_shape_in_14_shape_0[] = { 1, 32, 32, 28 };
  static const LL_LIB_TensorShape_TypeDef Transpose_44_tensor_shape_in_14[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 344064,
      .offset_end = 372736,
      .offset_limit = 372800,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_44_tensor_shape_in_14_shape_0,
      .batch = 28,
    }
  };

  static const uint32_t Transpose_44_tensor_axes_offsets_in_14_0[] = { 28672, 896, 28, 1 };
  static const uint32_t* Transpose_44_tensor_axes_offsets_in_14[] = {
    Transpose_44_tensor_axes_offsets_in_14_0
  };

  static const uint32_t Transpose_44_tensor_shape_out_14_shape_0[] = { 1, 28, 32, 32 };
  static const LL_LIB_TensorShape_TypeDef Transpose_44_tensor_shape_out_14[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 372736,
      .offset_end = 401408,
      .offset_limit = 401472,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_44_tensor_shape_out_14_shape_0,
      .batch = 32,
    }
  };

  static const uint32_t Transpose_44_tensor_axes_offsets_out_14_0[] = { 28672, 1024, 32, 1 };
  static const uint32_t* Transpose_44_tensor_axes_offsets_out_14[] = {
    Transpose_44_tensor_axes_offsets_out_14_0
  };

  static const uint8_t Transpose_44_perm_to_use_array_in_14[] = { 0, 3, 2, 1 };
  static const uint8_t Transpose_44_target_pos_array_in_14[] = { 0, 3, 2, 1 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_44_tensor_shape_in_14[0], Transpose_44_tensor_axes_offsets_in_14[0], &Transpose_44_tensor_shape_out_14[0], Transpose_44_tensor_axes_offsets_out_14[0], Transpose_44_target_pos_array_in_14, Transpose_44_perm_to_use_array_in_14, 1, 2);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 372736))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 401408))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 372736))) /* Equivalent hex address = 0x3425b000UL */, 28672);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_15') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_15') start function
static void _ec_blob_cache_start_func_15(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 32768))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 65536))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 32768))) /* Equivalent hex address = 0x34208000UL */, 32768);

};


/* scheduling epoch=17   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_17(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 65536))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 98304))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 65536))) /* Equivalent hex address = 0x34210000UL */, 32768);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_46 */
  static const uint32_t Transpose_46_tensor_shape_in_17_shape_0[] = { 1, 32, 32, 32 };
  static const LL_LIB_TensorShape_TypeDef Transpose_46_tensor_shape_in_17[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 32768,
      .offset_end = 65536,
      .offset_limit = 65600,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_46_tensor_shape_in_17_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_46_tensor_axes_offsets_in_17_0[] = { 32768, 1024, 32, 1 };
  static const uint32_t* Transpose_46_tensor_axes_offsets_in_17[] = {
    Transpose_46_tensor_axes_offsets_in_17_0
  };

  static const uint32_t Transpose_46_tensor_shape_out_17_shape_0[] = { 1, 32, 32, 32 };
  static const LL_LIB_TensorShape_TypeDef Transpose_46_tensor_shape_out_17[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 65536,
      .offset_end = 98304,
      .offset_limit = 98368,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_46_tensor_shape_out_17_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_46_tensor_axes_offsets_out_17_0[] = { 32768, 1024, 32, 1 };
  static const uint32_t* Transpose_46_tensor_axes_offsets_out_17[] = {
    Transpose_46_tensor_axes_offsets_out_17_0
  };

  static const uint8_t Transpose_46_perm_to_use_array_in_17[] = { 0, 2, 1, 3 };
  static const uint8_t Transpose_46_target_pos_array_in_17[] = { 0, 2, 1, 3 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_46_tensor_shape_in_17[0], Transpose_46_tensor_axes_offsets_in_17[0], &Transpose_46_tensor_shape_out_17[0], Transpose_46_tensor_axes_offsets_out_17[0], Transpose_46_target_pos_array_in_17, Transpose_46_perm_to_use_array_in_17, 4, 5);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 65536))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 98304))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 65536))) /* Equivalent hex address = 0x34210000UL */, 32768);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_18') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_18') start function
static void _ec_blob_cache_start_func_18(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 65536))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 98304))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 65536))) /* Equivalent hex address = 0x34210000UL */, 32768);

};


/* scheduling epoch=20   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_20(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 32768))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 32768);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_51 */
  static const uint32_t Transpose_51_tensor_shape_in_20_shape_0[] = { 1, 32, 32, 32 };
  static const LL_LIB_TensorShape_TypeDef Transpose_51_tensor_shape_in_20[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 65536,
      .offset_end = 98304,
      .offset_limit = 98368,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_51_tensor_shape_in_20_shape_0,
      .batch = 32,
    }
  };

  static const uint32_t Transpose_51_tensor_axes_offsets_in_20_0[] = { 32768, 1024, 32, 1 };
  static const uint32_t* Transpose_51_tensor_axes_offsets_in_20[] = {
    Transpose_51_tensor_axes_offsets_in_20_0
  };

  static const uint32_t Transpose_51_tensor_shape_out_20_shape_0[] = { 1, 32, 32, 32 };
  static const LL_LIB_TensorShape_TypeDef Transpose_51_tensor_shape_out_20[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 32768,
      .offset_limit = 32832,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_51_tensor_shape_out_20_shape_0,
      .batch = 32,
    }
  };

  static const uint32_t Transpose_51_tensor_axes_offsets_out_20_0[] = { 32768, 1024, 32, 1 };
  static const uint32_t* Transpose_51_tensor_axes_offsets_out_20[] = {
    Transpose_51_tensor_axes_offsets_out_20_0
  };

  static const uint8_t Transpose_51_perm_to_use_array_in_20[] = { 0, 3, 2, 1 };
  static const uint8_t Transpose_51_target_pos_array_in_20[] = { 0, 3, 2, 1 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_51_tensor_shape_in_20[0], Transpose_51_tensor_axes_offsets_in_20[0], &Transpose_51_tensor_shape_out_20[0], Transpose_51_tensor_axes_offsets_out_20[0], Transpose_51_target_pos_array_in_20, Transpose_51_perm_to_use_array_in_20, 8, 9);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 32768))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 32768);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_21') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_21') start function
static void _ec_blob_cache_start_func_21(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 36864))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 73728))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 36864))) /* Equivalent hex address = 0x34209000UL */, 36864);

};


/* scheduling epoch=23   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_23(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 73728))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 110592))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 73728))) /* Equivalent hex address = 0x34212000UL */, 36864);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_53 */
  static const uint32_t Transpose_53_tensor_shape_in_23_shape_0[] = { 1, 32, 36, 32 };
  static const LL_LIB_TensorShape_TypeDef Transpose_53_tensor_shape_in_23[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 36864,
      .offset_end = 73728,
      .offset_limit = 73792,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_53_tensor_shape_in_23_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_53_tensor_axes_offsets_in_23_0[] = { 36864, 1152, 32, 1 };
  static const uint32_t* Transpose_53_tensor_axes_offsets_in_23[] = {
    Transpose_53_tensor_axes_offsets_in_23_0
  };

  static const uint32_t Transpose_53_tensor_shape_out_23_shape_0[] = { 1, 36, 32, 32 };
  static const LL_LIB_TensorShape_TypeDef Transpose_53_tensor_shape_out_23[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 73728,
      .offset_end = 110592,
      .offset_limit = 110656,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_53_tensor_shape_out_23_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_53_tensor_axes_offsets_out_23_0[] = { 36864, 1024, 32, 1 };
  static const uint32_t* Transpose_53_tensor_axes_offsets_out_23[] = {
    Transpose_53_tensor_axes_offsets_out_23_0
  };

  static const uint8_t Transpose_53_perm_to_use_array_in_23[] = { 0, 2, 1, 3 };
  static const uint8_t Transpose_53_target_pos_array_in_23[] = { 0, 2, 1, 3 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_53_tensor_shape_in_23[0], Transpose_53_tensor_axes_offsets_in_23[0], &Transpose_53_tensor_shape_out_23[0], Transpose_53_tensor_axes_offsets_out_23[0], Transpose_53_target_pos_array_in_23, Transpose_53_perm_to_use_array_in_23, 4, 5);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 73728))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 110592))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 73728))) /* Equivalent hex address = 0x34212000UL */, 36864);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_24') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_24') start function
static void _ec_blob_cache_start_func_24(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 73728))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 110592))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 73728))) /* Equivalent hex address = 0x34212000UL */, 36864);

};


/* scheduling epoch=26   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_26(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 36864))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 36864);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_65 */
  static const uint32_t Transpose_65_tensor_shape_in_26_shape_0[] = { 1, 32, 32, 36 };
  static const LL_LIB_TensorShape_TypeDef Transpose_65_tensor_shape_in_26[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 73728,
      .offset_end = 110592,
      .offset_limit = 110656,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_65_tensor_shape_in_26_shape_0,
      .batch = 36,
    }
  };

  static const uint32_t Transpose_65_tensor_axes_offsets_in_26_0[] = { 36864, 1152, 36, 1 };
  static const uint32_t* Transpose_65_tensor_axes_offsets_in_26[] = {
    Transpose_65_tensor_axes_offsets_in_26_0
  };

  static const uint32_t Transpose_65_tensor_shape_out_26_shape_0[] = { 1, 36, 32, 32 };
  static const LL_LIB_TensorShape_TypeDef Transpose_65_tensor_shape_out_26[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 36864,
      .offset_limit = 36928,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_65_tensor_shape_out_26_shape_0,
      .batch = 32,
    }
  };

  static const uint32_t Transpose_65_tensor_axes_offsets_out_26_0[] = { 36864, 1024, 32, 1 };
  static const uint32_t* Transpose_65_tensor_axes_offsets_out_26[] = {
    Transpose_65_tensor_axes_offsets_out_26_0
  };

  static const uint8_t Transpose_65_perm_to_use_array_in_26[] = { 0, 3, 2, 1 };
  static const uint8_t Transpose_65_target_pos_array_in_26[] = { 0, 3, 2, 1 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_65_tensor_shape_in_26[0], Transpose_65_tensor_axes_offsets_in_26[0], &Transpose_65_tensor_shape_out_26[0], Transpose_65_tensor_axes_offsets_out_26[0], Transpose_65_target_pos_array_in_26, Transpose_65_perm_to_use_array_in_26, 8, 9);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 36864))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 36864);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_27') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_27') start function
static void _ec_blob_cache_start_func_27(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 43008))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 43008);

};


/* scheduling epoch=29   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_29(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 43008))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 86016))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 43008))) /* Equivalent hex address = 0x3420a800UL */, 43008);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_67 */
  static const uint32_t Transpose_67_tensor_shape_in_29_shape_0[] = { 1, 32, 42, 32 };
  static const LL_LIB_TensorShape_TypeDef Transpose_67_tensor_shape_in_29[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 43008,
      .offset_limit = 43072,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_67_tensor_shape_in_29_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_67_tensor_axes_offsets_in_29_0[] = { 43008, 1344, 32, 1 };
  static const uint32_t* Transpose_67_tensor_axes_offsets_in_29[] = {
    Transpose_67_tensor_axes_offsets_in_29_0
  };

  static const uint32_t Transpose_67_tensor_shape_out_29_shape_0[] = { 1, 42, 32, 32 };
  static const LL_LIB_TensorShape_TypeDef Transpose_67_tensor_shape_out_29[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 43008,
      .offset_end = 86016,
      .offset_limit = 86080,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_67_tensor_shape_out_29_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_67_tensor_axes_offsets_out_29_0[] = { 43008, 1024, 32, 1 };
  static const uint32_t* Transpose_67_tensor_axes_offsets_out_29[] = {
    Transpose_67_tensor_axes_offsets_out_29_0
  };

  static const uint8_t Transpose_67_perm_to_use_array_in_29[] = { 0, 2, 1, 3 };
  static const uint8_t Transpose_67_target_pos_array_in_29[] = { 0, 2, 1, 3 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_67_tensor_shape_in_29[0], Transpose_67_tensor_axes_offsets_in_29[0], &Transpose_67_tensor_shape_out_29[0], Transpose_67_tensor_axes_offsets_out_29[0], Transpose_67_target_pos_array_in_29, Transpose_67_perm_to_use_array_in_29, 0, 4);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 43008))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 86016))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 43008))) /* Equivalent hex address = 0x3420a800UL */, 43008);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_30') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_30') start function
static void _ec_blob_cache_start_func_30(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 129024))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 139776))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 129024))) /* Equivalent hex address = 0x3421f800UL */, 10752);

};


/* scheduling epoch=33   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_33(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 10752))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 10752);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_87 */
  static const uint32_t Transpose_87_tensor_shape_in_33_shape_0[] = { 1, 16, 16, 42 };
  static const LL_LIB_TensorShape_TypeDef Transpose_87_tensor_shape_in_33[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 129024,
      .offset_end = 139776,
      .offset_limit = 139840,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_87_tensor_shape_in_33_shape_0,
      .batch = 42,
    }
  };

  static const uint32_t Transpose_87_tensor_axes_offsets_in_33_0[] = { 10752, 672, 42, 1 };
  static const uint32_t* Transpose_87_tensor_axes_offsets_in_33[] = {
    Transpose_87_tensor_axes_offsets_in_33_0
  };

  static const uint32_t Transpose_87_tensor_shape_out_33_shape_0[] = { 1, 42, 16, 16 };
  static const LL_LIB_TensorShape_TypeDef Transpose_87_tensor_shape_out_33[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 10752,
      .offset_limit = 10816,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_87_tensor_shape_out_33_shape_0,
      .batch = 16,
    }
  };

  static const uint32_t Transpose_87_tensor_axes_offsets_out_33_0[] = { 10752, 256, 16, 1 };
  static const uint32_t* Transpose_87_tensor_axes_offsets_out_33[] = {
    Transpose_87_tensor_axes_offsets_out_33_0
  };

  static const uint8_t Transpose_87_perm_to_use_array_in_33[] = { 0, 3, 2, 1 };
  static const uint8_t Transpose_87_target_pos_array_in_33[] = { 0, 3, 2, 1 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_87_tensor_shape_in_33[0], Transpose_87_tensor_axes_offsets_in_33[0], &Transpose_87_tensor_shape_out_33[0], Transpose_87_tensor_axes_offsets_out_33[0], Transpose_87_target_pos_array_in_33, Transpose_87_perm_to_use_array_in_33, 6, 7);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 10752))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 10752);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_34') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_34') start function
static void _ec_blob_cache_start_func_34(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 12288))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 24576))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 12288))) /* Equivalent hex address = 0x34203000UL */, 12288);

};


/* scheduling epoch=36   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_36(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 24576))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 36864))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 24576))) /* Equivalent hex address = 0x34206000UL */, 12288);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_89 */
  static const uint32_t Transpose_89_tensor_shape_in_36_shape_0[] = { 1, 16, 48, 16 };
  static const LL_LIB_TensorShape_TypeDef Transpose_89_tensor_shape_in_36[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 12288,
      .offset_end = 24576,
      .offset_limit = 24640,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_89_tensor_shape_in_36_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_89_tensor_axes_offsets_in_36_0[] = { 12288, 768, 16, 1 };
  static const uint32_t* Transpose_89_tensor_axes_offsets_in_36[] = {
    Transpose_89_tensor_axes_offsets_in_36_0
  };

  static const uint32_t Transpose_89_tensor_shape_out_36_shape_0[] = { 1, 48, 16, 16 };
  static const LL_LIB_TensorShape_TypeDef Transpose_89_tensor_shape_out_36[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 24576,
      .offset_end = 36864,
      .offset_limit = 36928,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_89_tensor_shape_out_36_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_89_tensor_axes_offsets_out_36_0[] = { 12288, 256, 16, 1 };
  static const uint32_t* Transpose_89_tensor_axes_offsets_out_36[] = {
    Transpose_89_tensor_axes_offsets_out_36_0
  };

  static const uint8_t Transpose_89_perm_to_use_array_in_36[] = { 0, 2, 1, 3 };
  static const uint8_t Transpose_89_target_pos_array_in_36[] = { 0, 2, 1, 3 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_89_tensor_shape_in_36[0], Transpose_89_tensor_axes_offsets_in_36[0], &Transpose_89_tensor_shape_out_36[0], Transpose_89_tensor_axes_offsets_out_36[0], Transpose_89_target_pos_array_in_36, Transpose_89_perm_to_use_array_in_36, 4, 8);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 24576))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 36864))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 24576))) /* Equivalent hex address = 0x34206000UL */, 12288);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_37') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_37') start function
static void _ec_blob_cache_start_func_37(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 24576))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 36864))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 24576))) /* Equivalent hex address = 0x34206000UL */, 12288);

};


/* scheduling epoch=39   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_39(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 12288))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 12288);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_94 */
  static const uint32_t Transpose_94_tensor_shape_in_39_shape_0[] = { 1, 16, 16, 48 };
  static const LL_LIB_TensorShape_TypeDef Transpose_94_tensor_shape_in_39[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 24576,
      .offset_end = 36864,
      .offset_limit = 36928,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_94_tensor_shape_in_39_shape_0,
      .batch = 48,
    }
  };

  static const uint32_t Transpose_94_tensor_axes_offsets_in_39_0[] = { 12288, 768, 48, 1 };
  static const uint32_t* Transpose_94_tensor_axes_offsets_in_39[] = {
    Transpose_94_tensor_axes_offsets_in_39_0
  };

  static const uint32_t Transpose_94_tensor_shape_out_39_shape_0[] = { 1, 48, 16, 16 };
  static const LL_LIB_TensorShape_TypeDef Transpose_94_tensor_shape_out_39[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 12288,
      .offset_limit = 12352,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_94_tensor_shape_out_39_shape_0,
      .batch = 16,
    }
  };

  static const uint32_t Transpose_94_tensor_axes_offsets_out_39_0[] = { 12288, 256, 16, 1 };
  static const uint32_t* Transpose_94_tensor_axes_offsets_out_39[] = {
    Transpose_94_tensor_axes_offsets_out_39_0
  };

  static const uint8_t Transpose_94_perm_to_use_array_in_39[] = { 0, 3, 2, 1 };
  static const uint8_t Transpose_94_target_pos_array_in_39[] = { 0, 3, 2, 1 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_94_tensor_shape_in_39[0], Transpose_94_tensor_axes_offsets_in_39[0], &Transpose_94_tensor_shape_out_39[0], Transpose_94_tensor_axes_offsets_out_39[0], Transpose_94_target_pos_array_in_39, Transpose_94_perm_to_use_array_in_39, 6, 7);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 12288))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 12288);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_40') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_40') start function
static void _ec_blob_cache_start_func_40(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 14336))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 28672))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 14336))) /* Equivalent hex address = 0x34203800UL */, 14336);

};


/* scheduling epoch=42   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_42(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 28672))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 43008))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 28672))) /* Equivalent hex address = 0x34207000UL */, 14336);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_96 */
  static const uint32_t Transpose_96_tensor_shape_in_42_shape_0[] = { 1, 16, 56, 16 };
  static const LL_LIB_TensorShape_TypeDef Transpose_96_tensor_shape_in_42[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 14336,
      .offset_end = 28672,
      .offset_limit = 28736,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_96_tensor_shape_in_42_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_96_tensor_axes_offsets_in_42_0[] = { 14336, 896, 16, 1 };
  static const uint32_t* Transpose_96_tensor_axes_offsets_in_42[] = {
    Transpose_96_tensor_axes_offsets_in_42_0
  };

  static const uint32_t Transpose_96_tensor_shape_out_42_shape_0[] = { 1, 56, 16, 16 };
  static const LL_LIB_TensorShape_TypeDef Transpose_96_tensor_shape_out_42[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 28672,
      .offset_end = 43008,
      .offset_limit = 43072,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_96_tensor_shape_out_42_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_96_tensor_axes_offsets_out_42_0[] = { 14336, 256, 16, 1 };
  static const uint32_t* Transpose_96_tensor_axes_offsets_out_42[] = {
    Transpose_96_tensor_axes_offsets_out_42_0
  };

  static const uint8_t Transpose_96_perm_to_use_array_in_42[] = { 0, 2, 1, 3 };
  static const uint8_t Transpose_96_target_pos_array_in_42[] = { 0, 2, 1, 3 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_96_tensor_shape_in_42[0], Transpose_96_tensor_axes_offsets_in_42[0], &Transpose_96_tensor_shape_out_42[0], Transpose_96_tensor_axes_offsets_out_42[0], Transpose_96_target_pos_array_in_42, Transpose_96_perm_to_use_array_in_42, 1, 4);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 28672))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 43008))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 28672))) /* Equivalent hex address = 0x34207000UL */, 14336);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_43') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_43') start function
static void _ec_blob_cache_start_func_43(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 28672))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 43008))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 28672))) /* Equivalent hex address = 0x34207000UL */, 14336);

};


/* scheduling epoch=45   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_45(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 14336))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 14336);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_108 */
  static const uint32_t Transpose_108_tensor_shape_in_45_shape_0[] = { 1, 16, 16, 56 };
  static const LL_LIB_TensorShape_TypeDef Transpose_108_tensor_shape_in_45[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 28672,
      .offset_end = 43008,
      .offset_limit = 43072,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_108_tensor_shape_in_45_shape_0,
      .batch = 56,
    }
  };

  static const uint32_t Transpose_108_tensor_axes_offsets_in_45_0[] = { 14336, 896, 56, 1 };
  static const uint32_t* Transpose_108_tensor_axes_offsets_in_45[] = {
    Transpose_108_tensor_axes_offsets_in_45_0
  };

  static const uint32_t Transpose_108_tensor_shape_out_45_shape_0[] = { 1, 56, 16, 16 };
  static const LL_LIB_TensorShape_TypeDef Transpose_108_tensor_shape_out_45[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 14336,
      .offset_limit = 14400,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_108_tensor_shape_out_45_shape_0,
      .batch = 16,
    }
  };

  static const uint32_t Transpose_108_tensor_axes_offsets_out_45_0[] = { 14336, 256, 16, 1 };
  static const uint32_t* Transpose_108_tensor_axes_offsets_out_45[] = {
    Transpose_108_tensor_axes_offsets_out_45_0
  };

  static const uint8_t Transpose_108_perm_to_use_array_in_45[] = { 0, 3, 2, 1 };
  static const uint8_t Transpose_108_target_pos_array_in_45[] = { 0, 3, 2, 1 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_108_tensor_shape_in_45[0], Transpose_108_tensor_axes_offsets_in_45[0], &Transpose_108_tensor_shape_out_45[0], Transpose_108_tensor_axes_offsets_out_45[0], Transpose_108_target_pos_array_in_45, Transpose_108_perm_to_use_array_in_45, 6, 7);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 14336))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 14336);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_46') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_46') start function
static void _ec_blob_cache_start_func_46(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 16384))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 16384);

};


/* scheduling epoch=48   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_48(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 16384))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 32768))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 16384))) /* Equivalent hex address = 0x34204000UL */, 16384);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_110 */
  static const uint32_t Transpose_110_tensor_shape_in_48_shape_0[] = { 1, 16, 64, 16 };
  static const LL_LIB_TensorShape_TypeDef Transpose_110_tensor_shape_in_48[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 16384,
      .offset_limit = 16448,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_110_tensor_shape_in_48_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_110_tensor_axes_offsets_in_48_0[] = { 16384, 1024, 16, 1 };
  static const uint32_t* Transpose_110_tensor_axes_offsets_in_48[] = {
    Transpose_110_tensor_axes_offsets_in_48_0
  };

  static const uint32_t Transpose_110_tensor_shape_out_48_shape_0[] = { 1, 64, 16, 16 };
  static const LL_LIB_TensorShape_TypeDef Transpose_110_tensor_shape_out_48[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 16384,
      .offset_end = 32768,
      .offset_limit = 32832,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_110_tensor_shape_out_48_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_110_tensor_axes_offsets_out_48_0[] = { 16384, 256, 16, 1 };
  static const uint32_t* Transpose_110_tensor_axes_offsets_out_48[] = {
    Transpose_110_tensor_axes_offsets_out_48_0
  };

  static const uint8_t Transpose_110_perm_to_use_array_in_48[] = { 0, 2, 1, 3 };
  static const uint8_t Transpose_110_target_pos_array_in_48[] = { 0, 2, 1, 3 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_110_tensor_shape_in_48[0], Transpose_110_tensor_axes_offsets_in_48[0], &Transpose_110_tensor_shape_out_48[0], Transpose_110_tensor_axes_offsets_out_48[0], Transpose_110_target_pos_array_in_48, Transpose_110_perm_to_use_array_in_48, 6, 7);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 16384))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 32768))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 16384))) /* Equivalent hex address = 0x34204000UL */, 16384);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_49') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_49') start function
static void _ec_blob_cache_start_func_49(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 16384))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 32768))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 16384))) /* Equivalent hex address = 0x34204000UL */, 16384);

};


/* scheduling epoch=51   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_51(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 16384))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 16384);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_122 */
  static const uint32_t Transpose_122_tensor_shape_in_51_shape_0[] = { 1, 16, 16, 64 };
  static const LL_LIB_TensorShape_TypeDef Transpose_122_tensor_shape_in_51[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 16384,
      .offset_end = 32768,
      .offset_limit = 32832,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_122_tensor_shape_in_51_shape_0,
      .batch = 64,
    }
  };

  static const uint32_t Transpose_122_tensor_axes_offsets_in_51_0[] = { 16384, 1024, 64, 1 };
  static const uint32_t* Transpose_122_tensor_axes_offsets_in_51[] = {
    Transpose_122_tensor_axes_offsets_in_51_0
  };

  static const uint32_t Transpose_122_tensor_shape_out_51_shape_0[] = { 1, 64, 16, 16 };
  static const LL_LIB_TensorShape_TypeDef Transpose_122_tensor_shape_out_51[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 16384,
      .offset_limit = 16448,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_122_tensor_shape_out_51_shape_0,
      .batch = 16,
    }
  };

  static const uint32_t Transpose_122_tensor_axes_offsets_out_51_0[] = { 16384, 256, 16, 1 };
  static const uint32_t* Transpose_122_tensor_axes_offsets_out_51[] = {
    Transpose_122_tensor_axes_offsets_out_51_0
  };

  static const uint8_t Transpose_122_perm_to_use_array_in_51[] = { 0, 3, 2, 1 };
  static const uint8_t Transpose_122_target_pos_array_in_51[] = { 0, 3, 2, 1 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_122_tensor_shape_in_51[0], Transpose_122_tensor_axes_offsets_in_51[0], &Transpose_122_tensor_shape_out_51[0], Transpose_122_tensor_axes_offsets_out_51[0], Transpose_122_target_pos_array_in_51, Transpose_122_perm_to_use_array_in_51, 2, 3);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 16384))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 16384);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_52') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_52') start function
static void _ec_blob_cache_start_func_52(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 18432))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 18432);

};


/* scheduling epoch=54   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_54(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 18432))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 36864))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 18432))) /* Equivalent hex address = 0x34204800UL */, 18432);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_124 */
  static const uint32_t Transpose_124_tensor_shape_in_54_shape_0[] = { 1, 16, 72, 16 };
  static const LL_LIB_TensorShape_TypeDef Transpose_124_tensor_shape_in_54[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 18432,
      .offset_limit = 18496,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_124_tensor_shape_in_54_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_124_tensor_axes_offsets_in_54_0[] = { 18432, 1152, 16, 1 };
  static const uint32_t* Transpose_124_tensor_axes_offsets_in_54[] = {
    Transpose_124_tensor_axes_offsets_in_54_0
  };

  static const uint32_t Transpose_124_tensor_shape_out_54_shape_0[] = { 1, 72, 16, 16 };
  static const LL_LIB_TensorShape_TypeDef Transpose_124_tensor_shape_out_54[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 18432,
      .offset_end = 36864,
      .offset_limit = 36928,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_124_tensor_shape_out_54_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_124_tensor_axes_offsets_out_54_0[] = { 18432, 256, 16, 1 };
  static const uint32_t* Transpose_124_tensor_axes_offsets_out_54[] = {
    Transpose_124_tensor_axes_offsets_out_54_0
  };

  static const uint8_t Transpose_124_perm_to_use_array_in_54[] = { 0, 2, 1, 3 };
  static const uint8_t Transpose_124_target_pos_array_in_54[] = { 0, 2, 1, 3 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_124_tensor_shape_in_54[0], Transpose_124_tensor_axes_offsets_in_54[0], &Transpose_124_tensor_shape_out_54[0], Transpose_124_tensor_axes_offsets_out_54[0], Transpose_124_target_pos_array_in_54, Transpose_124_perm_to_use_array_in_54, 2, 3);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 18432))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 36864))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 18432))) /* Equivalent hex address = 0x34204800UL */, 18432);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_55') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_55') start function
static void _ec_blob_cache_start_func_55(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 18432))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 36864))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 18432))) /* Equivalent hex address = 0x34204800UL */, 18432);

};


/* scheduling epoch=57   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_57(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 18432))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 18432);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_136 */
  static const uint32_t Transpose_136_tensor_shape_in_57_shape_0[] = { 1, 16, 16, 72 };
  static const LL_LIB_TensorShape_TypeDef Transpose_136_tensor_shape_in_57[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 18432,
      .offset_end = 36864,
      .offset_limit = 36928,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_136_tensor_shape_in_57_shape_0,
      .batch = 72,
    }
  };

  static const uint32_t Transpose_136_tensor_axes_offsets_in_57_0[] = { 18432, 1152, 72, 1 };
  static const uint32_t* Transpose_136_tensor_axes_offsets_in_57[] = {
    Transpose_136_tensor_axes_offsets_in_57_0
  };

  static const uint32_t Transpose_136_tensor_shape_out_57_shape_0[] = { 1, 72, 16, 16 };
  static const LL_LIB_TensorShape_TypeDef Transpose_136_tensor_shape_out_57[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 18432,
      .offset_limit = 18496,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_136_tensor_shape_out_57_shape_0,
      .batch = 16,
    }
  };

  static const uint32_t Transpose_136_tensor_axes_offsets_out_57_0[] = { 18432, 256, 16, 1 };
  static const uint32_t* Transpose_136_tensor_axes_offsets_out_57[] = {
    Transpose_136_tensor_axes_offsets_out_57_0
  };

  static const uint8_t Transpose_136_perm_to_use_array_in_57[] = { 0, 3, 2, 1 };
  static const uint8_t Transpose_136_target_pos_array_in_57[] = { 0, 3, 2, 1 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_136_tensor_shape_in_57[0], Transpose_136_tensor_axes_offsets_in_57[0], &Transpose_136_tensor_shape_out_57[0], Transpose_136_tensor_axes_offsets_out_57[0], Transpose_136_target_pos_array_in_57, Transpose_136_perm_to_use_array_in_57, 4, 5);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 18432))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 18432);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_58') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_58') start function
static void _ec_blob_cache_start_func_58(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 20480))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 40960))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 20480))) /* Equivalent hex address = 0x34205000UL */, 20480);

};


/* scheduling epoch=60   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_60(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 40960))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 61440))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 40960))) /* Equivalent hex address = 0x3420a000UL */, 20480);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_138 */
  static const uint32_t Transpose_138_tensor_shape_in_60_shape_0[] = { 1, 16, 80, 16 };
  static const LL_LIB_TensorShape_TypeDef Transpose_138_tensor_shape_in_60[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 20480,
      .offset_end = 40960,
      .offset_limit = 41024,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_138_tensor_shape_in_60_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_138_tensor_axes_offsets_in_60_0[] = { 20480, 1280, 16, 1 };
  static const uint32_t* Transpose_138_tensor_axes_offsets_in_60[] = {
    Transpose_138_tensor_axes_offsets_in_60_0
  };

  static const uint32_t Transpose_138_tensor_shape_out_60_shape_0[] = { 1, 80, 16, 16 };
  static const LL_LIB_TensorShape_TypeDef Transpose_138_tensor_shape_out_60[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 40960,
      .offset_end = 61440,
      .offset_limit = 61504,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_138_tensor_shape_out_60_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_138_tensor_axes_offsets_out_60_0[] = { 20480, 256, 16, 1 };
  static const uint32_t* Transpose_138_tensor_axes_offsets_out_60[] = {
    Transpose_138_tensor_axes_offsets_out_60_0
  };

  static const uint8_t Transpose_138_perm_to_use_array_in_60[] = { 0, 2, 1, 3 };
  static const uint8_t Transpose_138_target_pos_array_in_60[] = { 0, 2, 1, 3 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_138_tensor_shape_in_60[0], Transpose_138_tensor_axes_offsets_in_60[0], &Transpose_138_tensor_shape_out_60[0], Transpose_138_tensor_axes_offsets_out_60[0], Transpose_138_target_pos_array_in_60, Transpose_138_perm_to_use_array_in_60, 8, 9);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 40960))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 61440))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 40960))) /* Equivalent hex address = 0x3420a000UL */, 20480);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_61') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_61') start function
static void _ec_blob_cache_start_func_61(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 40960))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 61440))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 40960))) /* Equivalent hex address = 0x3420a000UL */, 20480);

};


/* scheduling epoch=63   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_63(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 20480))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 20480);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_150 */
  static const uint32_t Transpose_150_tensor_shape_in_63_shape_0[] = { 1, 16, 16, 80 };
  static const LL_LIB_TensorShape_TypeDef Transpose_150_tensor_shape_in_63[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 40960,
      .offset_end = 61440,
      .offset_limit = 61504,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_150_tensor_shape_in_63_shape_0,
      .batch = 80,
    }
  };

  static const uint32_t Transpose_150_tensor_axes_offsets_in_63_0[] = { 20480, 1280, 80, 1 };
  static const uint32_t* Transpose_150_tensor_axes_offsets_in_63[] = {
    Transpose_150_tensor_axes_offsets_in_63_0
  };

  static const uint32_t Transpose_150_tensor_shape_out_63_shape_0[] = { 1, 80, 16, 16 };
  static const LL_LIB_TensorShape_TypeDef Transpose_150_tensor_shape_out_63[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 20480,
      .offset_limit = 20544,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_150_tensor_shape_out_63_shape_0,
      .batch = 16,
    }
  };

  static const uint32_t Transpose_150_tensor_axes_offsets_out_63_0[] = { 20480, 256, 16, 1 };
  static const uint32_t* Transpose_150_tensor_axes_offsets_out_63[] = {
    Transpose_150_tensor_axes_offsets_out_63_0
  };

  static const uint8_t Transpose_150_perm_to_use_array_in_63[] = { 0, 3, 2, 1 };
  static const uint8_t Transpose_150_target_pos_array_in_63[] = { 0, 3, 2, 1 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_150_tensor_shape_in_63[0], Transpose_150_tensor_axes_offsets_in_63[0], &Transpose_150_tensor_shape_out_63[0], Transpose_150_tensor_axes_offsets_out_63[0], Transpose_150_target_pos_array_in_63, Transpose_150_perm_to_use_array_in_63, 6, 7);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 20480))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 20480);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_64') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_64') start function
static void _ec_blob_cache_start_func_64(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 22528))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 22528);

};


/* scheduling epoch=66   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_66(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 22528))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 45056))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 22528))) /* Equivalent hex address = 0x34205800UL */, 22528);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_152 */
  static const uint32_t Transpose_152_tensor_shape_in_66_shape_0[] = { 1, 16, 88, 16 };
  static const LL_LIB_TensorShape_TypeDef Transpose_152_tensor_shape_in_66[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 22528,
      .offset_limit = 22592,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_152_tensor_shape_in_66_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_152_tensor_axes_offsets_in_66_0[] = { 22528, 1408, 16, 1 };
  static const uint32_t* Transpose_152_tensor_axes_offsets_in_66[] = {
    Transpose_152_tensor_axes_offsets_in_66_0
  };

  static const uint32_t Transpose_152_tensor_shape_out_66_shape_0[] = { 1, 88, 16, 16 };
  static const LL_LIB_TensorShape_TypeDef Transpose_152_tensor_shape_out_66[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 22528,
      .offset_end = 45056,
      .offset_limit = 45120,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_152_tensor_shape_out_66_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_152_tensor_axes_offsets_out_66_0[] = { 22528, 256, 16, 1 };
  static const uint32_t* Transpose_152_tensor_axes_offsets_out_66[] = {
    Transpose_152_tensor_axes_offsets_out_66_0
  };

  static const uint8_t Transpose_152_perm_to_use_array_in_66[] = { 0, 2, 1, 3 };
  static const uint8_t Transpose_152_target_pos_array_in_66[] = { 0, 2, 1, 3 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_152_tensor_shape_in_66[0], Transpose_152_tensor_axes_offsets_in_66[0], &Transpose_152_tensor_shape_out_66[0], Transpose_152_tensor_axes_offsets_out_66[0], Transpose_152_target_pos_array_in_66, Transpose_152_perm_to_use_array_in_66, 6, 7);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 22528))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 45056))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 22528))) /* Equivalent hex address = 0x34205800UL */, 22528);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_67') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_67') start function
static void _ec_blob_cache_start_func_67(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 73216))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 78848))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 73216))) /* Equivalent hex address = 0x34211e00UL */, 5632);

};


/* scheduling epoch=70   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_70(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 5632))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 5632);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_172 */
  static const uint32_t Transpose_172_tensor_shape_in_70_shape_0[] = { 1, 8, 8, 88 };
  static const LL_LIB_TensorShape_TypeDef Transpose_172_tensor_shape_in_70[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 73216,
      .offset_end = 78848,
      .offset_limit = 78912,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_172_tensor_shape_in_70_shape_0,
      .batch = 88,
    }
  };

  static const uint32_t Transpose_172_tensor_axes_offsets_in_70_0[] = { 5632, 704, 88, 1 };
  static const uint32_t* Transpose_172_tensor_axes_offsets_in_70[] = {
    Transpose_172_tensor_axes_offsets_in_70_0
  };

  static const uint32_t Transpose_172_tensor_shape_out_70_shape_0[] = { 1, 88, 8, 8 };
  static const LL_LIB_TensorShape_TypeDef Transpose_172_tensor_shape_out_70[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 5632,
      .offset_limit = 5696,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_172_tensor_shape_out_70_shape_0,
      .batch = 8,
    }
  };

  static const uint32_t Transpose_172_tensor_axes_offsets_out_70_0[] = { 5632, 64, 8, 1 };
  static const uint32_t* Transpose_172_tensor_axes_offsets_out_70[] = {
    Transpose_172_tensor_axes_offsets_out_70_0
  };

  static const uint8_t Transpose_172_perm_to_use_array_in_70[] = { 0, 3, 2, 1 };
  static const uint8_t Transpose_172_target_pos_array_in_70[] = { 0, 3, 2, 1 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_172_tensor_shape_in_70[0], Transpose_172_tensor_axes_offsets_in_70[0], &Transpose_172_tensor_shape_out_70[0], Transpose_172_tensor_axes_offsets_out_70[0], Transpose_172_target_pos_array_in_70, Transpose_172_perm_to_use_array_in_70, 1, 2);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 5632))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 5632);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_71') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_71') start function
static void _ec_blob_cache_start_func_71(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 8192))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 14336))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 8192))) /* Equivalent hex address = 0x34202000UL */, 6144);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 40960))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 41472))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 40960))) /* Equivalent hex address = 0x3420a000UL */, 512);

};


/* scheduling epoch=74   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_74(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 16384))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 22528))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 16384))) /* Equivalent hex address = 0x34204000UL */, 6144);

  /* Reset the stream switch */
  LL_Switch_Init(NULL, 0);

/* Unit= 27 [PROCESSOR 0] */
/* kind=Transpose node=Transpose_174 */
  static const uint32_t Transpose_174_tensor_shape_in_74_shape_0[] = { 1, 8, 96, 8 };
  static const LL_LIB_TensorShape_TypeDef Transpose_174_tensor_shape_in_74[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 8192,
      .offset_end = 14336,
      .offset_limit = 14400,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_174_tensor_shape_in_74_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_174_tensor_axes_offsets_in_74_0[] = { 6144, 768, 8, 1 };
  static const uint32_t* Transpose_174_tensor_axes_offsets_in_74[] = {
    Transpose_174_tensor_axes_offsets_in_74_0
  };

  static const uint32_t Transpose_174_tensor_shape_out_74_shape_0[] = { 1, 96, 8, 8 };
  static const LL_LIB_TensorShape_TypeDef Transpose_174_tensor_shape_out_74[] = {
    {
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 16384,
      .offset_end = 22528,
      .offset_limit = 22592,
      .ndims = 4,
      .nbits = 8,
      .shape = Transpose_174_tensor_shape_out_74_shape_0,
      .batch = 1,
    }
  };

  static const uint32_t Transpose_174_tensor_axes_offsets_out_74_0[] = { 6144, 64, 8, 1 };
  static const uint32_t* Transpose_174_tensor_axes_offsets_out_74[] = {
    Transpose_174_tensor_axes_offsets_out_74_0
  };

  static const uint8_t Transpose_174_perm_to_use_array_in_74[] = { 0, 2, 1, 3 };
  static const uint8_t Transpose_174_target_pos_array_in_74[] = { 0, 2, 1, 3 };
  LL_ATON_LIB_DMA_Transpose(&Transpose_174_tensor_shape_in_74[0], Transpose_174_tensor_axes_offsets_in_74[0], &Transpose_174_tensor_shape_out_74[0], Transpose_174_tensor_axes_offsets_out_74[0], Transpose_174_target_pos_array_in_74, Transpose_174_perm_to_use_array_in_74, 1, 2);

  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 16384))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 22528))) */
  LL_ATON_Cache_MCU_Clean_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 16384))) /* Equivalent hex address = 0x34204000UL */, 6144);

}


// Epoch Controller Blob (name='_ec_blob_face_detector_75') micro instructions needed

// Epoch Controller Blob (name='_ec_blob_face_detector_75') start function
static void _ec_blob_cache_start_func_75(const void *epoch_block) {
  LL_ATON_LIB_UNUSED(epoch_block);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 14336))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 0))) /* Equivalent hex address = 0x34200000UL */, 14336);

  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 8 */
  /*     start: ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 32768))) */
  /*     end:   ((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 33152))) */
  LL_ATON_Cache_MCU_Invalidate_Range(((uintptr_t)(ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x34200000UL + 32768))) /* Equivalent hex address = 0x34208000UL */, 384);

};


/* scheduling DONE                 ------------------------------------------------------------------- */

const EpochBlock_ItemTypeDef *LL_ATON_EpochBlockItems_face_detector(void) {

  static const EpochBlock_ItemTypeDef ll_atonn_rt_epoch_block_array[] = {
    {
      .start_epoch_block = _ec_blob_cache_start_func_1,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_1),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_1 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 1,
      .last_epoch_num = 6,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_7,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 7,
      .last_epoch_num = 7,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_8,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_8),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_8 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 8,
      .last_epoch_num = 9,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_10,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 10,
      .last_epoch_num = 10,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_11,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_11),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_11 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 11,
      .last_epoch_num = 13,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_14,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 14,
      .last_epoch_num = 14,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_15,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_15),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_15 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 15,
      .last_epoch_num = 16,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_17,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 17,
      .last_epoch_num = 17,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_18,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_18),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_18 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 18,
      .last_epoch_num = 19,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_20,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 20,
      .last_epoch_num = 20,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_21,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_21),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_21 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 21,
      .last_epoch_num = 22,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_23,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 23,
      .last_epoch_num = 23,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_24,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_24),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_24 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 24,
      .last_epoch_num = 25,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_26,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 26,
      .last_epoch_num = 26,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_27,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_27),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_27 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 27,
      .last_epoch_num = 28,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_29,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 29,
      .last_epoch_num = 29,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_30,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_30),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_30 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 30,
      .last_epoch_num = 32,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_33,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 33,
      .last_epoch_num = 33,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_34,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_34),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_34 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 34,
      .last_epoch_num = 35,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_36,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 36,
      .last_epoch_num = 36,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_37,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_37),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_37 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 37,
      .last_epoch_num = 38,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_39,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 39,
      .last_epoch_num = 39,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_40,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_40),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_40 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 40,
      .last_epoch_num = 41,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_42,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 42,
      .last_epoch_num = 42,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_43,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_43),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_43 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 43,
      .last_epoch_num = 44,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_45,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 45,
      .last_epoch_num = 45,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_46,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_46),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_46 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 46,
      .last_epoch_num = 47,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_48,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 48,
      .last_epoch_num = 48,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_49,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_49),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_49 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 49,
      .last_epoch_num = 50,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_51,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 51,
      .last_epoch_num = 51,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_52,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_52),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_52 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 52,
      .last_epoch_num = 53,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_54,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 54,
      .last_epoch_num = 54,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_55,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_55),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_55 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 55,
      .last_epoch_num = 56,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_57,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 57,
      .last_epoch_num = 57,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_58,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_58),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_58 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 58,
      .last_epoch_num = 59,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_60,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 60,
      .last_epoch_num = 60,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_61,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_61),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_61 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 61,
      .last_epoch_num = 62,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_63,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 63,
      .last_epoch_num = 63,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_64,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_64),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_64 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 64,
      .last_epoch_num = 65,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_66,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 66,
      .last_epoch_num = 66,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_67,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_67),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_67 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 67,
      .last_epoch_num = 69,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_70,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 70,
      .last_epoch_num = 70,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_71,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_71),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_71 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 71,
      .last_epoch_num = 73,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_74,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_hybrid,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 74,
      .last_epoch_num = 74,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = _ec_blob_cache_start_func_75,
      .end_epoch_block = NULL,
      .blob_address = (uintptr_t)(_ec_blob_face_detector_75),
      .wait_mask = 0,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_blob | EpochBlock_Flags_pure_hw | (LL_ATON_EC_MustDecryptBlob_face_detector__ec_blob_face_detector_75 ? EpochBlock_Flags_blob_encrypted : EpochBlock_Flags_NONE),
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 75,
      .last_epoch_num = 89,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .flags = EpochBlock_Flags_last_eb,
    },
  };


  return ll_atonn_rt_epoch_block_array;
}

const LL_Buffer_InfoTypeDef *LL_ATON_Input_Buffers_Info_face_detector(void)
{
  static const uint32_t buff_info__shape_1_128_128_3[] = { 1, 128, 3, 128 };
  static const uint32_t buff_info__mem_shape_F_1_128_128_3[] = { 1, 128, 128, 3 };
  static const float buff_info_Input_0_out_0_quant_scale[] = { 0.00392156885936856 };
  static const int16_t buff_info_Input_0_out_0_quant_offset[] = { 0 };
#if LL_ATON_DBG_BUFFER_INFO_EXCLUDED == 0
  static const uint32_t buff_info__shape_24_24_1_1[] = { 24, 1, 1, 24 };
  static const uint32_t buff_info__mem_shape_F_24_24_1_1[] = { 24, 24, 1, 1 };
  static const float buff_info_Conv2D_15_weights_quant_scale[] = { 0.00537109375, 0.00596318300813437, 0.00508273858577013, 0.00260672974400222, 0.00500199943780899, 0.00295467837713659, 0.0026528665330261, 0.00896592065691948, 0.00655527180060744, 0.0136564960703254, 0.0056709828786552, 0.00564022501930594, 0.0124415596947074, 0.0025009997189045, 0.00350832007825375, 0.0044560469686985, 0.005005843937397, 0.00313730305060744, 0.0068359375, 0.00354868965223432, 0.00722810020670295, 0.00468288641422987, 0.0062207798473537, 0.00406388426199555 };
  static const int16_t buff_info_Conv2D_15_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_28_24_1_1[] = { 28, 1, 1, 24 };
  static const uint32_t buff_info__mem_shape_F_28_24_1_1[] = { 28, 24, 1, 1 };
  static const float buff_info_Conv2D_29_weights_quant_scale[] = { 0.00170033366885036, 0.00239911419339478, 0.00232798652723432, 0.00271053775213659, 0.00331800570711493, 0.0021376721560955, 0.00172532454598695, 0.00663216644898057, 0.00227223802357912, 0.00419076019898057, 0.00215689581818879, 0.00408695265650749, 0.0046944203786552, 0.0018175981240347, 0.00233375374227762, 0.00187623035162687, 0.00252599036321044, 0.00350832007825375, 0.00234528793953359, 0.000926580978557467, 0.00116303213872015, 0.002320297062397, 0.00243756151758134, 0.00274129561148584, 0.00218188669532537, 0.00252214563079178, 0.00236835633404553, 0.00305656366981566 };
  static const int16_t buff_info_Conv2D_29_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_28_1_3_3[] = { 28, 3, 3, 1 };
  static const uint32_t buff_info__mem_shape_F_28_1_3_3[] = { 28, 1, 3, 3 };
  static const float buff_info_Conv2D_37_weights_quant_scale[] = { 0.0204693656414747, 0.015255905687809, 0.0111574186012149, 0.0131489913910627, 0.00871216785162687, 0.0112958289682865, 0.0159172005951405, 0.00673597445711493, 0.0170552413910627, 0.0116726132109761, 0.0189929865300655, 0.00981176178902388, 0.0107037397101521, 0.016962967813015, 0.0149329481646419, 0.0191160179674625, 0.0148714324459434, 0.0117033710703254, 0.00808932073414326, 0.0133950542658567, 0.017085999250412, 0.0163170527666807, 0.0153097314760089, 0.0107344975695014, 0.0149560160934925, 0.0154481418430805, 0.0257750991731882, 0.0107421875 };
  static const int16_t buff_info_Conv2D_37_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_32_28_1_1[] = { 32, 1, 1, 28 };
  static const uint32_t buff_info__mem_shape_M14_32_28_1_1[] = { 32, 2, 1, 1, 14 };
  static const float buff_info_Conv2D_40_weights_quant_scale[] = { 0.00196369807235897, 0.00208000116981566, 0.00153308780863881, 0.000970795401372015, 0.00164650741498917, 0.00295467837713659, 0.00276051927357912, 0.00143312464933842, 0.00127452937886119, 0.00183682178612798, 0.00336029776372015, 0.0025913508143276, 0.00182336522266269, 0.00129952013958246, 0.00202617491595447, 0.00117072160355747, 0.00146003777626902, 0.00546336732804775, 0.000563734152819961, 0.00115438143257052, 0.00281242304481566, 0.00248177605681121, 0.00275859679095447, 0.00198965007439256, 0.000919852696824819, 0.00188584218267351, 0.00175992713775486, 0.000617079844232649, 0.00111497298348695, 0.00155038910452276, 0.000498373701702803, 0.000989057938568294 };
  static const int16_t buff_info_Conv2D_40_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_36_32_1_1[] = { 36, 1, 1, 32 };
  static const uint32_t buff_info__mem_shape_M16_36_32_1_1[] = { 36, 2, 1, 1, 16 };
  static const float buff_info_Conv2D_58_weights_quant_scale[] = { 0.00137929839547724, 0.00318920705467463, 0.00123896566219628, 0.000768466270528734, 0.0019050658447668, 0.00106114661321044, 0.00150425231549889, 0.00190891057718545, 0.00134181219618767, 0.00211268151178956, 0.0022299459669739, 0.00229338393546641, 0.00235489965416491, 0.000888133596163243, 0.00123704329598695, 0.00173493637703359, 0.000824695511255413, 0.00697819283232093, 0.000680517987348139, 0.00081460305955261, 0.00137737602926791, 0.00159652589354664, 0.00152155361138284, 0.00200887373648584, 0.00105730188079178, 0.00131201557815075, 0.000869871117174625, 0.00196562032215297, 0.00096262531587854, 0.00101885455660522, 0.000931386894080788, 0.00118610053323209, 0.000923697429243475, 0.000570943055208772, 0.000827098439913243, 0.000857375736813992 };
  static const int16_t buff_info_Conv2D_58_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_36_1_3_3[] = { 36, 3, 3, 1 };
  static const uint32_t buff_info__mem_shape_F_36_1_3_3[] = { 36, 1, 3, 3 };
  static const float buff_info_Conv2D_69_weights_quant_scale[] = { 0.0128029650077224, 0.0147253321483731, 0.00867372006177902, 0.0121493600308895, 0.0100578246638179, 0.014525406062603, 0.0118648502975702, 0.0137180117890239, 0.010011687874794, 0.0113957924768329, 0.0133719854056835, 0.0118187135085464, 0.0148329846560955, 0.0143562378361821, 0.00765102123841643, 0.00925043039023876, 0.0149098793044686, 0.0206077750772238, 0.0112189343199134, 0.0127952760085464, 0.015871062874794, 0.00892747286707163, 0.015132874250412, 0.016486220061779, 0.0126261068508029, 0.0210999008268118, 0.0150482896715403, 0.0137795275077224, 0.0170706193894148, 0.0132028171792626, 0.018685407936573, 0.0180241148918867, 0.0177626721560955, 0.0208230800926685, 0.0162555370479822, 0.019638903439045 };
  static const int16_t buff_info_Conv2D_69_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_42_36_1_1[] = { 42, 1, 1, 36 };
  static const uint32_t buff_info__mem_shape_M18_42_36_1_1[] = { 42, 2, 1, 1, 18 };
  static const float buff_info_Conv2D_72_weights_quant_scale[] = { 0.00120532419532537, 0.00218380894511938, 0.00112458481453359, 0.00105634075589478, 0.00201848545111716, 0.00209538009949028, 0.00135815236717463, 0.00206462224014103, 0.00206269999034703, 0.00119282875675708, 0.00214920635335147, 0.00159748713485897, 0.00282780197449028, 0.00142255169339478, 0.00166284758597612, 0.00161094369832426, 0.000881405314430594, 0.00270477053709328, 0.00118033343460411, 0.00141486222855747, 0.00185316195711493, 0.00200887373648584, 0.00107748678419739, 0.00278935465030372, 0.00100924272555858, 0.00114861433394253, 0.0013427734375, 0.00128798594232649, 0.00117841106839478, 0.00227416027337313, 0.00151482527144253, 0.00124473276082426, 0.00129183067474514, 0.00050942727830261, 0.00113996374420822, 0.000764140917453915, 0.000777597480919212, 0.000572865421418101, 0.000908318441361189, 0.000438059418229386, 0.00048347533447668, 0.0013091319706291 };
  static const int16_t buff_info_Conv2D_72_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_42_1_3_3[] = { 42, 3, 3, 1 };
  static const uint32_t buff_info__mem_shape_F_42_1_3_3[] = { 42, 1, 3, 3 };
  static const float buff_info_Conv2D_80_weights_quant_scale[] = { 0.0108037032186985, 0.0147330220788717, 0.0122647024691105, 0.00798935815691948, 0.0148329846560955, 0.010503813624382, 0.0116649232804775, 0.021853469312191, 0.00950418319553137, 0.0170398615300655, 0.0112958289682865, 0.010980561375618, 0.015855684876442, 0.0103115774691105, 0.0152712846174836, 0.0138102853670716, 0.0149483270943165, 0.0164554622024298, 0.0115188239142299, 0.0129875121638179, 0.0160402320325375, 0.013433501124382, 0.0102269928902388, 0.0097041092813015, 0.019408218562603, 0.0186238922178745, 0.0104884346947074, 0.0131489913910627, 0.0155173474922776, 0.00953494105488062, 0.0185162406414747, 0.0126568647101521, 0.017209030687809, 0.0249292571097612, 0.017209030687809, 0.0217611957341433, 0.018439345061779, 0.0227454472333193, 0.0281126964837313, 0.0260826777666807, 0.0296044535934925, 0.0302042327821255 };
  static const int16_t buff_info_Conv2D_80_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_48_42_1_1[] = { 48, 1, 1, 42 };
  static const uint32_t buff_info__mem_shape_M21_48_42_1_1[] = { 48, 2, 1, 1, 21 };
  static const float buff_info_Conv2D_83_weights_quant_scale[] = { 0.000936192809604108, 0.00134373467881233, 0.00130240374710411, 0.000594492012169212, 0.00136007473338395, 0.00107075844425708, 0.00142831879202276, 0.00138891022652388, 0.00125146098434925, 0.00097175658447668, 0.00137353129684925, 0.0018175981240347, 0.00114092486910522, 0.000713198212906718, 0.00094147928757593, 0.00161863316316158, 0.000792015227489173, 0.000849205651320517, 0.00098329083994031, 0.000979446107521653, 0.000775194552261382, 0.00104576768353581, 0.000861701089888811, 0.00187334674410522, 0.00171955744735897, 0.000855453370604664, 0.00108805974014103, 0.00123896566219628, 0.00144562008790672, 0.00133796746376902, 0.00150713580660522, 0.00121493602637202, 0.000965508865192533, 0.000734344241209328, 0.000787209311965853, 0.00067619263427332, 0.000608429196290672, 0.000683401536662132, 0.00127452937886119, 0.000719926494639367, 0.000667061365675181, 0.000913604977540672, 0.000744436692912132, 0.000420758093241602, 0.000757893256377429, 0.000778558664023876, 0.000752606720197946, 0.000581035448703915 };
  static const int16_t buff_info_Conv2D_83_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_56_48_1_1[] = { 56, 1, 1, 48 };
  static const uint32_t buff_info__mem_shape_F_56_48_1_1[] = { 56, 48, 1, 1 };
  static const float buff_info_Conv2D_101_weights_quant_scale[] = { 0.00117072160355747, 0.00186757964547724, 0.00157730223145336, 0.000935231626499444, 0.002320297062397, 0.00190987170208246, 0.000781922833994031, 0.000920813879929483, 0.00154462200589478, 0.00101116509176791, 0.00164554629009217, 0.00123512092977762, 0.00170706200879067, 0.000928503344766796, 0.00120147946290672, 0.00181375339161605, 0.00130240374710411, 0.000671867339406163, 0.00121781951747835, 0.00114380847662687, 0.00131009321194142, 0.00111881771590561, 0.00105345714837313, 0.00186277378816158, 0.00130240374710411, 0.00148695101961493, 0.00182432634755969, 0.00117937219329178, 0.00105537951458246, 0.00146388250868767, 0.000874677032697946, 0.00160998245701194, 0.00219918810762465, 0.000535859842784703, 0.00106114661321044, 0.000805471849162132, 0.00075837381882593, 0.000700222211889923, 0.000728577142581344, 0.000754529086407274, 0.00107364205177873, 0.000521922658663243, 0.000558447674848139, 0.000561811786610633, 0.000457042769994587, 0.000654085422866046, 0.0010236605303362, 0.000607468013186008, 0.000393124064430594, 0.000404417980462313, 0.000506063166540116, 0.000613715732470155, 0.000315989105729386, 0.00058920553419739, 0.000362606486305594, 0.000300129555398598 };
  static const int16_t buff_info_Conv2D_101_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_64_56_1_1[] = { 64, 1, 1, 56 };
  static const uint32_t buff_info__mem_shape_M14_64_56_1_1[] = { 64, 4, 1, 1, 14 };
  static const float buff_info_Conv2D_115_weights_quant_scale[] = { 0.00108613737393171, 0.00131586031056941, 0.00162536138668656, 0.000980407232418656, 0.00265478901565075, 0.00115053670015186, 0.00185027834959328, 0.002320297062397, 0.00154846673831344, 0.0010371170938015, 0.00332185043953359, 0.00174070347566158, 0.000709834042936563, 0.00114284723531455, 0.00242602732032537, 0.00241641537286341, 0.000925619795452803, 0.00123031495604664, 0.00131778267677873, 0.00123127619735897, 0.00100539799313992, 0.00123223732225597, 0.00114765320904553, 0.0011591874063015, 0.00187719147652388, 0.00168495473917574, 0.00191467767581344, 0.00286624929867685, 0.00203770911321044, 0.00131682143546641, 0.00103038875386119, 0.00264902180060744, 0.00201656320132315, 0.00107556441798806, 0.000860739906784147, 0.000806913594715297, 0.000996747403405607, 0.00109959405381233, 0.00166957580950111, 0.000747800804674625, 0.00145811541005969, 0.0010236605303362, 0.000952532922383398, 0.000712237029802054, 0.000577190716285259, 0.000766543904319406, 0.00143793062306941, 0.00104288419242948, 0.000712237029802054, 0.00053537922212854, 0.00118129455950111, 0.000837671454064548, 0.000489723053760827, 0.00052336446242407, 0.000485157390357926, 0.000425323727540672, 0.000253271864494309, 0.00112266244832426, 0.000376783951651305, 0.000304214598145336, 0.000125915044918656, 0.000303974287817255, 0.00052817037794739, 0.000360924430424348 };
  static const int16_t buff_info_Conv2D_115_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_72_64_1_1[] = { 72, 1, 1, 64 };
  static const uint32_t buff_info__mem_shape_M16_72_64_1_1[] = { 72, 4, 1, 1, 16 };
  static const float buff_info_Conv2D_129_weights_quant_scale[] = { 0.00238565751351416, 0.00276436400599778, 0.00172436330467463, 0.0017974132206291, 0.000722329423297197, 0.00218573142774403, 0.00202809739857912, 0.00185989018063992, 0.00138698786031455, 0.00173685874324292, 0.000935712188947946, 0.00258173909969628, 0.000494528969284147, 0.00299312570132315, 0.000289316260023043, 0.00132354977540672, 0.00181086978409439, 0.00109767157118767, 0.00131105433683842, 0.00136776419822127, 0.00104576768353581, 0.00169456657022238, 0.0018925704061985, 0.00222417875193059, 0.000990980304777622, 0.00344103714451194, 0.00219342089258134, 0.00274129561148584, 0.002074234187603, 0.000956858217250556, 0.00120916892774403, 0.00131682143546641, 0.00155231147073209, 0.00155903969425708, 0.00157441862393171, 0.00102654402144253, 0.000766063283663243, 0.000923216808587313, 0.00144562008790672, 0.000921775063034147, 0.00193486246280372, 0.0012543445918709, 0.000668983731884509, 0.00324303330853581, 0.00213959463872015, 0.00139659969136119, 0.000991941429674625, 0.00121109129395336, 0.00126683991402388, 0.000490203616209328, 0.00122454785741866, 0.0020146407186985, 0.00074635905912146, 0.00101693219039589, 0.000945324019994587, 0.000591127900406718, 0.000405379163566977, 0.000808835960924625, 0.000991941429674625, 0.000569501251447946, 0.000219390145502985, 0.000596894999034703, 0.000489002151880413, 0.000723290606401861, 0.00068532390287146, 0.019777312874794, 0.000592089083511382, 0.000348429050063714, 0.000617560464888811, 0.000193798638065346, 0.000461127812741324, 0.000315508514177054 };
  static const int16_t buff_info_Conv2D_129_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_80_72_1_1[] = { 80, 1, 1, 72 };
  static const uint32_t buff_info__mem_shape_M24_80_72_1_1[] = { 80, 3, 1, 1, 24 };
  static const float buff_info_Conv2D_143_weights_quant_scale[] = { 0.00173589750193059, 0.00171186798252165, 0.00220111035741866, 0.0028681717813015, 0.00109959405381233, 0.00287970597855747, 0.00372746982611716, 0.00171379034873098, 0.00218380894511938, 0.00199349480681121, 0.000788170495070517, 0.00342950294725597, 0.00107556441798806, 0.00141293986234814, 0.00070646993117407, 0.00296429009176791, 0.00137064780574292, 0.00188295857515186, 0.000909279624465853, 0.00296621257439256, 0.00176857772748917, 0.00345449382439256, 0.00230299588292837, 0.0023798905313015, 0.00154366076458246, 0.00237796804867685, 0.002320297062397, 0.00131489906925708, 0.00220687757246196, 0.00136488070711493, 0.00244717346504331, 0.00226647080853581, 0.00201848545111716, 0.00179645209573209, 0.00254713650792837, 0.00148022267967463, 0.00139179383404553, 0.00144658121280372, 0.00334876356646419, 0.00139756093267351, 0.00238950224593282, 0.00185220071580261, 0.00130048138089478, 0.00105249602347612, 0.00188584218267351, 0.000784806383308023, 0.0010236605303362, 0.00202233018353581, 0.00152251473627985, 0.000676673254929483, 0.0012543445918709, 0.00158499169629067, 0.000775194552261382, 0.00191179406829178, 0.000635342323221266, 0.00176569423638284, 0.000449113023933023, 0.0010246216552332, 0.00146580499131233, 0.00065264361910522, 0.000364769162843004, 0.000742994889151305, 0.00116495450492948, 0.000969834218267351, 0.00142159045208246, 0.00148310628719628, 0.000529612123500556, 0.00088957539992407, 0.000678115000482649, 0.000494528969284147, 0.000892939511686563, 0.00037798544508405, 0.000206414173590019, 0.000364048260962591, 0.000374380993889645, 0.000267929921392351, 0.000687726831529289, 0.000143576791742817, 0.000428447587182745, 0.000251349498284981 };
  static const int16_t buff_info_Conv2D_143_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_88_80_1_1[] = { 88, 1, 1, 80 };
  static const uint32_t buff_info__mem_shape_M20_88_80_1_1[] = { 88, 4, 1, 1, 20 };
  static const float buff_info_Conv2D_157_weights_quant_scale[] = { 0.00313345831818879, 0.00223186821676791, 0.00244140625, 0.00204924331046641, 0.00171571271494031, 0.000707431114278734, 0.00316421617753804, 0.00190891057718545, 0.00186950201168656, 0.00218188669532537, 0.00256828241981566, 0.00239334697835147, 0.00110439991112798, 0.00146772735752165, 0.00048828125, 0.00184066651854664, 0.00208384590223432, 0.00199349480681121, 0.00147733918856829, 0.0012812577188015, 0.00401774747297168, 0.00219149840995669, 0.00139371620025486, 0.00320458598434925, 0.0012543445918709, 0.00222610123455524, 0.00248946552164853, 0.000765102100558579, 0.0012543445918709, 0.000660333083942533, 0.00295467837713659, 0.0013293168740347, 0.00267209019511938, 0.0014167845947668, 0.0027739757206291, 0.000775675114709884, 0.00140140566509217, 0.00143889174796641, 0.00165804161224514, 0.00181471451651305, 0.00195889221504331, 0.00281434552744031, 0.00169745017774403, 0.00262787588872015, 0.00317190564237535, 0.00186181254684925, 0.00186181254684925, 0.00185316195711493, 0.000448632432380691, 0.00136199709959328, 0.000632939394563437, 0.00273552839644253, 0.00138506549410522, 0.0015869140625, 0.000658891338389367, 0.00176088826265186, 0.000791534665040672, 0.00108133151661605, 0.00167245941702276, 0.000702625198755413, 0.00115438143257052, 0.00096262531587854, 0.000780000467784703, 0.00214536162093282, 0.00138602673541754, 0.00178107316605747, 0.0011591874063015, 0.00065264361910522, 0.00136584183201194, 0.000628614041488618, 0.000728096521925181, 0.00242794957011938, 0.000654565985314548, 0.000393844966311008, 0.000991941429674625, 0.000817006046418101, 0.00092033325927332, 0.000367652712156996, 0.000454639812232926, 0.000485637981910259, 0.000334491865942255, 0.00034746786695905, 0.000598336744587868, 0.000388077867683023, 0.000293881865218282, 0.000439741474110633, 0.000730018888134509, 0.000515194376930594 };
  static const int16_t buff_info_Conv2D_157_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_96_88_1_1[] = { 96, 1, 1, 88 };
  static const uint32_t buff_info__mem_shape_M22_96_88_1_1[] = { 96, 4, 1, 1, 22 };
  static const float buff_info_Conv2D_168_weights_quant_scale[] = { 0.000151025960803963, 0.000684362719766796, 0.000444547389633954, 0.00102269928902388, 0.000700222211889923, 0.000495009531732649, 0.000754529086407274, 0.000519039109349251, 0.000617560464888811, 0.000221793103264645, 0.000925139174796641, 0.000467615813249722, 0.000301811640383676, 0.000807874777819961, 0.000282587978290394, 0.000654565985314548, 0.000776636297814548, 0.00098329083994031, 0.000396968825953081, 0.000331368035404012, 0.000656007789075375, 0.000725212972611189, 0.000474824686534703, 0.000447430938947946, 0.000242458554566838, 0.000656968972180039, 0.00113035191316158, 0.000582477252464741, 0.000786248128861189, 0.000581035448703915, 0.000646395958028734, 0.000756932073272765, 0.00175896589644253, 0.000689168635290116, 0.000830462609883398, 0.000619963393546641, 0.00069253274705261, 0.000573826604522765, 0.000896303681656718, 0.000669464352540672, 0.00106306897941977, 0.00047890970017761, 0.000436377333244309, 0.000705989310517907, 0.000548835785593837, 0.000671867339406163, 0.000619482831098139, 0.000420517812017351, 0.000161478834343143, 0.000399612064938992, 0.000219270004890859, 0.000797782384324819, 0.000296765414532274, 0.000915046723093837, 0.000418835727032274, 0.000444787699962035, 0.000457763671875, 0.000382310769055039, 0.000377745134755969, 0.000561811786610633, 0.00042244017822668, 0.00048587829223834, 0.000606026209425181, 0.000193197891348973, 0.000466174038592726, 0.000607948575634509, 0.000656007789075375, 0.000248225667746738, 0.000470259052235633, 0.000271774653811008, 0.000551719393115491, 0.000517597363796085, 0.000221072215936147, 0.000255674822255969, 0.000522403279319406, 0.000389519642340019, 0.000319112936267629, 0.000218068526010029, 0.000390480825444683, 0.000261441920883954, 0.00029820718918927, 0.000304935470921919, 0.000331608316628262, 0.000293641583994031, 0.000649279507342726, 0.000240416033193469, 0.000409464206313714, 0.000187791243661195, 0.000215064821531996, 9.51571710174903e-05, 0.000568540068343282, 0.00032872476731427, 0.000491164799313992, 0.000473382911877707, 0.000270813470706344, 0.000210499201784842 };
  static const int16_t buff_info_Conv2D_168_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_96_96_1_1[] = { 96, 1, 1, 96 };
  static const uint32_t buff_info__mem_shape_M24_96_96_1_1[] = { 96, 4, 1, 1, 24 };
  static const float buff_info_Conv2D_183_weights_quant_scale[] = { 0.000696377479471266, 0.00115053670015186, 0.000724732410162687, 0.00107652554288507, 0.000769908016081899, 0.00095061055617407, 0.000371978036127985, 0.000716562324669212, 0.000824695511255413, 0.000425564008764923, 0.00103231112007052, 0.000970795401372015, 0.00030061014695093, 0.000970795401372015, 0.000416192488046363, 0.000820850778836757, 0.000846322102006525, 0.000782403396442533, 0.00057526835007593, 0.00100155326072127, 0.0010649913456291, 0.000556044687982649, 0.000650721252895892, 0.000499334884807467, 0.00043902060133405, 0.00161959428805858, 0.00159844825975597, 0.000988096697255969, 0.000821331341285259, 0.000203891060664319, 0.00056325359037146, 0.00167245941702276, 0.00149560160934925, 0.00102269928902388, 0.00176377187017351, 0.000970795401372015, 0.000930425710976124, 0.00150617468170822, 0.000513752631377429, 0.00144658121280372, 0.0015253983438015, 0.000764140917453915, 0.000685804465319961, 0.0010236605303362, 0.00102654402144253, 0.00138891022652388, 0.000441423559095711, 0.000646876520477235, 0.000284510344499722, 0.000666100182570517, 0.000201007511350326, 0.000755970890168101, 0.000577671336941421, 0.000883327680639923, 0.000546913419384509, 0.00104769004974514, 0.000296525133308023, 0.000407782121328637, 0.000838632637169212, 0.000790573481936008, 0.00080739421537146, 0.000369575078366324, 0.000582957814913243, 0.000384713726816699, 0.000457042769994587, 0.000475064967758954, 0.000749242608435452, 0.000438780291005969, 0.000823734328150749, 0.000267209019511938, 0.000544029870070517, 0.000943882274441421, 0.000349870824720711, 0.000374380993889645, 0.000578632520046085, 0.000718965311534703, 0.000861701089888811, 0.00062909466214478, 0.000800665933638811, 0.000397930009057745, 0.000268410512944683, 0.000731941254343837, 0.000495970714837313, 0.000320795021252707, 0.000898226047866046, 0.000200647074962035, 0.000495970714837313, 0.000935712188947946, 0.000850647455081344, 9.52172485995106e-05, 0.000758854439482093, 0.000239094413700514, 0.000477708235848695, 0.000823253707494587, 0.00046473226393573, 0.000361885613529012 };
  static const int16_t buff_info_Conv2D_183_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const float buff_info_Conv2D_194_weights_quant_scale[] = { 0.00128798594232649, 0.00110343878623098, 0.000652163056656718, 0.00169168307911605, 0.000721848860848695, 0.000544029870070517, 0.0013908325927332, 0.00150521344039589, 0.00269323633983731, 0.000734344241209328, 0.00130048138089478, 0.000475064967758954, 0.000472662009997293, 0.000935231626499444, 0.000728577142581344, 0.00148310628719628, 0.00060554564697668, 0.000949168752413243, 0.000716562324669212, 0.000928983907215297, 8.45240792841651e-05, 0.000741553143598139, 0.00126972352154553, 0.000865065201651305, 9.36553260544315e-05, 0.000331848626956344, 0.000755490269511938, 0.00081220013089478, 0.000678595621138811, 0.000678115000482649, 0.00109478808008134, 0.00138602673541754, 0.000709834042936563, 0.00221072230488062, 0.00113131303805858, 0.000948688189964741, 0.000776155735366046, 0.000821331341285259, 0.000597856182139367, 0.00138698786031455, 0.000967911852058023, 0.00038975992356427, 0.000806913594715297, 0.000846322102006525, 0.00126395642291754, 0.000656968972180039, 0.00142159045208246, 0.000984251964837313, 0.000286913302261382, 0.000801146496087313, 0.000176377187017351, 0.000522403279319406, 0.000264085188973695, 0.00124569388572127, 0.00101308745797724, 0.000730980071239173, 0.000748761987779289, 0.00105537951458246, 0.000582477252464741, 0.00154942786321044, 0.00117648870218545, 0.000545471673831344, 0.00146868848241866, 0.00106595258694142, 0.000933309260290116, 0.00126683991402388, 0.000871312920935452, 0.000491885701194406, 0.000933789822738618, 0.000958300021011382, 0.000830462609883398, 0.0010246216552332, 0.00112266244832426, 0.000809316581580788, 0.00102173816412687, 0.000585841364227235, 0.000197042623767629, 0.000638706493191421, 0.000853050383739173, 0.000334251584718004, 0.000572384800761938, 0.000494048348627985, 0.000315748795401305, 0.000368133303709328, 0.000691571563947946, 0.000762218551244587, 0.000359963247319683, 0.000439501192886382, 0.000294602767098695, 0.000398650881834328, 0.000482754432596266, 0.000478429108625278, 0.000361885613529012, 0.000620924576651305, 0.000396247924072668, 0.000559889420401305 };
  static const int16_t buff_info_Conv2D_194_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const float buff_info_Conv2D_205_weights_quant_scale[] = { 0.000322717387462035, 0.000624769309069961, 0.000439501192886382, 0.00179837446194142, 0.000935231626499444, 0.00188680330757052, 0.000756932073272765, 0.00146292138379067, 0.00167149817571044, 0.000680037366691977, 0.000327042711433023, 0.00126011169049889, 0.000382070458726957, 0.000112518551759422, 0.000518077926244587, 0.000420517812017351, 0.00102654402144253, 0.0020146407186985, 0.00075356790330261, 0.000462088995845988, 0.000263124005869031, 0.000692052184604108, 0.000949649373069406, 0.000663216633256525, 0.0008544921875, 0.000558447674848139, 0.000681479170452803, 0.000486599165014923, 0.00082854024367407, 0.00111881771590561, 0.00127164588775486, 0.000469057587906718, 0.000457283080322668, 0.00134661816991866, 0.00230299588292837, 0.000965989485848695, 0.00206077750772238, 0.000866026384755969, 0.00184547249227762, 0.00132354977540672, 0.000682440353557467, 0.00126107281539589, 0.00158787530381233, 0.000818928412627429, 0.00164266268257052, 0.000413068628404289, 0.00130048138089478, 0.000466174038592726, 0.000742514326702803, 0.00034266195143573, 0.000454880122561008, 0.00042484313598834, 0.000928022724110633, 0.000819889595732093, 0.00116399326361716, 0.000436377333244309, 0.000743475509807467, 0.000293641583994031, 0.000105730192444753, 0.00101789343170822, 0.000569981872104108, 0.000286192400380969, 0.00161190482322127, 0.00138122076168656, 0.000636784126982093, 0.000524806207977235, 0.000945804640650749, 0.00204347632825375, 0.000521442096214741, 0.000348669331287965, 0.00111016700975597, 0.00129759777337313, 0.000250868906732649, 0.00169456657022238, 0.00127837411127985, 0.000941959908232093, 0.000126635932247154, 0.00110151642002165, 0.000807874777819961, 0.000423881952883676, 0.000751645537093282, 0.000661774887703359, 0.000320795021252707, 0.00140525039751083, 0.000429889361839741, 0.000320554710924625, 0.000599297927692533, 0.000273456709692255, 0.00122935383114964, 0.000406340346671641, 0.000998669769614935, 0.000227440061280504, 0.000797301763668656, 0.000427486404078081, 0.00101597106549889, 0.000344344007316977 };
  static const int16_t buff_info_Conv2D_205_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const float buff_info_Conv2D_216_weights_quant_scale[] = { 0.000503179617226124, 0.000672828522510827, 0.00171955744735897, 0.00118321692571044, 0.000973678950686008, 0.00421382859349251, 0.000238493666984141, 0.0012543445918709, 0.000658410717733204, 0.000989057938568294, 1.55891957547283e-05, 0.00125626695808023, 0.00121685839258134, 0.000638706493191421, 0.00142255169339478, 0.00131393794436008, 0.000207976088859141, 0.000902551342733204, 0.000784325762651861, 0.000512310827616602, 2.46753843384795e-05, 0.0016205555293709, 0.0014513871865347, 0.00122935383114964, 0.000213022300158627, 0.000756932073272765, 0.00118994526565075, 0.00260865222662687, 0.00107556441798806, 0.000284510344499722, 0.00156096206046641, 0.000433974375482649, 0.000583438435569406, 0.00466366251930594, 0.00226647080853581, 0.00050221843412146, 0.000501737813465297, 4.47250713477843e-05, 0.00212998269125819, 0.000581035448703915, 0.000725693593267351, 0.000519519730005413, 0.00117072160355747, 0.00156288442667574, 0.002074234187603, 0.000178059257450514, 0.00185989018063992, 0.000638225872535259, 0.00102173816412687, 0.000444307108409703, 0.000133244073367678, 0.00128606357611716, 0.000175295848748647, 0.000755009707063437, 0.000590647279750556, 0.000154750552610494, 0.00286048231646419, 8.98706639418378e-05, 0.00042027750168927, 0.000543068686965853, 0.00127452937886119, 4.10605607612524e-05, 0.00302003882825375, 0.000785286945756525, 0.000785286945756525, 0.000574787787627429, 0.00122166436631233, 0.00299504795111716, 0.0010236605303362, 0.000506063166540116, 0.00244140625, 0.00420229462906718, 0.00148022267967463, 0.00148983451072127, 0.00281626777723432, 0.00297390203922987, 7.17883958714083e-05, 0.00202617491595447, 0.000266968738287687, 0.00163977919146419, 0.000275859696557745, 0.0035679133143276, 0.000919852696824819, 0.00215881830081344, 0.000332329218508676, 0.00107652554288507, 0.00119378999806941, 0.000931386894080788, 0.000869390554726124, 0.000918410893063992, 0.00231453008018434, 0.000299168372293934, 0.000560850603505969, 0.000797301763668656, 0.00195696973241866, 0.00103615585248917 };
  static const int16_t buff_info_Conv2D_216_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__mem_shape_F_96_96_1_1[] = { 96, 96, 1, 1 };
  static const float buff_info_Conv2D_223_weights_quant_scale[] = { 0.0341104827821255, 0.0376168787479401, 0.092273622751236, 0.0922121033072472, 0.0473363697528839, 0.0417999513447285, 0.0301119592040777, 0.0335260815918446, 0.04419906437397, 0.0375553630292416, 0.044568158686161, 0.034541092813015, 0.0850147604942322, 0.0561946369707584, 0.0579170770943165, 0.0543799214065075, 0.0390625, 0.0383858270943165, 0.079970471560955, 0.0799089595675468, 0.0533956699073315, 0.0441683083772659, 0.0350024588406086, 0.0365403555333614, 0.0487819872796535, 0.0369402058422565, 0.049673967063427, 0.0377399101853371, 0.084830217063427, 0.0680364146828651, 0.063115157186985, 0.0679749026894569, 0.0396469011902809, 0.044076032936573, 0.0877214595675468, 0.0877214595675468, 0.059947095811367, 0.0451218001544476, 0.0379859730601311, 0.0390932597219944, 0.0536109730601311, 0.0401082672178745, 0.055425688624382, 0.039677657186985, 0.0908587574958801, 0.0785556137561798, 0.0680979341268539, 0.0800935029983521, 0.049304872751236, 0.0535187013447285, 0.102116145193577, 0.102054625749588, 0.0666830688714981, 0.0502276085317135, 0.0553334169089794, 0.0410002470016479, 0.0558255426585674, 0.0425688959658146, 0.059578001499176, 0.0440452769398689, 0.0981176197528839, 0.086183562874794, 0.0855068862438202, 0.087536908686161, 0.0691436976194382, 0.0545952245593071, 0.119340553879738, 0.119340553879738, 0.0752952769398689, 0.0600393712520599, 0.0747416317462921, 0.0541030988097191, 0.0847686976194382, 0.049427904188633, 0.0779404491186142, 0.0492433570325375, 0.0980561003088951, 0.0846456661820412, 0.0981791317462921, 0.091904528439045, 0.087290845811367, 0.0607468001544476, 0.111774116754532, 0.112204723060131, 0.0853838548064232, 0.0603777058422565, 0.104207679629326, 0.055302657186985, 0.100762791931629, 0.0557640269398689, 0.0877214595675468, 0.0508735254406929, 0.0769561976194382, 0.0791707709431648, 0.0824926197528839, 0.0868602395057678 };
  static const int16_t buff_info_Conv2D_223_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_6_96_1_1[] = { 6, 1, 1, 96 };
  static const uint32_t buff_info__mem_shape_M24_6_96_1_1[] = { 6, 4, 1, 1, 24 };
  static const float buff_info_Conv2D_231_weights_quant_scale[] = { 0.161417320370674, 0.185900583863258, 0.20103345811367, 0.213459640741348, 0.298228353261948, 0.237204730510712 };
  static const int16_t buff_info_Conv2D_231_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_32_88_1_1[] = { 32, 1, 1, 88 };
  static const uint32_t buff_info__mem_shape_M22_32_88_1_1[] = { 32, 4, 1, 1, 22 };
  static const float buff_info_Conv2D_239_weights_quant_scale[] = { 0.0203001964837313, 0.028451032936573, 0.0322650112211704, 0.0322650112211704, 0.0385088585317135, 0.0419229827821255, 0.0257289614528418, 0.0283433813601732, 0.0339566916227341, 0.0331262312829494, 0.0271745808422565, 0.0353407971560955, 0.0446296744048595, 0.0453678630292416, 0.052134595811367, 0.0431532971560955, 0.025990404188633, 0.0270361714065075, 0.0538877956569195, 0.0538877956569195, 0.051396407186985, 0.0292814951390028, 0.0274360235780478, 0.037463091313839, 0.0346333645284176, 0.0444758869707584, 0.0289739165455103, 0.0487512312829494, 0.0544106774032116, 0.054318405687809, 0.0591166354715824, 0.0477054640650749 };
  static const int16_t buff_info_Conv2D_239_weights_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_2_88_1_1[] = { 2, 1, 1, 88 };
  static const uint32_t buff_info__mem_shape_M22_2_88_1_1[] = { 2, 4, 1, 1, 22 };
  static const float buff_info_Conv2D_247_weights_quant_scale[] = { 0.0129183074459434, 0.0156788267195225 };
  static const int16_t buff_info_Conv2D_247_weights_quant_offset[] = { 0, 0 };
  static const uint32_t buff_info__shape_24_8_3_3[] = { 24, 3, 3, 8 };
  static const uint32_t buff_info__mem_shape_L_24_8_3_3[] = { 24, 3, 3, 8 };
  static const float buff_info_Conv2D_12_weights_inflated_331_quant_scale[] = { 0.00792784243822098, 0.0128721706569195, 0.0108267720788717, 0.0187315456569195, 0.010619156062603, 0.0172551665455103, 0.0149329481646419, 0.0204386077821255, 0.0225455220788717, 0.0327571369707584, 0.0116495443508029, 0.0189468506723642, 0.0203617122024298, 0.0156173100695014, 0.013056717813015, 0.0134796379134059, 0.0152789736166596, 0.020007997751236, 0.011841781437397, 0.0151251843199134, 0.0145177161321044, 0.0237297005951405, 0.025636687874794, 0.0175166092813015 };
  static const int16_t buff_info_Conv2D_12_weights_inflated_331_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const float buff_info_Conv2D_26_weights_inflated_333_quant_scale[] = { 0.0348179116845131, 0.0150636686012149, 0.0185931343585253, 0.0174858514219522, 0.0127106914296746, 0.0152251478284597, 0.0107344975695014, 0.0137487696483731, 0.0150406006723642, 0.0110343871638179, 0.0116649232804775, 0.00798166822642088, 0.0103423353284597, 0.0156480688601732, 0.0268054865300655, 0.0135411536321044, 0.0129798231646419, 0.0155481053516269, 0.00770484749227762, 0.0105960872024298, 0.0145792318508029, 0.0227608270943165, 0.0149329481646419, 0.0122570125386119 };
  static const int16_t buff_info_Conv2D_26_weights_inflated_333_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_32_8_3_3[] = { 32, 3, 3, 8 };
  static const uint32_t buff_info__mem_shape_L_32_8_3_3[] = { 32, 3, 3, 8 };
  static const float buff_info_Conv2D_55_weights_inflated_336_quant_scale[] = { 0.0120724653825164, 0.0107344975695014, 0.0110574560239911, 0.010003998875618, 0.0137026328593493, 0.017332062125206, 0.015625, 0.0114496182650328, 0.0105807082727551, 0.0191006399691105, 0.0208999756723642, 0.020515501499176, 0.0149944638833404, 0.0149560160934925, 0.00941190961748362, 0.0220226384699345, 0.0115649607032537, 0.0097733149304986, 0.0115342028439045, 0.0161478836089373, 0.0126722436398268, 0.0108882877975702, 0.02806656062603, 0.0242064464837313, 0.0148406745865941, 0.0171936508268118, 0.0182547979056835, 0.0141947586089373, 0.0254213828593493, 0.0234990157186985, 0.0227454472333193, 0.0189007129520178 };
  static const int16_t buff_info_Conv2D_55_weights_inflated_336_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_48_8_3_3[] = { 48, 3, 3, 8 };
  static const uint32_t buff_info__mem_shape_L_48_8_3_3[] = { 48, 3, 3, 8 };
  static const float buff_info_Conv2D_98_weights_inflated_340_quant_scale[] = { 0.0101424092426896, 0.00825848896056414, 0.0154635207727551, 0.00877368357032537, 0.0183316934853792, 0.0182855557650328, 0.010988250374794, 0.0123646650463343, 0.0180087350308895, 0.0128721706569195, 0.00792784243822098, 0.00991941429674625, 0.0174858514219522, 0.0132720228284597, 0.0114034814760089, 0.0110343871638179, 0.00858144648373127, 0.0115265129134059, 0.0192698072642088, 0.0154942786321044, 0.0147560900077224, 0.0146868852898479, 0.011234313249588, 0.00993479322642088, 0.00920429360121489, 0.0121416710317135, 0.0123108392581344, 0.0124876964837313, 0.0117956446483731, 0.021484375, 0.0177319142967463, 0.0157095845788717, 0.0130413388833404, 0.018931470811367, 0.0130951646715403, 0.0155481053516269, 0.017209030687809, 0.0181471463292837, 0.0179010834544897, 0.0314499251544476, 0.0156403798609972, 0.0191006399691105, 0.0194389764219522, 0.0268054865300655, 0.0224840063601732, 0.0233759842813015, 0.026128813624382, 0.030511811375618 };
  static const int16_t buff_info_Conv2D_98_weights_inflated_340_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_56_8_3_3[] = { 56, 3, 3, 8 };
  static const uint32_t buff_info__mem_shape_L_56_8_3_3[] = { 56, 3, 3, 8 };
  static const float buff_info_Conv2D_112_weights_inflated_342_quant_scale[] = { 0.015871062874794, 0.00848148390650749, 0.0128491017967463, 0.0078740157186985, 0.015732653439045, 0.0116264764219522, 0.00956569891422987, 0.0157787892967463, 0.0154250739142299, 0.00887364707887173, 0.0121570499613881, 0.0111574186012149, 0.0130336489528418, 0.00759335001930594, 0.0154865896329284, 0.017808809876442, 0.0132797118276358, 0.0242679622024298, 0.021592028439045, 0.00961183570325375, 0.0114265503361821, 0.0114265503361821, 0.0114034814760089, 0.0113650346174836, 0.0277589820325375, 0.00851224176585674, 0.0138794910162687, 0.0117264399304986, 0.011834092438221, 0.0143331689760089, 0.0089812995865941, 0.0138718010857701, 0.0148714324459434, 0.016716904938221, 0.0192236714065075, 0.0108344610780478, 0.0139563856646419, 0.012818343937397, 0.0112035553902388, 0.0185777563601732, 0.0117264399304986, 0.0169168300926685, 0.0250061508268118, 0.0194543544203043, 0.0149944638833404, 0.0236220471560955, 0.0169168300926685, 0.020023375749588, 0.0195004921406507, 0.0312653779983521, 0.0149252582341433, 0.0215612705796957, 0.0323880426585674, 0.029665969312191, 0.0210845228284597, 0.0232990887016058 };
  static const int16_t buff_info_Conv2D_112_weights_inflated_342_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_64_8_3_3[] = { 64, 3, 3, 8 };
  static const uint32_t buff_info__mem_shape_L_64_8_3_3[] = { 64, 3, 3, 8 };
  static const float buff_info_Conv2D_126_weights_inflated_344_quant_scale[] = { 0.0124723175540566, 0.0114111714065075, 0.0122877703979611, 0.00815852638334036, 0.0215612705796957, 0.0104730557650328, 0.00911970995366573, 0.0118264025077224, 0.0132028171792626, 0.0128337228670716, 0.0195004921406507, 0.0102961985394359, 0.0262057092040777, 0.0182701777666807, 0.0320189483463764, 0.0117110600695014, 0.02416031062603, 0.017931841313839, 0.017347440123558, 0.0066513903439045, 0.0147022642195225, 0.00582092767581344, 0.00855068862438202, 0.0133258486166596, 0.0190852601081133, 0.0123415971174836, 0.0109574925154448, 0.0179164614528418, 0.00713198212906718, 0.0139871435239911, 0.0116649232804775, 0.0189007129520178, 0.0125876599922776, 0.013556532561779, 0.0113265868276358, 0.0106883607804775, 0.0136103592813015, 0.0180394928902388, 0.0101039614528418, 0.015740342438221, 0.0127030024304986, 0.011103592813015, 0.0164554622024298, 0.0135334646329284, 0.0140717271715403, 0.0253752451390028, 0.0232990887016058, 0.0149637060239911, 0.0189776085317135, 0.0294968020170927, 0.0184547249227762, 0.0152328368276358, 0.0314653068780899, 0.0195466298609972, 0.018070250749588, 0.022591657936573, 0.0338336601853371, 0.017824187874794, 0.0166861470788717, 0.0301734749227762, 0.0460445359349251, 0.0251753199845552, 0.0205923970788717, 0.0237758364528418 };
  static const int16_t buff_info_Conv2D_126_weights_inflated_344_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_72_8_3_3[] = { 72, 3, 3, 8 };
  static const uint32_t buff_info__mem_shape_L_72_8_3_3[] = { 72, 3, 3, 8 };
  static const float buff_info_Conv2D_140_weights_inflated_346_quant_scale[] = { 0.0120032606646419, 0.0104346089065075, 0.00653989287093282, 0.0108267720788717, 0.0261903293430805, 0.0180394928902388, 0.0072588580660522, 0.027835875749588, 0.00862758327275515, 0.00893516279757023, 0.0181010086089373, 0.00845072604715824, 0.020869217813015, 0.011472687125206, 0.0320189483463764, 0.0148099167272449, 0.0205923970788717, 0.0115803396329284, 0.0117879556491971, 0.0112189343199134, 0.00915815681219101, 0.0167937986552715, 0.00915046781301498, 0.00810469966381788, 0.0168706942349672, 0.00994248315691948, 0.019177533686161, 0.0320189483463764, 0.0213459637016058, 0.0237758364528418, 0.0079970471560955, 0.0133412275463343, 0.0180394928902388, 0.00760103948414326, 0.00686285085976124, 0.010626845061779, 0.0134950168430805, 0.0169322099536657, 0.0147099532186985, 0.00791246350854635, 0.0100808935239911, 0.0120493974536657, 0.0141409328207374, 0.0122185656800866, 0.0118187135085464, 0.0202386807650328, 0.0208538379520178, 0.008666031062603, 0.0207154285162687, 0.0169937256723642, 0.0175935048609972, 0.013310469686985, 0.0195158701390028, 0.0159325785934925, 0.0177319142967463, 0.0175627451390028, 0.0234836377203465, 0.0189776085317135, 0.0220226384699345, 0.0217919535934925, 0.0282818656414747, 0.0126799335703254, 0.0205770172178745, 0.021730437874794, 0.0191467758268118, 0.0401390269398689, 0.030388779938221, 0.0347563959658146, 0.020623154938221, 0.0187776815146208, 0.0208384599536657, 0.029896654188633 };
  static const int16_t buff_info_Conv2D_140_weights_inflated_346_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_80_8_3_3[] = { 80, 3, 3, 8 };
  static const uint32_t buff_info__mem_shape_L_80_8_3_3[] = { 80, 3, 3, 8 };
  static const float buff_info_Conv2D_154_weights_inflated_348_quant_scale[] = { 0.0107498774304986, 0.020869217813015, 0.00725501356646419, 0.00591704621911049, 0.0156788267195225, 0.0113112078979611, 0.0156019311398268, 0.0157095845788717, 0.00737804500386119, 0.0267593506723642, 0.0115034449845552, 0.022960752248764, 0.0138025963678956, 0.0108882877975702, 0.0304502956569195, 0.0192082915455103, 0.0132335750386119, 0.009642593562603, 0.0124031128361821, 0.00528266467154026, 0.0116649232804775, 0.0238219741731882, 0.0160402320325375, 0.0184547249227762, 0.0246985722333193, 0.00679364521056414, 0.0136872539296746, 0.012579970061779, 0.0102808196097612, 0.025882750749588, 0.0198234505951405, 0.0100655145943165, 0.00933501496911049, 0.00527882017195225, 0.00638610357418656, 0.0100808935239911, 0.00941959861665964, 0.00961183570325375, 0.0141793796792626, 0.0130797857418656, 0.0216843020170927, 0.0115342028439045, 0.025267593562603, 0.00936577282845974, 0.0175166092813015, 0.00802780501544476, 0.0243756156414747, 0.00917353574186563, 0.0306809786707163, 0.0232529528439045, 0.0254060048609972, 0.0144946482032537, 0.0252983514219522, 0.0119955707341433, 0.0199464820325375, 0.00933501496911049, 0.0223763529211283, 0.024544782936573, 0.0155250364914536, 0.012579970061779, 0.013794906437397, 0.0175319872796535, 0.0113650346174836, 0.025621309876442, 0.0141870696097612, 0.0183778293430805, 0.0133566064760089, 0.0165015999227762, 0.0127798970788717, 0.0208999756723642, 0.0252522137016058, 0.0156480688601732, 0.0459215044975281, 0.0252368357032537, 0.0255597941577435, 0.0357406511902809, 0.0284664127975702, 0.025636687874794, 0.0379244573414326, 0.028189592063427 };
  static const int16_t buff_info_Conv2D_154_weights_inflated_348_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_88_8_3_3[] = { 88, 3, 3, 8 };
  static const uint32_t buff_info__mem_shape_L_88_8_3_3[] = { 88, 3, 3, 8 };
  static const float buff_info_Conv2D_165_weights_inflated_350_quant_scale[] = { 0.0130490278825164, 0.0124031128361821, 0.0216227862983942, 0.0152020789682865, 0.0192544292658567, 0.0104884346947074, 0.0111727975308895, 0.0110882138833404, 0.0191006399691105, 0.00922736246138811, 0.0232375729829073, 0.0153020424768329, 0.0431532971560955, 0.00737420050427318, 0.0199926178902388, 0.0157634112983942, 0.0353100411593914, 0.0143101010471582, 0.0154558317735791, 0.0153404893353581, 0.0124953864142299, 0.0121954968199134, 0.0166553892195225, 0.0127568282186985, 0.0158403050154448, 0.0106422239914536, 0.0101654771715403, 0.018423967063427, 0.018193282186985, 0.028189592063427, 0.0124953864142299, 0.0178549457341433, 0.0138794910162687, 0.0135642224922776, 0.0125030754134059, 0.0135027067735791, 0.0227454472333193, 0.00721272127702832, 0.027466781437397, 0.0108190821483731, 0.035525344312191, 0.0143024111166596, 0.028558686375618, 0.0151174953207374, 0.0146407475695014, 0.00951187219470739, 0.0107575664296746, 0.0237604584544897, 0.025021530687809, 0.0201925449073315, 0.0276513285934925, 0.0166861470788717, 0.0110190082341433, 0.0150559796020389, 0.0234375, 0.0136641850695014, 0.020992249250412, 0.0310962107032537, 0.0426919274032116, 0.0179933570325375, 0.00921967253088951, 0.0224071107804775, 0.0143562378361821, 0.0111189717426896, 0.0381705202162266, 0.0175473671406507, 0.013179749250412, 0.0227454472333193, 0.0141255538910627, 0.0187469236552715, 0.024790845811367, 0.00931963603943586, 0.0193313229829073, 0.0198080707341433, 0.0324187986552715, 0.018423967063427, 0.0165477357804775, 0.0185316186398268, 0.0204232279211283, 0.0218688491731882, 0.0335260815918446, 0.0294352862983942, 0.0160709898918867, 0.0282357279211283, 0.0193467028439045, 0.0435531511902809, 0.033679872751236, 0.0174243357032537 };
  static const int16_t buff_info_Conv2D_165_weights_inflated_350_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_96_8_3_3[] = { 96, 3, 3, 8 };
  static const uint32_t buff_info__mem_shape_L_96_8_3_3[] = { 96, 3, 3, 8 };
  static const float buff_info_Conv2D_180_weights_inflated_352_quant_scale[] = { 0.0256059300154448, 0.0191313978284597, 0.0110728349536657, 0.0128491017967463, 0.0305579472333193, 0.0234682578593493, 0.028435654938221, 0.0204847436398268, 0.0104346089065075, 0.0146561274304986, 0.0244832672178745, 0.018439345061779, 0.0213459637016058, 0.00841996818780899, 0.0266516972333193, 0.0101962350308895, 0.0217919535934925, 0.0135334646329284, 0.0138256642967463, 0.0149713950231671, 0.00950418319553137, 0.0165169779211283, 0.0290815699845552, 0.0190237443894148, 0.0294352862983942, 0.0139794535934925, 0.0175473671406507, 0.0241449307650328, 0.0247139520943165, 0.0273129921406507, 0.0199157241731882, 0.0096349036321044, 0.0141255538910627, 0.0101193403825164, 0.0199772398918867, 0.0154096949845552, 0.0213305857032537, 0.0137487696483731, 0.0270207915455103, 0.017824187874794, 0.0152482157573104, 0.0251906979829073, 0.0368479341268539, 0.0128875495865941, 0.00848917290568352, 0.00985789857804775, 0.024406373500824, 0.0312807597219944, 0.0237758364528418, 0.0196081455796957, 0.019054502248764, 0.0116418553516269, 0.0122954603284597, 0.016363188624382, 0.015978716313839, 0.021715059876442, 0.0201925449073315, 0.020869217813015, 0.056163877248764, 0.0142255164682865, 0.0223917327821255, 0.0167784206569195, 0.0248677413910627, 0.021007627248764, 0.0241449307650328, 0.0156711377203465, 0.0173166822642088, 0.0243294779211283, 0.019654281437397, 0.0143024111166596, 0.0206077750772238, 0.00978869386017323, 0.017470471560955, 0.0169937256723642, 0.0218842271715403, 0.0195466298609972, 0.0139410067349672, 0.017455093562603, 0.0253752451390028, 0.018562376499176, 0.0320189483463764, 0.0318959169089794, 0.0202079229056835, 0.030880905687809, 0.0372785441577435, 0.029912032186985, 0.019285187125206, 0.032849408686161, 0.0344488173723221, 0.0314037911593914, 0.0263133607804775, 0.0292199794203043, 0.0341412387788296, 0.0264363922178745, 0.0272053387016058, 0.0336183570325375 };
  static const int16_t buff_info_Conv2D_180_weights_inflated_352_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const float buff_info_Conv2D_191_weights_inflated_354_quant_scale[] = { 0.040784940123558, 0.011226624250412, 0.0155711732804775, 0.0201617870479822, 0.0151174953207374, 0.011357344686985, 0.0174243357032537, 0.0174397137016058, 0.00833538360893726, 0.0155404154211283, 0.0232683308422565, 0.01171875, 0.0235143955796957, 0.0102193038910627, 0.0227915849536657, 0.0203155763447285, 0.0159172005951405, 0.0149098793044686, 0.0407234244048595, 0.0308501478284597, 0.0124646285548806, 0.0151636321097612, 0.0182701777666807, 0.027097687125206, 0.0131951281800866, 0.0338336601853371, 0.0287739913910627, 0.0224071107804775, 0.0257750991731882, 0.019654281437397, 0.0121186021715403, 0.0120570864528418, 0.019884966313839, 0.014410063624382, 0.0272514764219522, 0.0125569021329284, 0.0281126964837313, 0.00905050430446863, 0.024652436375618, 0.0198542084544897, 0.0118264025077224, 0.0223763529211283, 0.0162862949073315, 0.0161940213292837, 0.0134027432650328, 0.0143024111166596, 0.0150559796020389, 0.0203617122024298, 0.019285187125206, 0.0194697342813015, 0.012203186750412, 0.0264056343585253, 0.00985789857804775, 0.0140486592426896, 0.0146407475695014, 0.0255444142967463, 0.01685531437397, 0.0276051927357912, 0.015978716313839, 0.0188545770943165, 0.02220718562603, 0.018793061375618, 0.019777312874794, 0.0114496182650328, 0.0147407110780478, 0.0153097314760089, 0.0185316186398268, 0.0194389764219522, 0.0166553892195225, 0.0387549214065075, 0.0255290362983942, 0.0196850392967463, 0.0388779528439045, 0.00517885712906718, 0.026251845061779, 0.0243602357804775, 0.0477669797837734, 0.0291123278439045, 0.0183316934853792, 0.027712844312191, 0.0238988678902388, 0.0373093001544476, 0.020884595811367, 0.0223148372024298, 0.0250984244048595, 0.034418061375618, 0.0174243357032537, 0.0237297005951405, 0.0239757634699345, 0.0303118843585253, 0.0303580220788717, 0.0221610479056835, 0.0332492627203465, 0.0199464820325375, 0.0148714324459434, 0.0298043806105852 };
  static const int16_t buff_info_Conv2D_191_weights_inflated_354_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const float buff_info_Conv2D_202_weights_inflated_356_quant_scale[] = { 0.0175166092813015, 0.0108729088678956, 0.0113419657573104, 0.0258519928902388, 0.0189622286707163, 0.00996555108577013, 0.0180394928902388, 0.0181163884699345, 0.03125, 0.0152174578979611, 0.028697095811367, 0.0131643703207374, 0.032726377248764, 0.0216535441577435, 0.0170552413910627, 0.0292661171406507, 0.0309577994048595, 0.02271468937397, 0.0150944264605641, 0.0175935048609972, 0.0145484739914536, 0.00870447792112827, 0.0193159449845552, 0.0148329846560955, 0.0208999756723642, 0.023191437125206, 0.021115280687809, 0.0119186760857701, 0.023806594312191, 0.0370324812829494, 0.0400159955024719, 0.025021530687809, 0.0340182073414326, 0.011357344686985, 0.015386626124382, 0.0136334272101521, 0.019162155687809, 0.0189929865300655, 0.0101962350308895, 0.017824187874794, 0.0251291822642088, 0.015732653439045, 0.0246985722333193, 0.0296352114528418, 0.0228684786707163, 0.0187776815146208, 0.0231145415455103, 0.032972440123558, 0.02466781437397, 0.020638532936573, 0.0356791354715824, 0.0222533214837313, 0.0354638285934925, 0.0309731792658567, 0.019638903439045, 0.0161325056105852, 0.0070204846560955, 0.00909664109349251, 0.0159172005951405, 0.0286355800926685, 0.00858913641422987, 0.0360789857804775, 0.0122339446097612, 0.0331877470016479, 0.0221764277666807, 0.022330217063427, 0.0332185029983521, 0.0111497296020389, 0.0294968020170927, 0.0159479584544897, 0.018670029938221, 0.011480376124382, 0.0145715428516269, 0.0249753929674625, 0.016593873500824, 0.0110805239528418, 0.0154096949845552, 0.022699311375618, 0.0172551665455103, 0.020269438624382, 0.0233606044203043, 0.0157941691577435, 0.0140486592426896, 0.0163170527666807, 0.0136872539296746, 0.0251906979829073, 0.0164554622024298, 0.0119417449459434, 0.0150713585317135, 0.0253291092813015, 0.0323265269398689, 0.0255905520170927, 0.016363188624382, 0.0323880426585674, 0.0186546500772238, 0.0203309543430805 };
  static const int16_t buff_info_Conv2D_202_weights_inflated_356_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const float buff_info_Conv2D_213_weights_inflated_358_quant_scale[] = { 0.0364173240959644, 0.0101424092426896, 0.0195466298609972, 0.017685778439045, 0.0295583177357912, 0.00960414577275515, 0.0116879921406507, 0.016716904938221, 0.00745878461748362, 0.0108190821483731, 0.0218996070325375, 0.00465981801971793, 0.017101377248764, 0.00844303611665964, 0.0101577881723642, 0.0171936508268118, 0.0326956212520599, 0.00547490175813437, 0.0124876964837313, 0.0165784936398268, 0.0238373521715403, 0.025036908686161, 0.0126491757109761, 0.0101577881723642, 0.0273591298609972, 0.0232375729829073, 0.0164247043430805, 0.00693590054288507, 0.0244986470788717, 0.0188238192349672, 0.00881982035934925, 0.0486281998455524, 0.0319266729056835, 0.00208769063465297, 0.019408218562603, 0.0319574326276779, 0.0407541841268539, 0.0443528555333614, 0.110051676630974, 0.0302042327821255, 0.0135872904211283, 0.025159940123558, 0.0139717645943165, 0.0445989184081554, 0.00521730445325375, 0.0158095471560955, 0.0168860722333193, 0.0120109496638179, 0.0324495583772659, 0.0369402058422565, 0.0105345714837313, 0.0156480688601732, 0.017701156437397, 0.0181010086089373, 0.0153404893353581, 0.0217611957341433, 0.00602854322642088, 0.0204232279211283, 0.0265132877975702, 0.0343257859349251, 0.00416384730488062, 0.0173781979829073, 0.010619156062603, 0.0191006399691105, 0.0204847436398268, 0.0115342028439045, 0.0171782728284597, 0.0146023007109761, 0.0108959767967463, 0.01830093562603, 0.016363188624382, 0.024175688624382, 0.0053672487847507, 0.00974255613982677, 0.013064406812191, 0.0068320925347507, 0.023668184876442, 0.017808809876442, 0.04419906437397, 0.0125876599922776, 0.0088505782186985, 0.00941959861665964, 0.0142255164682865, 0.00575941195711493, 0.0238834898918867, 0.0107344975695014, 0.0141486218199134, 0.00902743637561798, 0.013056717813015, 0.00679364521056414, 0.0156634468585253, 0.0293122548609972, 0.0103577142581344, 0.0416461601853371, 0.020377092063427, 0.0133950542658567 };
  static const int16_t buff_info_Conv2D_213_weights_inflated_358_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_24_3_3_5[] = { 24, 3, 5, 3 };
  static const uint32_t buff_info__mem_shape_L_24_3_3_5[] = { 24, 3, 5, 3 };
  static const float buff_info_Conv2D_7_weights_submask_0_0_0_0_24_3_3_5_359_quant_scale[] = { 0.000811238947790116, 0.00246062991209328, 0.00414462340995669, 0.000956377654802054, 0.00227800500579178, 0.00298351375386119, 0.000748761987779289, 0.00179645209573209, 0.00637841410934925, 0.00352946599014103, 0.00258750608190894, 0.00528650963678956, 0.00362558430060744, 0.00339682260528207, 0.00133700633887202, 0.00178684026468545, 0.000908318441361189, 0.000773272186052054, 0.00127164588775486, 0.00104576768353581, 0.00127164588775486, 0.00617464305832982, 0.00164266268257052, 0.0031411477830261 };
  static const int16_t buff_info_Conv2D_7_weights_submask_0_0_0_0_24_3_3_5_359_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_24_3_2_5[] = { 24, 2, 5, 3 };
  static const uint32_t buff_info__mem_shape_L_24_3_2_5[] = { 24, 2, 5, 3 };
  static const float buff_info_Conv2D_7_weights_submask_0_0_3_0_24_3_2_5_360_quant_scale[] = { 0.000811238947790116, 0.00246062991209328, 0.00414462340995669, 0.000956377654802054, 0.00227800500579178, 0.00298351375386119, 0.000748761987779289, 0.00179645209573209, 0.00637841410934925, 0.00352946599014103, 0.00258750608190894, 0.00528650963678956, 0.00362558430060744, 0.00339682260528207, 0.00133700633887202, 0.00178684026468545, 0.000908318441361189, 0.000773272186052054, 0.00127164588775486, 0.00104576768353581, 0.00127164588775486, 0.00617464305832982, 0.00164266268257052, 0.0031411477830261 };
  static const int16_t buff_info_Conv2D_7_weights_submask_0_0_3_0_24_3_2_5_360_quant_offset[] = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 };
  static const uint32_t buff_info__shape_64_1_1_1[] = { 64, 1, 1, 1 };
  static const uint32_t buff_info__mem_shape_F_64_1_1_1[] = { 64, 1, 1, 1 };
  static const uint32_t buff_info__shape_32_1_1_1[] = { 32, 1, 1, 1 };
  static const uint32_t buff_info__mem_shape_F_32_1_1_1[] = { 32, 1, 1, 1 };
  static const uint32_t buff_info__shape_16_1_1_1[] = { 16, 1, 1, 1 };
  static const uint32_t buff_info__mem_shape_F_16_1_1_1[] = { 16, 1, 1, 1 };
  static const uint32_t buff_info__shape_8_1_1_1[] = { 8, 1, 1, 1 };
  static const uint32_t buff_info__mem_shape_F_8_1_1_1[] = { 8, 1, 1, 1 };
#endif // LL_ATON_DBG_BUFFER_INFO_EXCLUDED == 0
  static const LL_Buffer_InfoTypeDef buff_info[] = {
    {
      .name = "Input_0_out_0",
      .addr_base = {((unsigned char *)&_mem_pool__user_io_input_0_face_detector)},
      .offset_start = 0,
      .offset_end = 49152,
      .offset_limit = 49160,
      .is_user_allocated = 1,
      .is_param = 0,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_128_128_3,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_128_128_3,
      .per_channel = 0,
      .scale = buff_info_Input_0_out_0_quant_scale,
      .offset = buff_info_Input_0_out_0_quant_offset,
    },
#if LL_ATON_DBG_BUFFER_INFO_EXCLUDED == 0
    {
      .name = "Conv2D_15_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 151872,
      .offset_end = 152448,
      .offset_limit = 152512,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_F_24_24_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_24_24_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_15_weights_quant_scale,
      .offset = buff_info_Conv2D_15_weights_quant_offset,
    },
    {
      .name = "Conv2D_29_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 151200,
      .offset_end = 151872,
      .offset_limit = 151936,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_F_28_24_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_28_24_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_29_weights_quant_scale,
      .offset = buff_info_Conv2D_29_weights_quant_offset,
    },
    {
      .name = "Conv2D_37_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 153744,
      .offset_end = 153996,
      .offset_limit = 154064,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_28_1_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_28_1_3_3,
      .per_channel = 1,
      .scale = buff_info_Conv2D_37_weights_quant_scale,
      .offset = buff_info_Conv2D_37_weights_quant_offset,
    },
    {
      .name = "Conv2D_40_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 149584,
      .offset_end = 150480,
      .offset_limit = 150544,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 14,
      .mem_shape = buff_info__mem_shape_M14_32_28_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_32_28_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_40_weights_quant_scale,
      .offset = buff_info_Conv2D_40_weights_quant_offset,
    },
    {
      .name = "Conv2D_58_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 147344,
      .offset_end = 148496,
      .offset_limit = 148560,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_36_32_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_36_32_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_58_weights_quant_scale,
      .offset = buff_info_Conv2D_58_weights_quant_offset,
    },
    {
      .name = "Conv2D_69_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 153408,
      .offset_end = 153732,
      .offset_limit = 153800,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_36_1_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_36_1_3_3,
      .per_channel = 1,
      .scale = buff_info_Conv2D_69_weights_quant_scale,
      .offset = buff_info_Conv2D_69_weights_quant_offset,
    },
    {
      .name = "Conv2D_72_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 145824,
      .offset_end = 147336,
      .offset_limit = 147400,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 18,
      .mem_shape = buff_info__mem_shape_M18_42_36_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_42_36_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_72_weights_quant_scale,
      .offset = buff_info_Conv2D_72_weights_quant_offset,
    },
    {
      .name = "Conv2D_80_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 153024,
      .offset_end = 153402,
      .offset_limit = 153472,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_42_1_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_42_1_3_3,
      .per_channel = 1,
      .scale = buff_info_Conv2D_80_weights_quant_scale,
      .offset = buff_info_Conv2D_80_weights_quant_offset,
    },
    {
      .name = "Conv2D_83_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 140352,
      .offset_end = 142368,
      .offset_limit = 142432,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 21,
      .mem_shape = buff_info__mem_shape_M21_48_42_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_48_42_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_83_weights_quant_scale,
      .offset = buff_info_Conv2D_83_weights_quant_offset,
    },
    {
      .name = "Conv2D_101_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 135360,
      .offset_end = 138048,
      .offset_limit = 138112,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 48,
      .mem_shape = buff_info__mem_shape_F_56_48_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_56_48_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_101_weights_quant_scale,
      .offset = buff_info_Conv2D_101_weights_quant_offset,
    },
    {
      .name = "Conv2D_115_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 125504,
      .offset_end = 129088,
      .offset_limit = 129152,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 14,
      .mem_shape = buff_info__mem_shape_M14_64_56_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_64_56_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_115_weights_quant_scale,
      .offset = buff_info_Conv2D_115_weights_quant_offset,
    },
    {
      .name = "Conv2D_129_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 116864,
      .offset_end = 121472,
      .offset_limit = 121536,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_72_64_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_72_64_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_129_weights_quant_scale,
      .offset = buff_info_Conv2D_129_weights_quant_offset,
    },
    {
      .name = "Conv2D_143_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 95552,
      .offset_end = 101312,
      .offset_limit = 101376,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_M24_80_72_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_80_72_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_143_weights_quant_scale,
      .offset = buff_info_Conv2D_143_weights_quant_offset,
    },
    {
      .name = "Conv2D_157_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 54528,
      .offset_end = 61568,
      .offset_limit = 61632,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 20,
      .mem_shape = buff_info__mem_shape_M20_88_80_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_88_80_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_157_weights_quant_scale,
      .offset = buff_info_Conv2D_157_weights_quant_offset,
    },
    {
      .name = "Conv2D_168_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 46080,
      .offset_end = 54528,
      .offset_limit = 54592,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 22,
      .mem_shape = buff_info__mem_shape_M22_96_88_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_96_88_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_168_weights_quant_scale,
      .offset = buff_info_Conv2D_168_weights_quant_offset,
    },
    {
      .name = "Conv2D_183_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 0,
      .offset_end = 9216,
      .offset_limit = 9280,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_M24_96_96_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_96_96_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_183_weights_quant_scale,
      .offset = buff_info_Conv2D_183_weights_quant_offset,
    },
    {
      .name = "Conv2D_194_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 9216,
      .offset_end = 18432,
      .offset_limit = 18496,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_M24_96_96_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_96_96_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_194_weights_quant_scale,
      .offset = buff_info_Conv2D_194_weights_quant_offset,
    },
    {
      .name = "Conv2D_205_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 18432,
      .offset_end = 27648,
      .offset_limit = 27712,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_M24_96_96_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_96_96_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_205_weights_quant_scale,
      .offset = buff_info_Conv2D_205_weights_quant_offset,
    },
    {
      .name = "Conv2D_216_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 27648,
      .offset_end = 36864,
      .offset_limit = 36928,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_M24_96_96_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_96_96_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_216_weights_quant_scale,
      .offset = buff_info_Conv2D_216_weights_quant_offset,
    },
    {
      .name = "Conv2D_223_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 36864,
      .offset_end = 46080,
      .offset_limit = 46144,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 96,
      .mem_shape = buff_info__mem_shape_F_96_96_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_96_96_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_223_weights_quant_scale,
      .offset = buff_info_Conv2D_223_weights_quant_offset,
    },
    {
      .name = "Conv2D_231_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 152448,
      .offset_end = 153024,
      .offset_limit = 153088,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_M24_6_96_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_6_96_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_231_weights_quant_scale,
      .offset = buff_info_Conv2D_231_weights_quant_offset,
    },
    {
      .name = "Conv2D_239_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 132544,
      .offset_end = 135360,
      .offset_limit = 135424,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 22,
      .mem_shape = buff_info__mem_shape_M22_32_88_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_32_88_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_239_weights_quant_scale,
      .offset = buff_info_Conv2D_239_weights_quant_offset,
    },
    {
      .name = "Conv2D_247_weights",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 154000,
      .offset_end = 154176,
      .offset_limit = 154240,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 22,
      .mem_shape = buff_info__mem_shape_M22_2_88_1_1,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_2_88_1_1,
      .per_channel = 1,
      .scale = buff_info_Conv2D_247_weights_quant_scale,
      .offset = buff_info_Conv2D_247_weights_quant_offset,
    },
    {
      .name = "Conv2D_12_weights_inflated_331",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 142368,
      .offset_end = 144096,
      .offset_limit = 144160,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 8,
      .mem_shape = buff_info__mem_shape_L_24_8_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_24_8_3_3,
      .per_channel = 1,
      .scale = buff_info_Conv2D_12_weights_inflated_331_quant_scale,
      .offset = buff_info_Conv2D_12_weights_inflated_331_quant_offset,
    },
    {
      .name = "Conv2D_26_weights_inflated_333",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 144096,
      .offset_end = 145824,
      .offset_limit = 145888,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 8,
      .mem_shape = buff_info__mem_shape_L_24_8_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_24_8_3_3,
      .per_channel = 1,
      .scale = buff_info_Conv2D_26_weights_inflated_333_quant_scale,
      .offset = buff_info_Conv2D_26_weights_inflated_333_quant_offset,
    },
    {
      .name = "Conv2D_55_weights_inflated_336",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 138048,
      .offset_end = 140352,
      .offset_limit = 140416,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 8,
      .mem_shape = buff_info__mem_shape_L_32_8_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_32_8_3_3,
      .per_channel = 1,
      .scale = buff_info_Conv2D_55_weights_inflated_336_quant_scale,
      .offset = buff_info_Conv2D_55_weights_inflated_336_quant_offset,
    },
    {
      .name = "Conv2D_98_weights_inflated_340",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 129088,
      .offset_end = 132544,
      .offset_limit = 132608,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 8,
      .mem_shape = buff_info__mem_shape_L_48_8_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_48_8_3_3,
      .per_channel = 1,
      .scale = buff_info_Conv2D_98_weights_inflated_340_quant_scale,
      .offset = buff_info_Conv2D_98_weights_inflated_340_quant_offset,
    },
    {
      .name = "Conv2D_112_weights_inflated_342",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 121472,
      .offset_end = 125504,
      .offset_limit = 125568,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 8,
      .mem_shape = buff_info__mem_shape_L_56_8_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_56_8_3_3,
      .per_channel = 1,
      .scale = buff_info_Conv2D_112_weights_inflated_342_quant_scale,
      .offset = buff_info_Conv2D_112_weights_inflated_342_quant_offset,
    },
    {
      .name = "Conv2D_126_weights_inflated_344",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 112256,
      .offset_end = 116864,
      .offset_limit = 116928,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 8,
      .mem_shape = buff_info__mem_shape_L_64_8_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_64_8_3_3,
      .per_channel = 1,
      .scale = buff_info_Conv2D_126_weights_inflated_344_quant_scale,
      .offset = buff_info_Conv2D_126_weights_inflated_344_quant_offset,
    },
    {
      .name = "Conv2D_140_weights_inflated_346",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 107072,
      .offset_end = 112256,
      .offset_limit = 112320,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 8,
      .mem_shape = buff_info__mem_shape_L_72_8_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_72_8_3_3,
      .per_channel = 1,
      .scale = buff_info_Conv2D_140_weights_inflated_346_quant_scale,
      .offset = buff_info_Conv2D_140_weights_inflated_346_quant_offset,
    },
    {
      .name = "Conv2D_154_weights_inflated_348",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 101312,
      .offset_end = 107072,
      .offset_limit = 107136,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 8,
      .mem_shape = buff_info__mem_shape_L_80_8_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_80_8_3_3,
      .per_channel = 1,
      .scale = buff_info_Conv2D_154_weights_inflated_348_quant_scale,
      .offset = buff_info_Conv2D_154_weights_inflated_348_quant_offset,
    },
    {
      .name = "Conv2D_165_weights_inflated_350",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 89216,
      .offset_end = 95552,
      .offset_limit = 95616,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 8,
      .mem_shape = buff_info__mem_shape_L_88_8_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_88_8_3_3,
      .per_channel = 1,
      .scale = buff_info_Conv2D_165_weights_inflated_350_quant_scale,
      .offset = buff_info_Conv2D_165_weights_inflated_350_quant_offset,
    },
    {
      .name = "Conv2D_180_weights_inflated_352",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 61568,
      .offset_end = 68480,
      .offset_limit = 68544,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 8,
      .mem_shape = buff_info__mem_shape_L_96_8_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_96_8_3_3,
      .per_channel = 1,
      .scale = buff_info_Conv2D_180_weights_inflated_352_quant_scale,
      .offset = buff_info_Conv2D_180_weights_inflated_352_quant_offset,
    },
    {
      .name = "Conv2D_191_weights_inflated_354",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 68480,
      .offset_end = 75392,
      .offset_limit = 75456,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 8,
      .mem_shape = buff_info__mem_shape_L_96_8_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_96_8_3_3,
      .per_channel = 1,
      .scale = buff_info_Conv2D_191_weights_inflated_354_quant_scale,
      .offset = buff_info_Conv2D_191_weights_inflated_354_quant_offset,
    },
    {
      .name = "Conv2D_202_weights_inflated_356",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 75392,
      .offset_end = 82304,
      .offset_limit = 82368,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 8,
      .mem_shape = buff_info__mem_shape_L_96_8_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_96_8_3_3,
      .per_channel = 1,
      .scale = buff_info_Conv2D_202_weights_inflated_356_quant_scale,
      .offset = buff_info_Conv2D_202_weights_inflated_356_quant_offset,
    },
    {
      .name = "Conv2D_213_weights_inflated_358",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 82304,
      .offset_end = 89216,
      .offset_limit = 89280,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 8,
      .mem_shape = buff_info__mem_shape_L_96_8_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_96_8_3_3,
      .per_channel = 1,
      .scale = buff_info_Conv2D_213_weights_inflated_358_quant_scale,
      .offset = buff_info_Conv2D_213_weights_inflated_358_quant_offset,
    },
    {
      .name = "Conv2D_7_weights_submask_0_0_0_0_24_3_3_5_359",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 148496,
      .offset_end = 149576,
      .offset_limit = 149640,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 3,
      .mem_shape = buff_info__mem_shape_L_24_3_3_5,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_24_3_3_5,
      .per_channel = 1,
      .scale = buff_info_Conv2D_7_weights_submask_0_0_0_0_24_3_3_5_359_quant_scale,
      .offset = buff_info_Conv2D_7_weights_submask_0_0_0_0_24_3_3_5_359_quant_offset,
    },
    {
      .name = "Conv2D_7_weights_submask_0_0_3_0_24_3_2_5_360",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 150480,
      .offset_end = 151200,
      .offset_limit = 151264,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 3,
      .mem_shape = buff_info__mem_shape_L_24_3_2_5,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_24_3_2_5,
      .per_channel = 1,
      .scale = buff_info_Conv2D_7_weights_submask_0_0_3_0_24_3_2_5_360_quant_scale,
      .offset = buff_info_Conv2D_7_weights_submask_0_0_3_0_24_3_2_5_360_quant_offset,
    },
    {
      .name = "Pad_23_pad_kern_76",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 154176,
      .offset_end = 154240,
      .offset_limit = 154304,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_64_1_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_64_1_1_1,
    },
    {
      .name = "Pad_45_pad_kern_146",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 154304,
      .offset_end = 154336,
      .offset_limit = 154400,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_32_1_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_32_1_1_1,
    },
    {
      .name = "Pad_52_pad_kern_159",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 154272,
      .offset_end = 154304,
      .offset_limit = 154368,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_32_1_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_32_1_1_1,
    },
    {
      .name = "Pad_66_pad_kern_200",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 154240,
      .offset_end = 154272,
      .offset_limit = 154336,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_32_1_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_32_1_1_1,
    },
    {
      .name = "Pad_88_pad_kern_270",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 154416,
      .offset_end = 154432,
      .offset_limit = 154496,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_16_1_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_16_1_1_1,
    },
    {
      .name = "Pad_95_pad_kern_283",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 154400,
      .offset_end = 154416,
      .offset_limit = 154480,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_16_1_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_16_1_1_1,
    },
    {
      .name = "Pad_109_pad_kern_322",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 154384,
      .offset_end = 154400,
      .offset_limit = 154464,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_16_1_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_16_1_1_1,
    },
    {
      .name = "Pad_123_pad_kern_363",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 154368,
      .offset_end = 154384,
      .offset_limit = 154448,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_16_1_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_16_1_1_1,
    },
    {
      .name = "Pad_137_pad_kern_404",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 154352,
      .offset_end = 154368,
      .offset_limit = 154432,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_16_1_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_16_1_1_1,
    },
    {
      .name = "Pad_151_pad_kern_445",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 154336,
      .offset_end = 154352,
      .offset_limit = 154416,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_16_1_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_16_1_1_1,
    },
    {
      .name = "Pad_173_pad_kern_515",
      .addr_base = {(unsigned char *)(0x70380000UL) /* Equivalent hex address = 0x70380000UL */},
      .offset_start = 154432,
      .offset_end = 154440,
      .offset_limit = 154504,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_8_1_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_8_1_1_1,
    },
#endif // LL_ATON_DBG_BUFFER_INFO_EXCLUDED == 0
    {
      .name = NULL,
    }
  };

  return buff_info;
}

const LL_Buffer_InfoTypeDef *LL_ATON_Output_Buffers_Info_face_detector(void)
{
  static const uint32_t buff_info__shape_1_512_16[] = { 1, 512, 16, 1 };
  static const uint32_t buff_info__mem_shape_F_1_512_16[] = { 1, 512, 16 };
  static const float buff_info_Transpose_246_out_0_quant_scale[] = { 0.306708127260208 };
  static const int16_t buff_info_Transpose_246_out_0_quant_offset[] = { -47 };
  static const uint32_t buff_info__shape_1_512_1[] = { 1, 512, 1, 1 };
  static const uint32_t buff_info__mem_shape_F_1_512_1[] = { 1, 512, 1 };
  static const float buff_info_Transpose_254_out_0_quant_scale[] = { 0.0369369201362133 };
  static const int16_t buff_info_Transpose_254_out_0_quant_offset[] = { 49 };
  static const uint32_t buff_info__shape_1_384_1[] = { 1, 384, 1, 1 };
  static const uint32_t buff_info__mem_shape_F_1_384_1[] = { 1, 384, 1 };
  static const float buff_info_Transpose_238_out_0_quant_scale[] = { 1.22469842433929 };
  static const int16_t buff_info_Transpose_238_out_0_quant_offset[] = { 126 };
  static const uint32_t buff_info__shape_1_384_16[] = { 1, 384, 16, 1 };
  static const uint32_t buff_info__mem_shape_F_1_384_16[] = { 1, 384, 16 };
  static const float buff_info_Transpose_230_out_0_quant_scale[] = { 1.20201289653778 };
  static const int16_t buff_info_Transpose_230_out_0_quant_offset[] = { -47 };
  static const LL_Buffer_InfoTypeDef buff_info[] = {
    {
      .name = "Transpose_246_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 8192,
      .offset_limit = 8256,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 76,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_512_16,
      .mem_ndims = 3,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_512_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_246_out_0_quant_scale,
      .offset = buff_info_Transpose_246_out_0_quant_offset,
    },
    {
      .name = "Transpose_254_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 40960,
      .offset_end = 41472,
      .offset_limit = 41536,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 72,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_512_1,
      .mem_ndims = 3,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_512_1,
      .per_channel = 0,
      .scale = buff_info_Transpose_254_out_0_quant_scale,
      .offset = buff_info_Transpose_254_out_0_quant_offset,
    },
    {
      .name = "Transpose_238_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 32768,
      .offset_end = 33152,
      .offset_limit = 33216,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 85,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_384_1,
      .mem_ndims = 3,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_384_1,
      .per_channel = 0,
      .scale = buff_info_Transpose_238_out_0_quant_scale,
      .offset = buff_info_Transpose_238_out_0_quant_offset,
    },
    {
      .name = "Transpose_230_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 8192,
      .offset_end = 14336,
      .offset_limit = 14400,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 88,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_384_16,
      .mem_ndims = 3,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_384_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_230_out_0_quant_scale,
      .offset = buff_info_Transpose_230_out_0_quant_offset,
    },
    {
      .name = NULL,
    }
  };

  return buff_info;
}

const LL_Buffer_InfoTypeDef *LL_ATON_Internal_Buffers_Info_face_detector(void)
{
  static const uint32_t buff_info__shape_1_3_128_128[] = { 1, 128, 128, 3 };
  static const uint32_t buff_info__mem_shape_L_1_3_128_128[] = { 1, 128, 128, 3 };
  static const float buff_info_Transpose_1_out_0_quant_scale[] = { 0.00392156885936856 };
  static const int16_t buff_info_Transpose_1_out_0_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_7_zero_off_out_1_quant_scale[] = { 0.00392156885936856 };
  static const int16_t buff_info_Conv2D_7_zero_off_out_1_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_1_24_64_64[] = { 1, 64, 64, 24 };
  static const uint32_t buff_info__mem_shape_M8_1_24_64_64[] = { 1, 3, 64, 64, 8 };
  static const float buff_info_Conv2D_7_off_bias_out_7_quant_scale[] = { 0.0138769680634141 };
  static const int16_t buff_info_Conv2D_7_off_bias_out_7_quant_offset[] = { -128 };
  static const uint32_t buff_info__mem_shape_L_1_24_64_64[] = { 1, 64, 64, 24 };
  static const float buff_info_Conv2D_12_off_bias_out_16_quant_scale[] = { 0.117412641644478 };
  static const int16_t buff_info_Conv2D_12_off_bias_out_16_quant_offset[] = { 2 };
  static const float buff_info_Conv2D_15_off_bias_out_25_quant_scale[] = { 0.0632003918290138 };
  static const int16_t buff_info_Conv2D_15_off_bias_out_25_quant_offset[] = { 46 };
  static const float buff_info_Add_18_out_0_quant_scale[] = { 0.0200754459947348 };
  static const int16_t buff_info_Add_18_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_26_off_bias_out_34_quant_scale[] = { 0.120129145681858 };
  static const int16_t buff_info_Conv2D_26_off_bias_out_34_quant_offset[] = { -32 };
  static const uint32_t buff_info__shape_1_64_24_64[] = { 1, 24, 64, 64 };
  static const uint32_t buff_info__mem_shape_L_1_64_24_64[] = { 1, 24, 64, 64 };
  static const float buff_info_Transpose_22_out_0_quant_scale[] = { 0.0200754459947348 };
  static const int16_t buff_info_Transpose_22_out_0_quant_offset[] = { -128 };
  static const uint32_t buff_info__mem_shape_F_1_64_24_64[] = { 1, 64, 24, 64 };
  static const uint32_t buff_info__shape_1_28_64_64[] = { 1, 64, 64, 28 };
  static const uint32_t buff_info__mem_shape_M14_1_28_64_64[] = { 1, 2, 64, 64, 14 };
  static const float buff_info_Conv2D_29_off_bias_out_43_quant_scale[] = { 0.06427863240242 };
  static const int16_t buff_info_Conv2D_29_off_bias_out_43_quant_offset[] = { 30 };
  static const uint32_t buff_info__shape_1_64_28_64[] = { 1, 28, 64, 64 };
  static const uint32_t buff_info__mem_shape_F_1_64_28_64[] = { 1, 64, 28, 64 };
  static const uint32_t buff_info__mem_shape_F_1_28_64_64[] = { 1, 28, 64, 64 };
  static const float buff_info_Transpose_24_out_0_quant_scale[] = { 0.0200754459947348 };
  static const int16_t buff_info_Transpose_24_out_0_quant_offset[] = { -128 };
  static const uint32_t buff_info__mem_shape_L_1_28_64_64[] = { 1, 64, 64, 28 };
  static const float buff_info_Transpose_24_out_0_inserted_out763_quant_scale[] = { 0.0200754459947348 };
  static const int16_t buff_info_Transpose_24_out_0_inserted_out763_quant_offset[] = { -128 };
  static const float buff_info_Add_32_out_0_quant_scale[] = { 0.0243262350559235 };
  static const int16_t buff_info_Add_32_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_37_zero_off_out_46_quant_scale[] = { 0.0243262350559235 };
  static const int16_t buff_info_Conv2D_37_zero_off_out_46_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_1_28_32_32[] = { 1, 32, 32, 28 };
  static const uint32_t buff_info__mem_shape_L_1_28_32_32[] = { 1, 32, 32, 28 };
  static const float buff_info_MaxPool_43_out_0_quant_scale[] = { 0.0243262350559235 };
  static const int16_t buff_info_MaxPool_43_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_37_zero_off_out_46_cp_in_192_quant_scale[] = { 0.0243262350559235 };
  static const int16_t buff_info_Conv2D_37_zero_off_out_46_cp_in_192_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_1_32_28_32[] = { 1, 28, 32, 32 };
  static const uint32_t buff_info__mem_shape_L_1_32_28_32[] = { 1, 28, 32, 32 };
  static const float buff_info_Transpose_44_out_0_quant_scale[] = { 0.0243262350559235 };
  static const int16_t buff_info_Transpose_44_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_37_off_bias_out_52_quant_scale[] = { 0.136931210756302 };
  static const int16_t buff_info_Conv2D_37_off_bias_out_52_quant_offset[] = { 20 };
  static const uint32_t buff_info__mem_shape_F_1_32_28_32[] = { 1, 32, 28, 32 };
  static const uint32_t buff_info__shape_1_32_32_32[] = { 1, 32, 32, 32 };
  static const uint32_t buff_info__mem_shape_F_1_32_32_32[] = { 1, 32, 32, 32 };
  static const uint32_t buff_info__mem_shape_M16_1_32_32_32[] = { 1, 2, 32, 32, 16 };
  static const float buff_info_Conv2D_40_off_bias_out_61_quant_scale[] = { 0.0720452964305878 };
  static const int16_t buff_info_Conv2D_40_off_bias_out_61_quant_offset[] = { -14 };
  static const float buff_info_Transpose_46_out_0_quant_scale[] = { 0.0243262350559235 };
  static const int16_t buff_info_Transpose_46_out_0_quant_offset[] = { -128 };
  static const uint32_t buff_info__mem_shape_L_1_32_32_32[] = { 1, 32, 32, 32 };
  static const float buff_info_Transpose_46_out_0_inserted_out768_quant_scale[] = { 0.0243262350559235 };
  static const int16_t buff_info_Transpose_46_out_0_inserted_out768_quant_offset[] = { -128 };
  static const float buff_info_Add_47_out_0_quant_scale[] = { 0.0397368408739567 };
  static const int16_t buff_info_Add_47_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_55_zero_off_out_64_quant_scale[] = { 0.0397368408739567 };
  static const int16_t buff_info_Conv2D_55_zero_off_out_64_quant_offset[] = { 0 };
  static const float buff_info_Transpose_51_out_0_quant_scale[] = { 0.0397368408739567 };
  static const int16_t buff_info_Transpose_51_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_55_off_bias_out_70_quant_scale[] = { 0.175731912255287 };
  static const int16_t buff_info_Conv2D_55_off_bias_out_70_quant_offset[] = { -22 };
  static const uint32_t buff_info__shape_1_32_36_32[] = { 1, 36, 32, 32 };
  static const uint32_t buff_info__mem_shape_F_1_32_36_32[] = { 1, 32, 36, 32 };
  static const uint32_t buff_info__shape_1_36_32_32[] = { 1, 32, 32, 36 };
  static const uint32_t buff_info__mem_shape_M18_1_36_32_32[] = { 1, 2, 32, 32, 18 };
  static const float buff_info_Conv2D_58_off_bias_out_79_quant_scale[] = { 0.0679439753293991 };
  static const int16_t buff_info_Conv2D_58_off_bias_out_79_quant_offset[] = { 23 };
  static const uint32_t buff_info__mem_shape_F_1_36_32_32[] = { 1, 36, 32, 32 };
  static const float buff_info_Transpose_53_out_0_quant_scale[] = { 0.0397368408739567 };
  static const int16_t buff_info_Transpose_53_out_0_quant_offset[] = { -128 };
  static const uint32_t buff_info__mem_shape_L_1_36_32_32[] = { 1, 32, 32, 36 };
  static const float buff_info_Transpose_53_out_0_inserted_out773_quant_scale[] = { 0.0397368408739567 };
  static const int16_t buff_info_Transpose_53_out_0_inserted_out773_quant_offset[] = { -128 };
  static const float buff_info_Add_61_out_0_quant_scale[] = { 0.0276320911943913 };
  static const int16_t buff_info_Add_61_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_69_zero_off_out_82_quant_scale[] = { 0.0276320911943913 };
  static const int16_t buff_info_Conv2D_69_zero_off_out_82_quant_offset[] = { 0 };
  static const uint32_t buff_info__mem_shape_L_1_32_36_32[] = { 1, 36, 32, 32 };
  static const float buff_info_Transpose_65_out_0_quant_scale[] = { 0.0276320911943913 };
  static const int16_t buff_info_Transpose_65_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_69_zero_off_out_82_cp_in_195_quant_scale[] = { 0.0276320911943913 };
  static const int16_t buff_info_Conv2D_69_zero_off_out_82_cp_in_195_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_69_off_bias_out_88_quant_scale[] = { 0.147784203290939 };
  static const int16_t buff_info_Conv2D_69_off_bias_out_88_quant_offset[] = { 20 };
  static const uint32_t buff_info__shape_1_32_42_32[] = { 1, 42, 32, 32 };
  static const uint32_t buff_info__mem_shape_F_1_32_42_32[] = { 1, 32, 42, 32 };
  static const uint32_t buff_info__shape_1_42_32_32[] = { 1, 32, 32, 42 };
  static const uint32_t buff_info__mem_shape_F_1_42_32_32[] = { 1, 42, 32, 32 };
  static const float buff_info_Transpose_67_out_0_quant_scale[] = { 0.0276320911943913 };
  static const int16_t buff_info_Transpose_67_out_0_quant_offset[] = { -128 };
  static const uint32_t buff_info__mem_shape_L_1_42_32_32[] = { 1, 32, 32, 42 };
  static const float buff_info_Transpose_67_out_0_inserted_out778_quant_scale[] = { 0.0276320911943913 };
  static const int16_t buff_info_Transpose_67_out_0_inserted_out778_quant_offset[] = { -128 };
  static const uint32_t buff_info__mem_shape_M21_1_42_32_32[] = { 1, 2, 32, 32, 21 };
  static const float buff_info_Conv2D_72_off_bias_out_97_quant_scale[] = { 0.0554033257067204 };
  static const int16_t buff_info_Conv2D_72_off_bias_out_97_quant_offset[] = { 3 };
  static const float buff_info_Add_75_out_0_quant_scale[] = { 0.0269579831510782 };
  static const int16_t buff_info_Add_75_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_80_zero_off_out_100_quant_scale[] = { 0.0269579831510782 };
  static const int16_t buff_info_Conv2D_80_zero_off_out_100_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_1_42_16_16[] = { 1, 16, 16, 42 };
  static const uint32_t buff_info__mem_shape_L_1_42_16_16[] = { 1, 16, 16, 42 };
  static const float buff_info_MaxPool_86_out_0_quant_scale[] = { 0.0269579831510782 };
  static const int16_t buff_info_MaxPool_86_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_80_zero_off_out_100_cp_in_197_quant_scale[] = { 0.0269579831510782 };
  static const int16_t buff_info_Conv2D_80_zero_off_out_100_cp_in_197_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_1_16_42_16[] = { 1, 42, 16, 16 };
  static const uint32_t buff_info__mem_shape_L_1_16_42_16[] = { 1, 42, 16, 16 };
  static const float buff_info_Transpose_87_out_0_quant_scale[] = { 0.0269579831510782 };
  static const int16_t buff_info_Transpose_87_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_80_off_bias_out_106_quant_scale[] = { 0.190418049693108 };
  static const int16_t buff_info_Conv2D_80_off_bias_out_106_quant_offset[] = { -17 };
  static const uint32_t buff_info__mem_shape_F_1_16_42_16[] = { 1, 16, 42, 16 };
  static const uint32_t buff_info__shape_1_16_48_16[] = { 1, 48, 16, 16 };
  static const uint32_t buff_info__mem_shape_F_1_16_48_16[] = { 1, 16, 48, 16 };
  static const uint32_t buff_info__shape_1_48_16_16[] = { 1, 16, 16, 48 };
  static const uint32_t buff_info__mem_shape_M24_1_48_16_16[] = { 1, 2, 16, 16, 24 };
  static const float buff_info_Conv2D_83_off_bias_out_115_quant_scale[] = { 0.0607114173471928 };
  static const int16_t buff_info_Conv2D_83_off_bias_out_115_quant_offset[] = { -29 };
  static const uint32_t buff_info__mem_shape_F_1_48_16_16[] = { 1, 48, 16, 16 };
  static const float buff_info_Transpose_89_out_0_quant_scale[] = { 0.0269579831510782 };
  static const int16_t buff_info_Transpose_89_out_0_quant_offset[] = { -128 };
  static const uint32_t buff_info__mem_shape_L_1_48_16_16[] = { 1, 16, 16, 48 };
  static const float buff_info_Transpose_89_out_0_inserted_out783_quant_scale[] = { 0.0269579831510782 };
  static const int16_t buff_info_Transpose_89_out_0_inserted_out783_quant_offset[] = { -128 };
  static const float buff_info_Add_90_out_0_quant_scale[] = { 0.0372552536427975 };
  static const int16_t buff_info_Add_90_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_98_zero_off_out_118_quant_scale[] = { 0.0372552536427975 };
  static const int16_t buff_info_Conv2D_98_zero_off_out_118_quant_offset[] = { 0 };
  static const uint32_t buff_info__mem_shape_L_1_16_48_16[] = { 1, 48, 16, 16 };
  static const float buff_info_Transpose_94_out_0_quant_scale[] = { 0.0372552536427975 };
  static const int16_t buff_info_Transpose_94_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_98_off_bias_out_124_quant_scale[] = { 0.159382984042168 };
  static const int16_t buff_info_Conv2D_98_off_bias_out_124_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_1_16_56_16[] = { 1, 56, 16, 16 };
  static const uint32_t buff_info__mem_shape_F_1_16_56_16[] = { 1, 16, 56, 16 };
  static const uint32_t buff_info__shape_1_56_16_16[] = { 1, 16, 16, 56 };
  static const uint32_t buff_info__mem_shape_M14_1_56_16_16[] = { 1, 4, 16, 16, 14 };
  static const float buff_info_Conv2D_101_off_bias_out_130_quant_scale[] = { 0.0712688341736794 };
  static const int16_t buff_info_Conv2D_101_off_bias_out_130_quant_offset[] = { -21 };
  static const uint32_t buff_info__mem_shape_F_1_56_16_16[] = { 1, 56, 16, 16 };
  static const float buff_info_Transpose_96_out_0_quant_scale[] = { 0.0372552536427975 };
  static const int16_t buff_info_Transpose_96_out_0_quant_offset[] = { -128 };
  static const uint32_t buff_info__mem_shape_L_1_56_16_16[] = { 1, 16, 16, 56 };
  static const float buff_info_Transpose_96_out_0_inserted_out787_quant_scale[] = { 0.0372552536427975 };
  static const int16_t buff_info_Transpose_96_out_0_inserted_out787_quant_offset[] = { -128 };
  static const float buff_info_Add_104_out_0_quant_scale[] = { 0.0415017157793045 };
  static const int16_t buff_info_Add_104_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_112_zero_off_out_133_quant_scale[] = { 0.0415017157793045 };
  static const int16_t buff_info_Conv2D_112_zero_off_out_133_quant_offset[] = { 0 };
  static const uint32_t buff_info__mem_shape_L_1_16_56_16[] = { 1, 56, 16, 16 };
  static const float buff_info_Transpose_108_out_0_quant_scale[] = { 0.0415017157793045 };
  static const int16_t buff_info_Transpose_108_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_112_off_bias_out_139_quant_scale[] = { 0.180353388190269 };
  static const int16_t buff_info_Conv2D_112_off_bias_out_139_quant_offset[] = { 6 };
  static const uint32_t buff_info__shape_1_16_64_16[] = { 1, 64, 16, 16 };
  static const uint32_t buff_info__mem_shape_F_1_16_64_16[] = { 1, 16, 64, 16 };
  static const uint32_t buff_info__shape_1_64_16_16[] = { 1, 16, 16, 64 };
  static const uint32_t buff_info__mem_shape_F_1_64_16_16[] = { 1, 64, 16, 16 };
  static const float buff_info_Transpose_110_out_0_quant_scale[] = { 0.0415017157793045 };
  static const int16_t buff_info_Transpose_110_out_0_quant_offset[] = { -128 };
  static const uint32_t buff_info__mem_shape_L_1_64_16_16[] = { 1, 16, 16, 64 };
  static const float buff_info_Transpose_110_out_0_inserted_out794_quant_scale[] = { 0.0415017157793045 };
  static const int16_t buff_info_Transpose_110_out_0_inserted_out794_quant_offset[] = { -128 };
  static const uint32_t buff_info__mem_shape_M16_1_64_16_16[] = { 1, 4, 16, 16, 16 };
  static const float buff_info_Conv2D_115_off_bias_out_148_quant_scale[] = { 0.0881709307432175 };
  static const int16_t buff_info_Conv2D_115_off_bias_out_148_quant_offset[] = { 4 };
  static const float buff_info_Add_118_out_0_quant_scale[] = { 0.0424482710659504 };
  static const int16_t buff_info_Add_118_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_126_zero_off_out_151_quant_scale[] = { 0.0424482710659504 };
  static const int16_t buff_info_Conv2D_126_zero_off_out_151_quant_offset[] = { 0 };
  static const uint32_t buff_info__mem_shape_L_1_16_64_16[] = { 1, 64, 16, 16 };
  static const float buff_info_Transpose_122_out_0_quant_scale[] = { 0.0424482710659504 };
  static const int16_t buff_info_Transpose_122_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_126_off_bias_out_157_quant_scale[] = { 0.222459837794304 };
  static const int16_t buff_info_Conv2D_126_off_bias_out_157_quant_offset[] = { 27 };
  static const uint32_t buff_info__shape_1_16_72_16[] = { 1, 72, 16, 16 };
  static const uint32_t buff_info__mem_shape_F_1_16_72_16[] = { 1, 16, 72, 16 };
  static const uint32_t buff_info__shape_1_72_16_16[] = { 1, 16, 16, 72 };
  static const uint32_t buff_info__mem_shape_F_1_72_16_16[] = { 1, 72, 16, 16 };
  static const float buff_info_Transpose_124_out_0_quant_scale[] = { 0.0424482710659504 };
  static const int16_t buff_info_Transpose_124_out_0_quant_offset[] = { -128 };
  static const uint32_t buff_info__mem_shape_L_1_72_16_16[] = { 1, 16, 16, 72 };
  static const float buff_info_Transpose_124_out_0_inserted_out801_quant_scale[] = { 0.0424482710659504 };
  static const int16_t buff_info_Transpose_124_out_0_inserted_out801_quant_offset[] = { -128 };
  static const uint32_t buff_info__mem_shape_M24_1_72_16_16[] = { 1, 3, 16, 16, 24 };
  static const float buff_info_Conv2D_129_off_bias_out_166_quant_scale[] = { 0.0689409300684929 };
  static const int16_t buff_info_Conv2D_129_off_bias_out_166_quant_offset[] = { 14 };
  static const float buff_info_Add_132_out_0_quant_scale[] = { 0.0304187368601561 };
  static const int16_t buff_info_Add_132_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_140_zero_off_out_169_quant_scale[] = { 0.0304187368601561 };
  static const int16_t buff_info_Conv2D_140_zero_off_out_169_quant_offset[] = { 0 };
  static const uint32_t buff_info__mem_shape_L_1_16_72_16[] = { 1, 72, 16, 16 };
  static const float buff_info_Transpose_136_out_0_quant_scale[] = { 0.0304187368601561 };
  static const int16_t buff_info_Transpose_136_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_140_off_bias_out_175_quant_scale[] = { 0.232053399085999 };
  static const int16_t buff_info_Conv2D_140_off_bias_out_175_quant_offset[] = { -12 };
  static const uint32_t buff_info__shape_1_16_80_16[] = { 1, 80, 16, 16 };
  static const uint32_t buff_info__mem_shape_F_1_16_80_16[] = { 1, 16, 80, 16 };
  static const uint32_t buff_info__shape_1_80_16_16[] = { 1, 16, 16, 80 };
  static const uint32_t buff_info__mem_shape_M20_1_80_16_16[] = { 1, 4, 16, 16, 20 };
  static const float buff_info_Conv2D_143_off_bias_out_184_quant_scale[] = { 0.0814998671412468 };
  static const int16_t buff_info_Conv2D_143_off_bias_out_184_quant_offset[] = { 12 };
  static const uint32_t buff_info__mem_shape_F_1_80_16_16[] = { 1, 80, 16, 16 };
  static const float buff_info_Transpose_138_out_0_quant_scale[] = { 0.0304187368601561 };
  static const int16_t buff_info_Transpose_138_out_0_quant_offset[] = { -128 };
  static const uint32_t buff_info__mem_shape_L_1_80_16_16[] = { 1, 16, 16, 80 };
  static const float buff_info_Transpose_138_out_0_inserted_out807_quant_scale[] = { 0.0304187368601561 };
  static const int16_t buff_info_Transpose_138_out_0_inserted_out807_quant_offset[] = { -128 };
  static const float buff_info_Add_146_out_0_quant_scale[] = { 0.036800492554903 };
  static const int16_t buff_info_Add_146_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_154_zero_off_out_187_quant_scale[] = { 0.036800492554903 };
  static const int16_t buff_info_Conv2D_154_zero_off_out_187_quant_offset[] = { 0 };
  static const uint32_t buff_info__mem_shape_L_1_16_80_16[] = { 1, 80, 16, 16 };
  static const float buff_info_Transpose_150_out_0_quant_scale[] = { 0.036800492554903 };
  static const int16_t buff_info_Transpose_150_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_154_off_bias_out_193_quant_scale[] = { 0.373142600059509 };
  static const int16_t buff_info_Conv2D_154_off_bias_out_193_quant_offset[] = { -38 };
  static const uint32_t buff_info__shape_1_16_88_16[] = { 1, 88, 16, 16 };
  static const uint32_t buff_info__mem_shape_F_1_16_88_16[] = { 1, 16, 88, 16 };
  static const uint32_t buff_info__shape_1_88_16_16[] = { 1, 16, 16, 88 };
  static const uint32_t buff_info__mem_shape_F_1_88_16_16[] = { 1, 88, 16, 16 };
  static const float buff_info_Transpose_152_out_0_quant_scale[] = { 0.036800492554903 };
  static const int16_t buff_info_Transpose_152_out_0_quant_offset[] = { -128 };
  static const uint32_t buff_info__mem_shape_M22_1_88_16_16[] = { 1, 4, 16, 16, 22 };
  static const float buff_info_Conv2D_157_off_bias_out_202_quant_scale[] = { 0.0714662149548531 };
  static const int16_t buff_info_Conv2D_157_off_bias_out_202_quant_offset[] = { 34 };
  static const uint32_t buff_info__mem_shape_L_1_88_16_16[] = { 1, 16, 16, 88 };
  static const float buff_info_Transpose_152_out_0_inserted_out814_quant_scale[] = { 0.036800492554903 };
  static const int16_t buff_info_Transpose_152_out_0_inserted_out814_quant_offset[] = { -128 };
  static const float buff_info_Add_160_out_0_quant_scale[] = { 0.0260655228048563 };
  static const int16_t buff_info_Add_160_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_165_zero_off_out_205_quant_scale[] = { 0.0260655228048563 };
  static const int16_t buff_info_Conv2D_165_zero_off_out_205_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_247_zero_off_out_322_quant_scale[] = { 0.0260655228048563 };
  static const int16_t buff_info_Conv2D_247_zero_off_out_322_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_239_zero_off_out_313_quant_scale[] = { 0.0260655228048563 };
  static const int16_t buff_info_Conv2D_239_zero_off_out_313_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_1_88_8_8[] = { 1, 8, 8, 88 };
  static const uint32_t buff_info__mem_shape_L_1_88_8_8[] = { 1, 8, 8, 88 };
  static const float buff_info_MaxPool_171_out_0_quant_scale[] = { 0.0260655228048563 };
  static const int16_t buff_info_MaxPool_171_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_165_off_bias_out_211_quant_scale[] = { 0.593284428119659 };
  static const int16_t buff_info_Conv2D_165_off_bias_out_211_quant_offset[] = { -26 };
  static const uint32_t buff_info__shape_1_8_88_8[] = { 1, 88, 8, 8 };
  static const uint32_t buff_info__mem_shape_L_1_8_88_8[] = { 1, 88, 8, 8 };
  static const float buff_info_Transpose_172_out_0_quant_scale[] = { 0.0260655228048563 };
  static const int16_t buff_info_Transpose_172_out_0_quant_offset[] = { -128 };
  static const uint32_t buff_info__shape_1_2_16_16[] = { 1, 16, 16, 2 };
  static const uint32_t buff_info__mem_shape_L_1_2_16_16[] = { 1, 16, 16, 2 };
  static const uint32_t buff_info__mem_shape_F_1_8_88_8[] = { 1, 8, 88, 8 };
  static const float buff_info_Conv2D_247_off_bias_out_328_quant_scale[] = { 0.0369369201362133 };
  static const int16_t buff_info_Conv2D_247_off_bias_out_328_quant_offset[] = { 49 };
  static const uint32_t buff_info__shape_1_16_16_2[] = { 1, 16, 2, 16 };
  static const uint32_t buff_info__mem_shape_F_1_16_16_2[] = { 1, 16, 16, 2 };
  static const float buff_info_Transpose_250_out_0_quant_scale[] = { 0.0369369201362133 };
  static const int16_t buff_info_Transpose_250_out_0_quant_offset[] = { 49 };
  static const uint32_t buff_info__shape_1_32_16_16[] = { 1, 16, 16, 32 };
  static const uint32_t buff_info__mem_shape_L_1_32_16_16[] = { 1, 16, 16, 32 };
  static const float buff_info_Conv2D_239_off_bias_out_319_quant_scale[] = { 0.306708127260208 };
  static const int16_t buff_info_Conv2D_239_off_bias_out_319_quant_offset[] = { -47 };
  static const uint32_t buff_info__shape_1_16_16_32[] = { 1, 16, 32, 16 };
  static const uint32_t buff_info__mem_shape_F_1_16_16_32[] = { 1, 16, 16, 32 };
  static const float buff_info_Transpose_242_out_0_quant_scale[] = { 0.306708127260208 };
  static const int16_t buff_info_Transpose_242_out_0_quant_offset[] = { -47 };
  static const uint32_t buff_info__shape_1_512_16_1[] = { 1, 16, 1, 512 };
  static const uint32_t buff_info__mem_shape_F_1_512_16_1[] = { 1, 512, 16, 1 };
  static const float buff_info_Reshape_243_out_0_inserted_out827_quant_scale[] = { 0.306708127260208 };
  static const int16_t buff_info_Reshape_243_out_0_inserted_out827_quant_offset[] = { -47 };
  static const uint32_t buff_info__shape_1_8_96_8[] = { 1, 96, 8, 8 };
  static const uint32_t buff_info__mem_shape_F_1_8_96_8[] = { 1, 8, 96, 8 };
  static const uint32_t buff_info__shape_1_96_8_8[] = { 1, 8, 8, 96 };
  static const uint32_t buff_info__mem_shape_F_1_96_8_8[] = { 1, 96, 8, 8 };
  static const float buff_info_Transpose_174_out_0_quant_scale[] = { 0.0260655228048563 };
  static const int16_t buff_info_Transpose_174_out_0_quant_offset[] = { -128 };
  static const uint32_t buff_info__mem_shape_M24_1_96_8_8[] = { 1, 4, 8, 8, 24 };
  static const float buff_info_Conv2D_168_off_bias_out_220_quant_scale[] = { 0.0591815412044525 };
  static const int16_t buff_info_Conv2D_168_off_bias_out_220_quant_offset[] = { 6 };
  static const uint32_t buff_info__mem_shape_L_1_96_8_8[] = { 1, 8, 8, 96 };
  static const float buff_info_Transpose_174_out_0_inserted_out830_quant_scale[] = { 0.0260655228048563 };
  static const int16_t buff_info_Transpose_174_out_0_inserted_out830_quant_offset[] = { -128 };
  static const uint32_t buff_info__mem_shape_L_1_512_16_1[] = { 1, 16, 1, 512 };
  static const float buff_info_Reshape_243_out_0_inserted_out827_inserted_out829_quant_scale[] = { 0.306708127260208 };
  static const int16_t buff_info_Reshape_243_out_0_inserted_out827_inserted_out829_quant_offset[] = { -47 };
  static const uint32_t buff_info__shape_1_16_1_512[] = { 1, 1, 512, 16 };
  static const uint32_t buff_info__mem_shape_F_1_16_1_512[] = { 1, 16, 1, 512 };
  static const float buff_info_Transpose_244_out_0_quant_scale[] = { 0.306708127260208 };
  static const int16_t buff_info_Transpose_244_out_0_quant_offset[] = { -47 };
  static const uint32_t buff_info__shape_1_16_512_1[] = { 1, 512, 1, 16 };
  static const uint32_t buff_info__mem_shape_F_1_16_512_1[] = { 1, 16, 512, 1 };
  static const float buff_info_Transpose_244_out_0_cp_in_172_inserted_out831_quant_scale[] = { 0.306708127260208 };
  static const int16_t buff_info_Transpose_244_out_0_cp_in_172_inserted_out831_quant_offset[] = { -47 };
  static const float buff_info_Add_175_out_0_quant_scale[] = { 0.0281831510365009 };
  static const int16_t buff_info_Add_175_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_180_zero_off_out_223_quant_scale[] = { 0.0281831510365009 };
  static const int16_t buff_info_Conv2D_180_zero_off_out_223_quant_offset[] = { 0 };
  static const uint32_t buff_info__mem_shape_L_1_16_512_1[] = { 1, 512, 1, 16 };
  static const float buff_info_Transpose_244_out_0_cp_in_172_inserted_out831_inserted_out833_quant_scale[] = { 0.306708127260208 };
  static const int16_t buff_info_Transpose_244_out_0_cp_in_172_inserted_out831_inserted_out833_quant_offset[] = { -47 };
  static const uint32_t buff_info__shape_1_512_1_16[] = { 1, 1, 16, 512 };
  static const uint32_t buff_info__mem_shape_F_1_512_1_16[] = { 1, 512, 1, 16 };
  static const float buff_info_Transpose_246_out_0_cp_in_173_quant_scale[] = { 0.306708127260208 };
  static const int16_t buff_info_Transpose_246_out_0_cp_in_173_quant_offset[] = { -47 };
  static const float buff_info_Conv2D_180_off_bias_out_229_quant_scale[] = { 0.25239896774292 };
  static const int16_t buff_info_Conv2D_180_off_bias_out_229_quant_offset[] = { -3 };
  static const float buff_info_Add_186_out_0_quant_scale[] = { 0.0298720635473728 };
  static const int16_t buff_info_Add_186_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_191_zero_off_out_241_quant_scale[] = { 0.0298720635473728 };
  static const int16_t buff_info_Conv2D_191_zero_off_out_241_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_191_off_bias_out_247_quant_scale[] = { 0.265733778476715 };
  static const int16_t buff_info_Conv2D_191_off_bias_out_247_quant_offset[] = { 17 };
  static const float buff_info_Add_197_out_0_quant_scale[] = { 0.0283430349081755 };
  static const int16_t buff_info_Add_197_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_202_zero_off_out_259_quant_scale[] = { 0.0283430349081755 };
  static const int16_t buff_info_Conv2D_202_zero_off_out_259_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_202_off_bias_out_265_quant_scale[] = { 0.260736018419266 };
  static const int16_t buff_info_Conv2D_202_off_bias_out_265_quant_offset[] = { -17 };
  static const float buff_info_Add_208_out_0_quant_scale[] = { 0.0309466309845448 };
  static const int16_t buff_info_Add_208_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_213_zero_off_out_277_quant_scale[] = { 0.0309466309845448 };
  static const int16_t buff_info_Conv2D_213_zero_off_out_277_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_213_off_bias_out_283_quant_scale[] = { 1.31773746013641 };
  static const int16_t buff_info_Conv2D_213_off_bias_out_283_quant_offset[] = { 118 };
  static const float buff_info_Add_219_out_0_quant_scale[] = { 0.0229979231953621 };
  static const int16_t buff_info_Add_219_out_0_quant_offset[] = { -128 };
  static const float buff_info_Conv2D_231_zero_off_out_304_quant_scale[] = { 0.0229979231953621 };
  static const int16_t buff_info_Conv2D_231_zero_off_out_304_quant_offset[] = { 0 };
  static const float buff_info_Conv2D_223_zero_off_out_295_quant_scale[] = { 0.0229979231953621 };
  static const int16_t buff_info_Conv2D_223_zero_off_out_295_quant_offset[] = { 0 };
  static const uint32_t buff_info__shape_1_6_8_8[] = { 1, 8, 8, 6 };
  static const uint32_t buff_info__mem_shape_L_1_6_8_8[] = { 1, 8, 8, 6 };
  static const float buff_info_Conv2D_231_off_bias_out_310_quant_scale[] = { 1.22469842433929 };
  static const int16_t buff_info_Conv2D_231_off_bias_out_310_quant_offset[] = { 126 };
  static const uint32_t buff_info__shape_1_8_8_6[] = { 1, 8, 6, 8 };
  static const uint32_t buff_info__mem_shape_F_1_8_8_6[] = { 1, 8, 8, 6 };
  static const float buff_info_Transpose_234_out_0_quant_scale[] = { 1.22469842433929 };
  static const int16_t buff_info_Transpose_234_out_0_quant_offset[] = { 126 };
  static const float buff_info_Conv2D_223_off_bias_out_301_quant_scale[] = { 1.20201289653778 };
  static const int16_t buff_info_Conv2D_223_off_bias_out_301_quant_offset[] = { -47 };
  static const uint32_t buff_info__shape_1_8_8_96[] = { 1, 8, 96, 8 };
  static const uint32_t buff_info__mem_shape_F_1_8_8_96[] = { 1, 8, 8, 96 };
  static const float buff_info_Transpose_226_out_0_quant_scale[] = { 1.20201289653778 };
  static const int16_t buff_info_Transpose_226_out_0_quant_offset[] = { -47 };
  static const uint32_t buff_info__shape_1_384_16_1[] = { 1, 16, 1, 384 };
  static const uint32_t buff_info__mem_shape_F_1_384_16_1[] = { 1, 384, 16, 1 };
  static const float buff_info_Reshape_227_out_0_inserted_out849_quant_scale[] = { 1.20201289653778 };
  static const int16_t buff_info_Reshape_227_out_0_inserted_out849_quant_offset[] = { -47 };
  static const uint32_t buff_info__mem_shape_L_1_384_16_1[] = { 1, 16, 1, 384 };
  static const float buff_info_Reshape_227_out_0_inserted_out849_inserted_out851_quant_scale[] = { 1.20201289653778 };
  static const int16_t buff_info_Reshape_227_out_0_inserted_out849_inserted_out851_quant_offset[] = { -47 };
  static const uint32_t buff_info__shape_1_16_1_384[] = { 1, 1, 384, 16 };
  static const uint32_t buff_info__mem_shape_F_1_16_1_384[] = { 1, 16, 1, 384 };
  static const float buff_info_Transpose_228_out_0_quant_scale[] = { 1.20201289653778 };
  static const int16_t buff_info_Transpose_228_out_0_quant_offset[] = { -47 };
  static const uint32_t buff_info__shape_1_16_384_1[] = { 1, 384, 1, 16 };
  static const uint32_t buff_info__mem_shape_F_1_16_384_1[] = { 1, 16, 384, 1 };
  static const float buff_info_Transpose_228_out_0_cp_in_189_inserted_out852_quant_scale[] = { 1.20201289653778 };
  static const int16_t buff_info_Transpose_228_out_0_cp_in_189_inserted_out852_quant_offset[] = { -47 };
  static const uint32_t buff_info__mem_shape_L_1_16_384_1[] = { 1, 384, 1, 16 };
  static const float buff_info_Transpose_228_out_0_cp_in_189_inserted_out852_inserted_out854_quant_scale[] = { 1.20201289653778 };
  static const int16_t buff_info_Transpose_228_out_0_cp_in_189_inserted_out852_inserted_out854_quant_offset[] = { -47 };
  static const uint32_t buff_info__shape_1_384_1_16[] = { 1, 1, 16, 384 };
  static const uint32_t buff_info__mem_shape_F_1_384_1_16[] = { 1, 384, 1, 16 };
  static const float buff_info_Transpose_230_out_0_cp_in_190_quant_scale[] = { 1.20201289653778 };
  static const int16_t buff_info_Transpose_230_out_0_cp_in_190_quant_offset[] = { -47 };
  static const LL_Buffer_InfoTypeDef buff_info[] = {
    {
      .name = "Transpose_1_out_0",
      .addr_base = {((unsigned char *)&_mem_pool__user_io_input_0_face_detector)},
      .offset_start = 0,
      .offset_end = 49152,
      .offset_limit = 49160,
      .is_user_allocated = 1,
      .is_param = 0,
      .epoch = 1,
      .batch = 3,
      .mem_shape = buff_info__mem_shape_L_1_3_128_128,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_3_128_128,
      .per_channel = 0,
      .scale = buff_info_Transpose_1_out_0_quant_scale,
      .offset = buff_info_Transpose_1_out_0_quant_offset,
    },
    {
      .name = "Conv2D_7_zero_off_out_1",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 294912,
      .offset_end = 344064,
      .offset_limit = 344128,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 2,
      .batch = 3,
      .mem_shape = buff_info__mem_shape_L_1_3_128_128,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_3_128_128,
      .per_channel = 0,
      .scale = buff_info_Conv2D_7_zero_off_out_1_quant_scale,
      .offset = buff_info_Conv2D_7_zero_off_out_1_quant_offset,
    },
    {
      .name = "Conv2D_7_off_bias_out_7",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 196608,
      .offset_end = 294912,
      .offset_limit = 294976,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 3,
      .batch = 8,
      .mem_shape = buff_info__mem_shape_M8_1_24_64_64,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_24_64_64,
      .per_channel = 0,
      .scale = buff_info_Conv2D_7_off_bias_out_7_quant_scale,
      .offset = buff_info_Conv2D_7_off_bias_out_7_quant_offset,
    },
    {
      .name = "Conv2D_12_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 196608,
      .offset_limit = 196672,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 3,
      .batch = 8,
      .mem_shape = buff_info__mem_shape_M8_1_24_64_64,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 17,
      .Qn = -2,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_24_64_64,
    },
    {
      .name = "Conv2D_12_off_bias_out_16",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 294912,
      .offset_end = 393216,
      .offset_limit = 393280,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 4,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_L_1_24_64_64,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_24_64_64,
      .per_channel = 0,
      .scale = buff_info_Conv2D_12_off_bias_out_16_quant_scale,
      .offset = buff_info_Conv2D_12_off_bias_out_16_quant_offset,
    },
    {
      .name = "Conv2D_15_off_bias_out_25",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 98304,
      .offset_limit = 98368,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 5,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_L_1_24_64_64,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_24_64_64,
      .per_channel = 0,
      .scale = buff_info_Conv2D_15_off_bias_out_25_quant_scale,
      .offset = buff_info_Conv2D_15_off_bias_out_25_quant_offset,
    },
    {
      .name = "Add_18_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 98304,
      .offset_end = 196608,
      .offset_limit = 196672,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 6,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_L_1_24_64_64,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_24_64_64,
      .per_channel = 0,
      .scale = buff_info_Add_18_out_0_quant_scale,
      .offset = buff_info_Add_18_out_0_quant_offset,
    },
    {
      .name = "Conv2D_26_off_bias_out_34",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 327680,
      .offset_end = 425984,
      .offset_limit = 426048,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 6,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_L_1_24_64_64,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_24_64_64,
      .per_channel = 0,
      .scale = buff_info_Conv2D_26_off_bias_out_34_quant_scale,
      .offset = buff_info_Conv2D_26_off_bias_out_34_quant_offset,
    },
    {
      .name = "Transpose_22_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 98304,
      .offset_limit = 98368,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 7,
      .batch = 64,
      .mem_shape = buff_info__mem_shape_L_1_64_24_64,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_64_24_64,
      .per_channel = 0,
      .scale = buff_info_Transpose_22_out_0_quant_scale,
      .offset = buff_info_Transpose_22_out_0_quant_offset,
    },
    {
      .name = "Transpose_22_out_0_cp_in_191",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 229376,
      .offset_end = 327680,
      .offset_limit = 327744,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 8,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_64_24_64,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_64_24_64,
    },
    {
      .name = "Conv2D_29_off_bias_out_43",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 114688,
      .offset_end = 229376,
      .offset_limit = 229440,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 8,
      .batch = 14,
      .mem_shape = buff_info__mem_shape_M14_1_28_64_64,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_28_64_64,
      .per_channel = 0,
      .scale = buff_info_Conv2D_29_off_bias_out_43_quant_scale,
      .offset = buff_info_Conv2D_29_off_bias_out_43_quant_offset,
    },
    {
      .name = "Pad_23_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 114688,
      .offset_limit = 114752,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 9,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_64_28_64,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_64_28_64,
    },
    {
      .name = "Transpose_24_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 229376,
      .offset_end = 344064,
      .offset_limit = 344128,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 10,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_28_64_64,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_28_64_64,
      .per_channel = 0,
      .scale = buff_info_Transpose_24_out_0_quant_scale,
      .offset = buff_info_Transpose_24_out_0_quant_offset,
    },
    {
      .name = "Transpose_24_out_0_inserted_out763",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 344064,
      .offset_end = 458752,
      .offset_limit = 458816,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 11,
      .batch = 28,
      .mem_shape = buff_info__mem_shape_L_1_28_64_64,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_28_64_64,
      .per_channel = 0,
      .scale = buff_info_Transpose_24_out_0_inserted_out763_quant_scale,
      .offset = buff_info_Transpose_24_out_0_inserted_out763_quant_offset,
    },
    {
      .name = "Add_32_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 114688,
      .offset_limit = 114752,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 12,
      .batch = 28,
      .mem_shape = buff_info__mem_shape_L_1_28_64_64,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_28_64_64,
      .per_channel = 0,
      .scale = buff_info_Add_32_out_0_quant_scale,
      .offset = buff_info_Add_32_out_0_quant_offset,
    },
    {
      .name = "Conv2D_37_zero_off_out_46",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 229376,
      .offset_end = 344064,
      .offset_limit = 344128,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 12,
      .batch = 28,
      .mem_shape = buff_info__mem_shape_L_1_28_64_64,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_28_64_64,
      .per_channel = 0,
      .scale = buff_info_Conv2D_37_zero_off_out_46_quant_scale,
      .offset = buff_info_Conv2D_37_zero_off_out_46_quant_offset,
    },
    {
      .name = "MaxPool_43_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 344064,
      .offset_end = 372736,
      .offset_limit = 372800,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 13,
      .batch = 28,
      .mem_shape = buff_info__mem_shape_L_1_28_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_28_32_32,
      .per_channel = 0,
      .scale = buff_info_MaxPool_43_out_0_quant_scale,
      .offset = buff_info_MaxPool_43_out_0_quant_offset,
    },
    {
      .name = "Conv2D_37_zero_off_out_46_cp_in_192",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 114688,
      .offset_end = 229376,
      .offset_limit = 229440,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 13,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_28_64_64,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_28_64_64,
      .per_channel = 0,
      .scale = buff_info_Conv2D_37_zero_off_out_46_cp_in_192_quant_scale,
      .offset = buff_info_Conv2D_37_zero_off_out_46_cp_in_192_quant_offset,
    },
    {
      .name = "Transpose_44_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 372736,
      .offset_end = 401408,
      .offset_limit = 401472,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 14,
      .batch = 32,
      .mem_shape = buff_info__mem_shape_L_1_32_28_32,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_32_28_32,
      .per_channel = 0,
      .scale = buff_info_Transpose_44_out_0_quant_scale,
      .offset = buff_info_Transpose_44_out_0_quant_offset,
    },
    {
      .name = "Conv2D_37_off_bias_out_52",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 65536,
      .offset_end = 94208,
      .offset_limit = 94272,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 15,
      .batch = 28,
      .mem_shape = buff_info__mem_shape_L_1_28_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_28_32_32,
      .per_channel = 0,
      .scale = buff_info_Conv2D_37_off_bias_out_52_quant_scale,
      .offset = buff_info_Conv2D_37_off_bias_out_52_quant_offset,
    },
    {
      .name = "Transpose_44_out_0_cp_in_193",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 401408,
      .offset_end = 430080,
      .offset_limit = 430144,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 15,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_32_28_32,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_32_28_32,
    },
    {
      .name = "Pad_45_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 32768,
      .offset_end = 65536,
      .offset_limit = 65600,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 16,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_32_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_32_32_32,
    },
    {
      .name = "Conv2D_40_off_bias_out_61",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 32768,
      .offset_limit = 32832,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 16,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_32_32_32,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_32_32_32,
      .per_channel = 0,
      .scale = buff_info_Conv2D_40_off_bias_out_61_quant_scale,
      .offset = buff_info_Conv2D_40_off_bias_out_61_quant_offset,
    },
    {
      .name = "Transpose_46_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 65536,
      .offset_end = 98304,
      .offset_limit = 98368,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 17,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_32_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_32_32_32,
      .per_channel = 0,
      .scale = buff_info_Transpose_46_out_0_quant_scale,
      .offset = buff_info_Transpose_46_out_0_quant_offset,
    },
    {
      .name = "Transpose_46_out_0_inserted_out768",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 32768,
      .offset_end = 65536,
      .offset_limit = 65600,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 18,
      .batch = 32,
      .mem_shape = buff_info__mem_shape_L_1_32_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_32_32_32,
      .per_channel = 0,
      .scale = buff_info_Transpose_46_out_0_inserted_out768_quant_scale,
      .offset = buff_info_Transpose_46_out_0_inserted_out768_quant_offset,
    },
    {
      .name = "Add_47_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 65536,
      .offset_end = 98304,
      .offset_limit = 98368,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 19,
      .batch = 32,
      .mem_shape = buff_info__mem_shape_L_1_32_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_32_32_32,
      .per_channel = 0,
      .scale = buff_info_Add_47_out_0_quant_scale,
      .offset = buff_info_Add_47_out_0_quant_offset,
    },
    {
      .name = "Conv2D_55_zero_off_out_64",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 98304,
      .offset_end = 131072,
      .offset_limit = 131136,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 19,
      .batch = 32,
      .mem_shape = buff_info__mem_shape_L_1_32_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_32_32_32,
      .per_channel = 0,
      .scale = buff_info_Conv2D_55_zero_off_out_64_quant_scale,
      .offset = buff_info_Conv2D_55_zero_off_out_64_quant_offset,
    },
    {
      .name = "Transpose_51_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 32768,
      .offset_limit = 32832,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 20,
      .batch = 32,
      .mem_shape = buff_info__mem_shape_L_1_32_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_32_32_32,
      .per_channel = 0,
      .scale = buff_info_Transpose_51_out_0_quant_scale,
      .offset = buff_info_Transpose_51_out_0_quant_offset,
    },
    {
      .name = "Conv2D_55_off_bias_out_70",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 131072,
      .offset_end = 163840,
      .offset_limit = 163904,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 21,
      .batch = 32,
      .mem_shape = buff_info__mem_shape_L_1_32_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_32_32_32,
      .per_channel = 0,
      .scale = buff_info_Conv2D_55_off_bias_out_70_quant_scale,
      .offset = buff_info_Conv2D_55_off_bias_out_70_quant_offset,
    },
    {
      .name = "Transpose_51_out_0_cp_in_194",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 163840,
      .offset_end = 196608,
      .offset_limit = 196672,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 21,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_32_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_32_32_32,
    },
    {
      .name = "Pad_52_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 36864,
      .offset_end = 73728,
      .offset_limit = 73792,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 22,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_32_36_32,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_32_36_32,
    },
    {
      .name = "Conv2D_58_off_bias_out_79",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 36864,
      .offset_limit = 36928,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 22,
      .batch = 18,
      .mem_shape = buff_info__mem_shape_M18_1_36_32_32,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_36_32_32,
      .per_channel = 0,
      .scale = buff_info_Conv2D_58_off_bias_out_79_quant_scale,
      .offset = buff_info_Conv2D_58_off_bias_out_79_quant_offset,
    },
    {
      .name = "Transpose_53_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 73728,
      .offset_end = 110592,
      .offset_limit = 110656,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 23,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_36_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_36_32_32,
      .per_channel = 0,
      .scale = buff_info_Transpose_53_out_0_quant_scale,
      .offset = buff_info_Transpose_53_out_0_quant_offset,
    },
    {
      .name = "Transpose_53_out_0_inserted_out773",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 36864,
      .offset_end = 73728,
      .offset_limit = 73792,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 24,
      .batch = 36,
      .mem_shape = buff_info__mem_shape_L_1_36_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_36_32_32,
      .per_channel = 0,
      .scale = buff_info_Transpose_53_out_0_inserted_out773_quant_scale,
      .offset = buff_info_Transpose_53_out_0_inserted_out773_quant_offset,
    },
    {
      .name = "Add_61_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 73728,
      .offset_end = 110592,
      .offset_limit = 110656,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 25,
      .batch = 36,
      .mem_shape = buff_info__mem_shape_L_1_36_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_36_32_32,
      .per_channel = 0,
      .scale = buff_info_Add_61_out_0_quant_scale,
      .offset = buff_info_Add_61_out_0_quant_offset,
    },
    {
      .name = "Conv2D_69_zero_off_out_82",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 110592,
      .offset_end = 147456,
      .offset_limit = 147520,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 25,
      .batch = 36,
      .mem_shape = buff_info__mem_shape_L_1_36_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_36_32_32,
      .per_channel = 0,
      .scale = buff_info_Conv2D_69_zero_off_out_82_quant_scale,
      .offset = buff_info_Conv2D_69_zero_off_out_82_quant_offset,
    },
    {
      .name = "Transpose_65_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 36864,
      .offset_limit = 36928,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 26,
      .batch = 32,
      .mem_shape = buff_info__mem_shape_L_1_32_36_32,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_32_36_32,
      .per_channel = 0,
      .scale = buff_info_Transpose_65_out_0_quant_scale,
      .offset = buff_info_Transpose_65_out_0_quant_offset,
    },
    {
      .name = "Conv2D_69_zero_off_out_82_cp_in_195",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 43008,
      .offset_end = 79872,
      .offset_limit = 79936,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 27,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_36_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_36_32_32,
      .per_channel = 0,
      .scale = buff_info_Conv2D_69_zero_off_out_82_cp_in_195_quant_scale,
      .offset = buff_info_Conv2D_69_zero_off_out_82_cp_in_195_quant_offset,
    },
    {
      .name = "Transpose_65_out_0_cp_in_196",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 147456,
      .offset_end = 184320,
      .offset_limit = 184384,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 27,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_32_36_32,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_32_36_32,
    },
    {
      .name = "Conv2D_69_off_bias_out_88",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 184320,
      .offset_end = 221184,
      .offset_limit = 221248,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 28,
      .batch = 36,
      .mem_shape = buff_info__mem_shape_L_1_36_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_36_32_32,
      .per_channel = 0,
      .scale = buff_info_Conv2D_69_off_bias_out_88_quant_scale,
      .offset = buff_info_Conv2D_69_off_bias_out_88_quant_offset,
    },
    {
      .name = "Pad_66_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 43008,
      .offset_limit = 43072,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 28,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_32_42_32,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_32_42_32,
    },
    {
      .name = "Transpose_67_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 43008,
      .offset_end = 86016,
      .offset_limit = 86080,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 29,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_42_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_42_32_32,
      .per_channel = 0,
      .scale = buff_info_Transpose_67_out_0_quant_scale,
      .offset = buff_info_Transpose_67_out_0_quant_offset,
    },
    {
      .name = "Transpose_67_out_0_inserted_out778",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 129024,
      .offset_end = 172032,
      .offset_limit = 172096,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 30,
      .batch = 42,
      .mem_shape = buff_info__mem_shape_L_1_42_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_42_32_32,
      .per_channel = 0,
      .scale = buff_info_Transpose_67_out_0_inserted_out778_quant_scale,
      .offset = buff_info_Transpose_67_out_0_inserted_out778_quant_offset,
    },
    {
      .name = "Conv2D_72_off_bias_out_97",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 86016,
      .offset_end = 129024,
      .offset_limit = 129088,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 30,
      .batch = 21,
      .mem_shape = buff_info__mem_shape_M21_1_42_32_32,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_42_32_32,
      .per_channel = 0,
      .scale = buff_info_Conv2D_72_off_bias_out_97_quant_scale,
      .offset = buff_info_Conv2D_72_off_bias_out_97_quant_offset,
    },
    {
      .name = "Add_75_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 43008,
      .offset_limit = 43072,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 31,
      .batch = 42,
      .mem_shape = buff_info__mem_shape_L_1_42_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_42_32_32,
      .per_channel = 0,
      .scale = buff_info_Add_75_out_0_quant_scale,
      .offset = buff_info_Add_75_out_0_quant_offset,
    },
    {
      .name = "Conv2D_80_zero_off_out_100",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 43008,
      .offset_end = 86016,
      .offset_limit = 86080,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 31,
      .batch = 42,
      .mem_shape = buff_info__mem_shape_L_1_42_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_42_32_32,
      .per_channel = 0,
      .scale = buff_info_Conv2D_80_zero_off_out_100_quant_scale,
      .offset = buff_info_Conv2D_80_zero_off_out_100_quant_offset,
    },
    {
      .name = "MaxPool_86_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 129024,
      .offset_end = 139776,
      .offset_limit = 139840,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 32,
      .batch = 42,
      .mem_shape = buff_info__mem_shape_L_1_42_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_42_16_16,
      .per_channel = 0,
      .scale = buff_info_MaxPool_86_out_0_quant_scale,
      .offset = buff_info_MaxPool_86_out_0_quant_offset,
    },
    {
      .name = "Conv2D_80_zero_off_out_100_cp_in_197",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 86016,
      .offset_end = 129024,
      .offset_limit = 129088,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 32,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_42_32_32,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_42_32_32,
      .per_channel = 0,
      .scale = buff_info_Conv2D_80_zero_off_out_100_cp_in_197_quant_scale,
      .offset = buff_info_Conv2D_80_zero_off_out_100_cp_in_197_quant_offset,
    },
    {
      .name = "Transpose_87_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 10752,
      .offset_limit = 10816,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 33,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_L_1_16_42_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_42_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_87_out_0_quant_scale,
      .offset = buff_info_Transpose_87_out_0_quant_offset,
    },
    {
      .name = "Conv2D_80_off_bias_out_106",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 24576,
      .offset_end = 35328,
      .offset_limit = 35392,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 34,
      .batch = 42,
      .mem_shape = buff_info__mem_shape_L_1_42_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_42_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_80_off_bias_out_106_quant_scale,
      .offset = buff_info_Conv2D_80_off_bias_out_106_quant_offset,
    },
    {
      .name = "Transpose_87_out_0_cp_in_198",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 35328,
      .offset_end = 46080,
      .offset_limit = 46144,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 34,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_16_42_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_42_16,
    },
    {
      .name = "Pad_88_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 12288,
      .offset_end = 24576,
      .offset_limit = 24640,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 35,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_16_48_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_48_16,
    },
    {
      .name = "Conv2D_83_off_bias_out_115",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 12288,
      .offset_limit = 12352,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 35,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_M24_1_48_16_16,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_48_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_83_off_bias_out_115_quant_scale,
      .offset = buff_info_Conv2D_83_off_bias_out_115_quant_offset,
    },
    {
      .name = "Transpose_89_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 24576,
      .offset_end = 36864,
      .offset_limit = 36928,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 36,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_48_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_48_16_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_89_out_0_quant_scale,
      .offset = buff_info_Transpose_89_out_0_quant_offset,
    },
    {
      .name = "Transpose_89_out_0_inserted_out783",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 12288,
      .offset_end = 24576,
      .offset_limit = 24640,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 37,
      .batch = 48,
      .mem_shape = buff_info__mem_shape_L_1_48_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_48_16_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_89_out_0_inserted_out783_quant_scale,
      .offset = buff_info_Transpose_89_out_0_inserted_out783_quant_offset,
    },
    {
      .name = "Add_90_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 24576,
      .offset_end = 36864,
      .offset_limit = 36928,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 38,
      .batch = 48,
      .mem_shape = buff_info__mem_shape_L_1_48_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_48_16_16,
      .per_channel = 0,
      .scale = buff_info_Add_90_out_0_quant_scale,
      .offset = buff_info_Add_90_out_0_quant_offset,
    },
    {
      .name = "Conv2D_98_zero_off_out_118",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 36864,
      .offset_end = 49152,
      .offset_limit = 49216,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 38,
      .batch = 48,
      .mem_shape = buff_info__mem_shape_L_1_48_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_48_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_98_zero_off_out_118_quant_scale,
      .offset = buff_info_Conv2D_98_zero_off_out_118_quant_offset,
    },
    {
      .name = "Transpose_94_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 12288,
      .offset_limit = 12352,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 39,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_L_1_16_48_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_48_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_94_out_0_quant_scale,
      .offset = buff_info_Transpose_94_out_0_quant_offset,
    },
    {
      .name = "Transpose_94_out_0_cp_in_199",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 49152,
      .offset_end = 61440,
      .offset_limit = 61504,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 40,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_16_48_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_48_16,
    },
    {
      .name = "Conv2D_98_off_bias_out_124",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 61440,
      .offset_end = 73728,
      .offset_limit = 73792,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 40,
      .batch = 48,
      .mem_shape = buff_info__mem_shape_L_1_48_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_48_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_98_off_bias_out_124_quant_scale,
      .offset = buff_info_Conv2D_98_off_bias_out_124_quant_offset,
    },
    {
      .name = "Pad_95_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 14336,
      .offset_end = 28672,
      .offset_limit = 28736,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 41,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_16_56_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_56_16,
    },
    {
      .name = "Conv2D_101_off_bias_out_130",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 14336,
      .offset_limit = 14400,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 41,
      .batch = 14,
      .mem_shape = buff_info__mem_shape_M14_1_56_16_16,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_56_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_101_off_bias_out_130_quant_scale,
      .offset = buff_info_Conv2D_101_off_bias_out_130_quant_offset,
    },
    {
      .name = "Transpose_96_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 28672,
      .offset_end = 43008,
      .offset_limit = 43072,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 42,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_56_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_56_16_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_96_out_0_quant_scale,
      .offset = buff_info_Transpose_96_out_0_quant_offset,
    },
    {
      .name = "Transpose_96_out_0_inserted_out787",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 14336,
      .offset_end = 28672,
      .offset_limit = 28736,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 43,
      .batch = 56,
      .mem_shape = buff_info__mem_shape_L_1_56_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_56_16_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_96_out_0_inserted_out787_quant_scale,
      .offset = buff_info_Transpose_96_out_0_inserted_out787_quant_offset,
    },
    {
      .name = "Add_104_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 28672,
      .offset_end = 43008,
      .offset_limit = 43072,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 44,
      .batch = 56,
      .mem_shape = buff_info__mem_shape_L_1_56_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_56_16_16,
      .per_channel = 0,
      .scale = buff_info_Add_104_out_0_quant_scale,
      .offset = buff_info_Add_104_out_0_quant_offset,
    },
    {
      .name = "Conv2D_112_zero_off_out_133",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 43008,
      .offset_end = 57344,
      .offset_limit = 57408,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 44,
      .batch = 56,
      .mem_shape = buff_info__mem_shape_L_1_56_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_56_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_112_zero_off_out_133_quant_scale,
      .offset = buff_info_Conv2D_112_zero_off_out_133_quant_offset,
    },
    {
      .name = "Transpose_108_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 14336,
      .offset_limit = 14400,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 45,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_L_1_16_56_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_56_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_108_out_0_quant_scale,
      .offset = buff_info_Transpose_108_out_0_quant_offset,
    },
    {
      .name = "Transpose_108_out_0_cp_in_200",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 16384,
      .offset_end = 30720,
      .offset_limit = 30784,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 46,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_16_56_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_56_16,
    },
    {
      .name = "Conv2D_112_off_bias_out_139",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 57344,
      .offset_end = 71680,
      .offset_limit = 71744,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 46,
      .batch = 56,
      .mem_shape = buff_info__mem_shape_L_1_56_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_56_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_112_off_bias_out_139_quant_scale,
      .offset = buff_info_Conv2D_112_off_bias_out_139_quant_offset,
    },
    {
      .name = "Pad_109_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 16384,
      .offset_limit = 16448,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 47,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_16_64_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_64_16,
    },
    {
      .name = "Transpose_110_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 16384,
      .offset_end = 32768,
      .offset_limit = 32832,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 48,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_64_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_64_16_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_110_out_0_quant_scale,
      .offset = buff_info_Transpose_110_out_0_quant_offset,
    },
    {
      .name = "Transpose_110_out_0_inserted_out794",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 32768,
      .offset_end = 49152,
      .offset_limit = 49216,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 49,
      .batch = 64,
      .mem_shape = buff_info__mem_shape_L_1_64_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_64_16_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_110_out_0_inserted_out794_quant_scale,
      .offset = buff_info_Transpose_110_out_0_inserted_out794_quant_offset,
    },
    {
      .name = "Conv2D_115_off_bias_out_148",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 16384,
      .offset_limit = 16448,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 49,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_M16_1_64_16_16,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_64_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_115_off_bias_out_148_quant_scale,
      .offset = buff_info_Conv2D_115_off_bias_out_148_quant_offset,
    },
    {
      .name = "Add_118_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 16384,
      .offset_end = 32768,
      .offset_limit = 32832,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 50,
      .batch = 64,
      .mem_shape = buff_info__mem_shape_L_1_64_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_64_16_16,
      .per_channel = 0,
      .scale = buff_info_Add_118_out_0_quant_scale,
      .offset = buff_info_Add_118_out_0_quant_offset,
    },
    {
      .name = "Conv2D_126_zero_off_out_151",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 71680,
      .offset_end = 88064,
      .offset_limit = 88128,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 50,
      .batch = 64,
      .mem_shape = buff_info__mem_shape_L_1_64_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_64_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_126_zero_off_out_151_quant_scale,
      .offset = buff_info_Conv2D_126_zero_off_out_151_quant_offset,
    },
    {
      .name = "Transpose_122_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 16384,
      .offset_limit = 16448,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 51,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_L_1_16_64_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_64_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_122_out_0_quant_scale,
      .offset = buff_info_Transpose_122_out_0_quant_offset,
    },
    {
      .name = "Transpose_122_out_0_cp_in_201",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 18432,
      .offset_end = 34816,
      .offset_limit = 34880,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 52,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_16_64_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_64_16,
    },
    {
      .name = "Conv2D_126_off_bias_out_157",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 55296,
      .offset_end = 71680,
      .offset_limit = 71744,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 52,
      .batch = 64,
      .mem_shape = buff_info__mem_shape_L_1_64_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_64_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_126_off_bias_out_157_quant_scale,
      .offset = buff_info_Conv2D_126_off_bias_out_157_quant_offset,
    },
    {
      .name = "Pad_123_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 18432,
      .offset_limit = 18496,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 53,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_16_72_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_72_16,
    },
    {
      .name = "Transpose_124_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 18432,
      .offset_end = 36864,
      .offset_limit = 36928,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 54,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_72_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_72_16_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_124_out_0_quant_scale,
      .offset = buff_info_Transpose_124_out_0_quant_offset,
    },
    {
      .name = "Transpose_124_out_0_inserted_out801",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 36864,
      .offset_end = 55296,
      .offset_limit = 55360,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 55,
      .batch = 72,
      .mem_shape = buff_info__mem_shape_L_1_72_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_72_16_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_124_out_0_inserted_out801_quant_scale,
      .offset = buff_info_Transpose_124_out_0_inserted_out801_quant_offset,
    },
    {
      .name = "Conv2D_129_off_bias_out_166",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 18432,
      .offset_limit = 18496,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 55,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_M24_1_72_16_16,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_72_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_129_off_bias_out_166_quant_scale,
      .offset = buff_info_Conv2D_129_off_bias_out_166_quant_offset,
    },
    {
      .name = "Add_132_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 18432,
      .offset_end = 36864,
      .offset_limit = 36928,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 56,
      .batch = 72,
      .mem_shape = buff_info__mem_shape_L_1_72_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_72_16_16,
      .per_channel = 0,
      .scale = buff_info_Add_132_out_0_quant_scale,
      .offset = buff_info_Add_132_out_0_quant_offset,
    },
    {
      .name = "Conv2D_140_zero_off_out_169",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 55296,
      .offset_end = 73728,
      .offset_limit = 73792,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 56,
      .batch = 72,
      .mem_shape = buff_info__mem_shape_L_1_72_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_72_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_140_zero_off_out_169_quant_scale,
      .offset = buff_info_Conv2D_140_zero_off_out_169_quant_offset,
    },
    {
      .name = "Transpose_136_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 18432,
      .offset_limit = 18496,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 57,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_L_1_16_72_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_72_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_136_out_0_quant_scale,
      .offset = buff_info_Transpose_136_out_0_quant_offset,
    },
    {
      .name = "Transpose_136_out_0_cp_in_202",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 73728,
      .offset_end = 92160,
      .offset_limit = 92224,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 58,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_16_72_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_72_16,
    },
    {
      .name = "Conv2D_140_off_bias_out_175",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 92160,
      .offset_end = 110592,
      .offset_limit = 110656,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 58,
      .batch = 72,
      .mem_shape = buff_info__mem_shape_L_1_72_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_72_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_140_off_bias_out_175_quant_scale,
      .offset = buff_info_Conv2D_140_off_bias_out_175_quant_offset,
    },
    {
      .name = "Pad_137_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 20480,
      .offset_end = 40960,
      .offset_limit = 41024,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 59,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_16_80_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_80_16,
    },
    {
      .name = "Conv2D_143_off_bias_out_184",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 20480,
      .offset_limit = 20544,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 59,
      .batch = 20,
      .mem_shape = buff_info__mem_shape_M20_1_80_16_16,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_80_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_143_off_bias_out_184_quant_scale,
      .offset = buff_info_Conv2D_143_off_bias_out_184_quant_offset,
    },
    {
      .name = "Transpose_138_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 40960,
      .offset_end = 61440,
      .offset_limit = 61504,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 60,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_80_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_80_16_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_138_out_0_quant_scale,
      .offset = buff_info_Transpose_138_out_0_quant_offset,
    },
    {
      .name = "Transpose_138_out_0_inserted_out807",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 20480,
      .offset_end = 40960,
      .offset_limit = 41024,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 61,
      .batch = 80,
      .mem_shape = buff_info__mem_shape_L_1_80_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_80_16_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_138_out_0_inserted_out807_quant_scale,
      .offset = buff_info_Transpose_138_out_0_inserted_out807_quant_offset,
    },
    {
      .name = "Add_146_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 40960,
      .offset_end = 61440,
      .offset_limit = 61504,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 62,
      .batch = 80,
      .mem_shape = buff_info__mem_shape_L_1_80_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_80_16_16,
      .per_channel = 0,
      .scale = buff_info_Add_146_out_0_quant_scale,
      .offset = buff_info_Add_146_out_0_quant_offset,
    },
    {
      .name = "Conv2D_154_zero_off_out_187",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 61440,
      .offset_end = 81920,
      .offset_limit = 81984,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 62,
      .batch = 80,
      .mem_shape = buff_info__mem_shape_L_1_80_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_80_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_154_zero_off_out_187_quant_scale,
      .offset = buff_info_Conv2D_154_zero_off_out_187_quant_offset,
    },
    {
      .name = "Transpose_150_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 20480,
      .offset_limit = 20544,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 63,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_L_1_16_80_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_80_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_150_out_0_quant_scale,
      .offset = buff_info_Transpose_150_out_0_quant_offset,
    },
    {
      .name = "Conv2D_154_off_bias_out_193",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 112640,
      .offset_end = 133120,
      .offset_limit = 133184,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 64,
      .batch = 80,
      .mem_shape = buff_info__mem_shape_L_1_80_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_80_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_154_off_bias_out_193_quant_scale,
      .offset = buff_info_Conv2D_154_off_bias_out_193_quant_offset,
    },
    {
      .name = "Transpose_150_out_0_cp_in_203",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 22528,
      .offset_end = 43008,
      .offset_limit = 43072,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 64,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_16_80_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_80_16,
    },
    {
      .name = "Pad_151_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 22528,
      .offset_limit = 22592,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 65,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_16_88_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_88_16,
    },
    {
      .name = "Transpose_152_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 22528,
      .offset_end = 45056,
      .offset_limit = 45120,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 66,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_88_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_88_16_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_152_out_0_quant_scale,
      .offset = buff_info_Transpose_152_out_0_quant_offset,
    },
    {
      .name = "Conv2D_157_off_bias_out_202",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 67584,
      .offset_end = 90112,
      .offset_limit = 90176,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 67,
      .batch = 22,
      .mem_shape = buff_info__mem_shape_M22_1_88_16_16,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_88_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_157_off_bias_out_202_quant_scale,
      .offset = buff_info_Conv2D_157_off_bias_out_202_quant_offset,
    },
    {
      .name = "Transpose_152_out_0_inserted_out814",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 90112,
      .offset_end = 112640,
      .offset_limit = 112704,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 67,
      .batch = 88,
      .mem_shape = buff_info__mem_shape_L_1_88_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_88_16_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_152_out_0_inserted_out814_quant_scale,
      .offset = buff_info_Transpose_152_out_0_inserted_out814_quant_offset,
    },
    {
      .name = "Add_160_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 22528,
      .offset_limit = 22592,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 68,
      .batch = 88,
      .mem_shape = buff_info__mem_shape_L_1_88_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_88_16_16,
      .per_channel = 0,
      .scale = buff_info_Add_160_out_0_quant_scale,
      .offset = buff_info_Add_160_out_0_quant_offset,
    },
    {
      .name = "Conv2D_165_zero_off_out_205",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 112640,
      .offset_end = 135168,
      .offset_limit = 135232,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 68,
      .batch = 88,
      .mem_shape = buff_info__mem_shape_L_1_88_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_88_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_165_zero_off_out_205_quant_scale,
      .offset = buff_info_Conv2D_165_zero_off_out_205_quant_offset,
    },
    {
      .name = "Conv2D_247_zero_off_out_322",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 22528,
      .offset_end = 45056,
      .offset_limit = 45120,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 68,
      .batch = 22,
      .mem_shape = buff_info__mem_shape_M22_1_88_16_16,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_88_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_247_zero_off_out_322_quant_scale,
      .offset = buff_info_Conv2D_247_zero_off_out_322_quant_offset,
    },
    {
      .name = "Conv2D_239_zero_off_out_313",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 45056,
      .offset_end = 67584,
      .offset_limit = 67648,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 68,
      .batch = 22,
      .mem_shape = buff_info__mem_shape_M22_1_88_16_16,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_88_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_239_zero_off_out_313_quant_scale,
      .offset = buff_info_Conv2D_239_zero_off_out_313_quant_offset,
    },
    {
      .name = "MaxPool_171_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 73216,
      .offset_end = 78848,
      .offset_limit = 78912,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 69,
      .batch = 88,
      .mem_shape = buff_info__mem_shape_L_1_88_8_8,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_88_8_8,
      .per_channel = 0,
      .scale = buff_info_MaxPool_171_out_0_quant_scale,
      .offset = buff_info_MaxPool_171_out_0_quant_offset,
    },
    {
      .name = "Conv2D_165_off_bias_out_211",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 67584,
      .offset_end = 73216,
      .offset_limit = 73280,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 69,
      .batch = 88,
      .mem_shape = buff_info__mem_shape_L_1_88_8_8,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_88_8_8,
      .per_channel = 0,
      .scale = buff_info_Conv2D_165_off_bias_out_211_quant_scale,
      .offset = buff_info_Conv2D_165_off_bias_out_211_quant_offset,
    },
    {
      .name = "Transpose_172_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 5632,
      .offset_limit = 5696,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 70,
      .batch = 8,
      .mem_shape = buff_info__mem_shape_L_1_8_88_8,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_8_88_8,
      .per_channel = 0,
      .scale = buff_info_Transpose_172_out_0_quant_scale,
      .offset = buff_info_Transpose_172_out_0_quant_offset,
    },
    {
      .name = "Conv2D_247_out_0_cp_in_162_cp_in_163_cp_in_164",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 19968,
      .offset_end = 20992,
      .offset_limit = 21056,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 71,
      .batch = 2,
      .mem_shape = buff_info__mem_shape_L_1_2_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 19,
      .Qn = -4,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 16,
      .ndims = 4,
      .shape = buff_info__shape_1_2_16_16,
    },
    {
      .name = "Transpose_172_out_0_cp_in_204",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 14336,
      .offset_end = 19968,
      .offset_limit = 20032,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 71,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_8_88_8,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_8_88_8,
    },
    {
      .name = "Conv2D_247_off_bias_out_328",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 40960,
      .offset_end = 41472,
      .offset_limit = 41536,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 72,
      .batch = 2,
      .mem_shape = buff_info__mem_shape_L_1_2_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_2_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_247_off_bias_out_328_quant_scale,
      .offset = buff_info_Conv2D_247_off_bias_out_328_quant_offset,
    },
    {
      .name = "Transpose_250_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 40960,
      .offset_end = 41472,
      .offset_limit = 41536,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 72,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_16_16_2,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_16_2,
      .per_channel = 0,
      .scale = buff_info_Transpose_250_out_0_quant_scale,
      .offset = buff_info_Transpose_250_out_0_quant_offset,
    },
    {
      .name = "Conv2D_239_off_bias_out_319",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 8192,
      .offset_limit = 8256,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 72,
      .batch = 32,
      .mem_shape = buff_info__mem_shape_L_1_32_16_16,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_32_16_16,
      .per_channel = 0,
      .scale = buff_info_Conv2D_239_off_bias_out_319_quant_scale,
      .offset = buff_info_Conv2D_239_off_bias_out_319_quant_offset,
    },
    {
      .name = "Transpose_242_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 8192,
      .offset_limit = 8256,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 72,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_16_16_32,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_16_32,
      .per_channel = 0,
      .scale = buff_info_Transpose_242_out_0_quant_scale,
      .offset = buff_info_Transpose_242_out_0_quant_offset,
    },
    {
      .name = "Reshape_243_out_0_inserted_out827",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 8192,
      .offset_limit = 8256,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 72,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_512_16_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_512_16_1,
      .per_channel = 0,
      .scale = buff_info_Reshape_243_out_0_inserted_out827_quant_scale,
      .offset = buff_info_Reshape_243_out_0_inserted_out827_quant_offset,
    },
    {
      .name = "Pad_173_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 8192,
      .offset_end = 14336,
      .offset_limit = 14400,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 73,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_8_96_8,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FXP,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_8_96_8,
    },
    {
      .name = "Transpose_174_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 16384,
      .offset_end = 22528,
      .offset_limit = 22592,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 74,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_96_8_8,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_96_8_8,
      .per_channel = 0,
      .scale = buff_info_Transpose_174_out_0_quant_scale,
      .offset = buff_info_Transpose_174_out_0_quant_offset,
    },
    {
      .name = "Conv2D_168_off_bias_out_220",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 22528,
      .offset_end = 28672,
      .offset_limit = 28736,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 75,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_M24_1_96_8_8,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_96_8_8,
      .per_channel = 0,
      .scale = buff_info_Conv2D_168_off_bias_out_220_quant_scale,
      .offset = buff_info_Conv2D_168_off_bias_out_220_quant_offset,
    },
    {
      .name = "Transpose_174_out_0_inserted_out830",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 28672,
      .offset_end = 34816,
      .offset_limit = 34880,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 75,
      .batch = 96,
      .mem_shape = buff_info__mem_shape_L_1_96_8_8,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_96_8_8,
      .per_channel = 0,
      .scale = buff_info_Transpose_174_out_0_inserted_out830_quant_scale,
      .offset = buff_info_Transpose_174_out_0_inserted_out830_quant_offset,
    },
    {
      .name = "Reshape_243_out_0_inserted_out827_inserted_out829",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 8192,
      .offset_end = 16384,
      .offset_limit = 16448,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 75,
      .batch = 512,
      .mem_shape = buff_info__mem_shape_L_1_512_16_1,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_512_16_1,
      .per_channel = 0,
      .scale = buff_info_Reshape_243_out_0_inserted_out827_inserted_out829_quant_scale,
      .offset = buff_info_Reshape_243_out_0_inserted_out827_inserted_out829_quant_offset,
    },
    {
      .name = "Transpose_244_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 8192,
      .offset_end = 16384,
      .offset_limit = 16448,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 75,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_16_1_512,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_1_512,
      .per_channel = 0,
      .scale = buff_info_Transpose_244_out_0_quant_scale,
      .offset = buff_info_Transpose_244_out_0_quant_offset,
    },
    {
      .name = "Transpose_244_out_0_cp_in_172_inserted_out831",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 8192,
      .offset_end = 16384,
      .offset_limit = 16448,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 75,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_16_512_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_512_1,
      .per_channel = 0,
      .scale = buff_info_Transpose_244_out_0_cp_in_172_inserted_out831_quant_scale,
      .offset = buff_info_Transpose_244_out_0_cp_in_172_inserted_out831_quant_offset,
    },
    {
      .name = "Add_175_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 16384,
      .offset_end = 22528,
      .offset_limit = 22592,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 76,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_M24_1_96_8_8,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_96_8_8,
      .per_channel = 0,
      .scale = buff_info_Add_175_out_0_quant_scale,
      .offset = buff_info_Add_175_out_0_quant_offset,
    },
    {
      .name = "Conv2D_180_zero_off_out_223",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 34816,
      .offset_end = 40960,
      .offset_limit = 41024,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 76,
      .batch = 96,
      .mem_shape = buff_info__mem_shape_L_1_96_8_8,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_96_8_8,
      .per_channel = 0,
      .scale = buff_info_Conv2D_180_zero_off_out_223_quant_scale,
      .offset = buff_info_Conv2D_180_zero_off_out_223_quant_offset,
    },
    {
      .name = "Transpose_244_out_0_cp_in_172_inserted_out831_inserted_out833",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 8192,
      .offset_limit = 8256,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 76,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_L_1_16_512_1,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_512_1,
      .per_channel = 0,
      .scale = buff_info_Transpose_244_out_0_cp_in_172_inserted_out831_inserted_out833_quant_scale,
      .offset = buff_info_Transpose_244_out_0_cp_in_172_inserted_out831_inserted_out833_quant_offset,
    },
    {
      .name = "Transpose_246_out_0_cp_in_173",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 0,
      .offset_end = 8192,
      .offset_limit = 8256,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 76,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_512_1_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_512_1_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_246_out_0_cp_in_173_quant_scale,
      .offset = buff_info_Transpose_246_out_0_cp_in_173_quant_offset,
    },
    {
      .name = "Conv2D_180_off_bias_out_229",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 22528,
      .offset_end = 28672,
      .offset_limit = 28736,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 77,
      .batch = 96,
      .mem_shape = buff_info__mem_shape_L_1_96_8_8,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_96_8_8,
      .per_channel = 0,
      .scale = buff_info_Conv2D_180_off_bias_out_229_quant_scale,
      .offset = buff_info_Conv2D_180_off_bias_out_229_quant_offset,
    },
    {
      .name = "Add_186_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 8192,
      .offset_end = 14336,
      .offset_limit = 14400,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 78,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_M24_1_96_8_8,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_96_8_8,
      .per_channel = 0,
      .scale = buff_info_Add_186_out_0_quant_scale,
      .offset = buff_info_Add_186_out_0_quant_offset,
    },
    {
      .name = "Conv2D_191_zero_off_out_241",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 28672,
      .offset_end = 34816,
      .offset_limit = 34880,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 78,
      .batch = 96,
      .mem_shape = buff_info__mem_shape_L_1_96_8_8,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_96_8_8,
      .per_channel = 0,
      .scale = buff_info_Conv2D_191_zero_off_out_241_quant_scale,
      .offset = buff_info_Conv2D_191_zero_off_out_241_quant_offset,
    },
    {
      .name = "Conv2D_191_off_bias_out_247",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 20480,
      .offset_end = 26624,
      .offset_limit = 26688,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 79,
      .batch = 96,
      .mem_shape = buff_info__mem_shape_L_1_96_8_8,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_96_8_8,
      .per_channel = 0,
      .scale = buff_info_Conv2D_191_off_bias_out_247_quant_scale,
      .offset = buff_info_Conv2D_191_off_bias_out_247_quant_offset,
    },
    {
      .name = "Add_197_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 14336,
      .offset_end = 20480,
      .offset_limit = 20544,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 80,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_M24_1_96_8_8,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_96_8_8,
      .per_channel = 0,
      .scale = buff_info_Add_197_out_0_quant_scale,
      .offset = buff_info_Add_197_out_0_quant_offset,
    },
    {
      .name = "Conv2D_202_zero_off_out_259",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 26624,
      .offset_end = 32768,
      .offset_limit = 32832,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 80,
      .batch = 96,
      .mem_shape = buff_info__mem_shape_L_1_96_8_8,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_96_8_8,
      .per_channel = 0,
      .scale = buff_info_Conv2D_202_zero_off_out_259_quant_scale,
      .offset = buff_info_Conv2D_202_zero_off_out_259_quant_offset,
    },
    {
      .name = "Conv2D_202_off_bias_out_265",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 20480,
      .offset_end = 26624,
      .offset_limit = 26688,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 81,
      .batch = 96,
      .mem_shape = buff_info__mem_shape_L_1_96_8_8,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_96_8_8,
      .per_channel = 0,
      .scale = buff_info_Conv2D_202_off_bias_out_265_quant_scale,
      .offset = buff_info_Conv2D_202_off_bias_out_265_quant_offset,
    },
    {
      .name = "Add_208_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 8192,
      .offset_end = 14336,
      .offset_limit = 14400,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 82,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_M24_1_96_8_8,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_96_8_8,
      .per_channel = 0,
      .scale = buff_info_Add_208_out_0_quant_scale,
      .offset = buff_info_Add_208_out_0_quant_offset,
    },
    {
      .name = "Conv2D_213_zero_off_out_277",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 26624,
      .offset_end = 32768,
      .offset_limit = 32832,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 82,
      .batch = 96,
      .mem_shape = buff_info__mem_shape_L_1_96_8_8,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_96_8_8,
      .per_channel = 0,
      .scale = buff_info_Conv2D_213_zero_off_out_277_quant_scale,
      .offset = buff_info_Conv2D_213_zero_off_out_277_quant_offset,
    },
    {
      .name = "Conv2D_213_off_bias_out_283",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 14336,
      .offset_end = 20480,
      .offset_limit = 20544,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 83,
      .batch = 96,
      .mem_shape = buff_info__mem_shape_L_1_96_8_8,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_96_8_8,
      .per_channel = 0,
      .scale = buff_info_Conv2D_213_off_bias_out_283_quant_scale,
      .offset = buff_info_Conv2D_213_off_bias_out_283_quant_offset,
    },
    {
      .name = "Add_219_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 26624,
      .offset_end = 32768,
      .offset_limit = 32832,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 84,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_M24_1_96_8_8,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_96_8_8,
      .per_channel = 0,
      .scale = buff_info_Add_219_out_0_quant_scale,
      .offset = buff_info_Add_219_out_0_quant_offset,
    },
    {
      .name = "Conv2D_231_zero_off_out_304",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 20480,
      .offset_end = 26624,
      .offset_limit = 26688,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 84,
      .batch = 24,
      .mem_shape = buff_info__mem_shape_M24_1_96_8_8,
      .mem_ndims = 5,
      .chpos = CHPos_Mixed,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_96_8_8,
      .per_channel = 0,
      .scale = buff_info_Conv2D_231_zero_off_out_304_quant_scale,
      .offset = buff_info_Conv2D_231_zero_off_out_304_quant_offset,
    },
    {
      .name = "Conv2D_223_zero_off_out_295",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 14336,
      .offset_end = 20480,
      .offset_limit = 20544,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 85,
      .batch = 96,
      .mem_shape = buff_info__mem_shape_L_1_96_8_8,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 8,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_UINT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_96_8_8,
      .per_channel = 0,
      .scale = buff_info_Conv2D_223_zero_off_out_295_quant_scale,
      .offset = buff_info_Conv2D_223_zero_off_out_295_quant_offset,
    },
    {
      .name = "Conv2D_231_off_bias_out_310",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 32768,
      .offset_end = 33152,
      .offset_limit = 33216,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 85,
      .batch = 6,
      .mem_shape = buff_info__mem_shape_L_1_6_8_8,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_6_8_8,
      .per_channel = 0,
      .scale = buff_info_Conv2D_231_off_bias_out_310_quant_scale,
      .offset = buff_info_Conv2D_231_off_bias_out_310_quant_offset,
    },
    {
      .name = "Transpose_234_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 32768,
      .offset_end = 33152,
      .offset_limit = 33216,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 85,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_8_8_6,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_8_8_6,
      .per_channel = 0,
      .scale = buff_info_Transpose_234_out_0_quant_scale,
      .offset = buff_info_Transpose_234_out_0_quant_offset,
    },
    {
      .name = "Conv2D_223_off_bias_out_301",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 8192,
      .offset_end = 14336,
      .offset_limit = 14400,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 86,
      .batch = 96,
      .mem_shape = buff_info__mem_shape_L_1_96_8_8,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_96_8_8,
      .per_channel = 0,
      .scale = buff_info_Conv2D_223_off_bias_out_301_quant_scale,
      .offset = buff_info_Conv2D_223_off_bias_out_301_quant_offset,
    },
    {
      .name = "Transpose_226_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 8192,
      .offset_end = 14336,
      .offset_limit = 14400,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 86,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_8_8_96,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_8_8_96,
      .per_channel = 0,
      .scale = buff_info_Transpose_226_out_0_quant_scale,
      .offset = buff_info_Transpose_226_out_0_quant_offset,
    },
    {
      .name = "Reshape_227_out_0_inserted_out849",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 8192,
      .offset_end = 14336,
      .offset_limit = 14400,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 86,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_384_16_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_384_16_1,
      .per_channel = 0,
      .scale = buff_info_Reshape_227_out_0_inserted_out849_quant_scale,
      .offset = buff_info_Reshape_227_out_0_inserted_out849_quant_offset,
    },
    {
      .name = "Reshape_227_out_0_inserted_out849_inserted_out851",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 14336,
      .offset_end = 20480,
      .offset_limit = 20544,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 87,
      .batch = 384,
      .mem_shape = buff_info__mem_shape_L_1_384_16_1,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_384_16_1,
      .per_channel = 0,
      .scale = buff_info_Reshape_227_out_0_inserted_out849_inserted_out851_quant_scale,
      .offset = buff_info_Reshape_227_out_0_inserted_out849_inserted_out851_quant_offset,
    },
    {
      .name = "Transpose_228_out_0",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 14336,
      .offset_end = 20480,
      .offset_limit = 20544,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 87,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_16_1_384,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_1_384,
      .per_channel = 0,
      .scale = buff_info_Transpose_228_out_0_quant_scale,
      .offset = buff_info_Transpose_228_out_0_quant_offset,
    },
    {
      .name = "Transpose_228_out_0_cp_in_189_inserted_out852",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 14336,
      .offset_end = 20480,
      .offset_limit = 20544,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 87,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_16_384_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_384_1,
      .per_channel = 0,
      .scale = buff_info_Transpose_228_out_0_cp_in_189_inserted_out852_quant_scale,
      .offset = buff_info_Transpose_228_out_0_cp_in_189_inserted_out852_quant_offset,
    },
    {
      .name = "Transpose_228_out_0_cp_in_189_inserted_out852_inserted_out854",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 8192,
      .offset_end = 14336,
      .offset_limit = 14400,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 88,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_L_1_16_384_1,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_16_384_1,
      .per_channel = 0,
      .scale = buff_info_Transpose_228_out_0_cp_in_189_inserted_out852_inserted_out854_quant_scale,
      .offset = buff_info_Transpose_228_out_0_cp_in_189_inserted_out852_inserted_out854_quant_offset,
    },
    {
      .name = "Transpose_230_out_0_cp_in_190",
      .addr_base = {(unsigned char *)(0x34200000UL) /* Equivalent hex address = 0x34200000UL */},
      .offset_start = 8192,
      .offset_end = 14336,
      .offset_limit = 14400,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 88,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_384_1_16,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 7,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_INT8,
      .nbits = 8,
      .ndims = 4,
      .shape = buff_info__shape_1_384_1_16,
      .per_channel = 0,
      .scale = buff_info_Transpose_230_out_0_cp_in_190_quant_scale,
      .offset = buff_info_Transpose_230_out_0_cp_in_190_quant_offset,
    },
    {
      .name = NULL,
    }
  };

  return buff_info;
}

